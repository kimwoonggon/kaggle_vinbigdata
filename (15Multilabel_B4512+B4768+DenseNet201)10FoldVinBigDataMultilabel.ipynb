{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "(TPU-B4512)+InferenceOtherModel 10FoldVinBigDataMultilabel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSxJAF+jk7CfdwjQbXboBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoonggon/kaggle_vinbigdata/blob/main/(15Multilabel_B4512%2BB4768%2BDenseNet201)10FoldVinBigDataMultilabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbJWFGLTJ9A",
        "outputId": "9ad033e0-ee32-4b98-a485-8634db4099c3"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_vL8ic3HcZ",
        "outputId": "d507414a-32a2-4b97-92c2-2e7508e92662"
      },
      "source": [
        "#!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "#!pip install -U tensorflow-addons==0.9.1\n",
        "!pip install -U tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import requests\n",
        "import os\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xX204k2Ktd"
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPVid4aN0du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42420dc1-cfc3-41f8-8615-4d01b943caeb"
      },
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "!pip install gcsfs #gcp 파일 로드\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import functools"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/49/2dbc00f89ab9e7513faee7927ea0c649d68eb721108aee860380eaf86ff4/gcsfs-0.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.28.0)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.1MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.3)\n",
            "Collecting ujson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/4e/50e8e4cf5f00b537095711c2c86ac4d7191aed2b4fffd5a19f06898f6929/ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (54.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 21.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (20.3.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.8.0->gcsfs) (3.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.8.0->gcsfs) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: multidict, yarl, async-timeout, aiohttp, fsspec, ujson, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-0.9.0 gcsfs-0.8.0 multidict-5.1.0 ujson-4.0.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NERnp6GCrxgr"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CFiVVS4Q82",
        "outputId": "a2a0dcc8-d0c7-4347-8ac7-f8097389f9fb"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.104.152.122:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ylvljm1eIu",
        "outputId": "47a07aa5-2ae1-428e-94f4-786040dc8cbd"
      },
      "source": [
        "MIXED_PRECISION = True\n",
        "XLA_ACCELERATE = True\n",
        " \n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "    if tpu: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
        "    else: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        " \n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed precision enabled\n",
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqZy4Kipt7v"
      },
      "source": [
        "class CFG:\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 512\n",
        "    OBJ_HEIGHT = 512\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 7e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 15\n",
        "    #CLASS_WEIGHT = {0:1.42629, 1:1.29648, 2:1.28211, 3:1.05131, 4:1.26954}\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        " \n",
        "    NET = 4\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    #GCS_PATH_2019 = 'gs://kds-2ae4f2c9141c2ce643fa1d59c544fc258a02543d9cd46d9149ba8c5a'\n",
        "    #GCS_PATH = 'gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df'\n",
        "    #If Ten fold\n",
        "    GCS_PATH = 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/vin_2classifier'\n",
        "    \n",
        "    #RANDAUG_NUM = 2\n",
        "    #RANDAUG_MAGNITUDE = 22"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXd8pFJ1fmR",
        "outputId": "b9ad890e-92d1-422b-eca2-8bb86dee4a0c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import efficientnet.tfkeras as efn\n",
        "# Configuration\n",
        "effnets = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]\n",
        " \n",
        "TTA_NUM = CFG.TTA_NUM\n",
        "TOTALWIDTH = CFG.WIDTH\n",
        "TOTALHEIGHT = CFG.HEIGHT\n",
        "HEIGHT = CFG.OBJ_HEIGHT\n",
        "WIDTH = CFG.OBJ_WIDTH\n",
        "IMAGE_SIZE = [HEIGHT, WIDTH]\n",
        "NET = CFG.NET\n",
        "BATCH_SIZE = CFG.BATCH_SIZE\n",
        "AUG_BATCH = BATCH_SIZE\n",
        "CHANNELS = CFG.CHANNELS\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "GCS_PATH = CFG.GCS_PATH\n",
        "ROOT_PATH = CFG.ROOT_PATH\n",
        "EPOCHS = CFG.EPOCHS\n",
        "SEED = CFG.SEED\n",
        "LEARNING_RATE = CFG.LEARNING_RATE\n",
        "NUMBER_OF_CLASSES = CFG.NUMBER_OF_CLASSES\n",
        " \n",
        "#class_weight = CFG.CLASS_WEIGHT\n",
        " \n",
        "IMAGE_MEAN = CFG.MEAN\n",
        "IMAGE_STD = CFG.STD \n",
        "FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH + '/train*')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(\"gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df\"+\"/test*\")\n",
        "#FILENAMES_2019 = tf.io.gfile.glob(CFG.GCS_PATH_2019+ '/train*')\n",
        "print(FILENAMES)\n",
        "print(TEST_FILENAMES)\n",
        "#print(FILENAMES_2019)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold0-1490.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold1-1501.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold2-1500.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold3-1495.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold4-1501.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold5-1494.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold6-1495.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold7-1516.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold8-1508.tfrecords', 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953/train2019_fold9-1500.tfrecords']\n",
            "['gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df/test-3000.tfrecords']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SOJUTcaXH2a",
        "outputId": "77c7a282-3e43-4c35-a142-67492d62ffb7"
      },
      "source": [
        "\"test_image = tf.cast(tf.random.uniform(shape=(1024,1024,3),minval = 0,maxval = 255,dtype=tf.int32), dtype=tf.uint8)\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow_addons.image.utils import to_4D_image, from_4D_image \n",
        "import inspect\n",
        "import math\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import image as contrib_image\n",
        "#from tensorflow.contrib import training as contrib_training\n",
        "def blend(image1, image2, factor):\n",
        "  \"\"\"Blend image1 and image2 using 'factor'.\n",
        "  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n",
        "  A value of 1.0 means only image2 is used.  A value between 0.0 and\n",
        "  1.0 means we linearly interpolate the pixel values between the two\n",
        "  images.  A value greater than 1.0 \"extrapolates\" the difference\n",
        "  between the two pixel values, and we clip the results to values\n",
        "  between 0 and 255.\n",
        "  Args:\n",
        "    image1: An image Tensor of type uint8.\n",
        "    image2: An image Tensor of type uint8.\n",
        "    factor: A floating point value above 0.0.\n",
        "  Returns:\n",
        "    A blended image Tensor of type uint8.\n",
        "  \"\"\"\n",
        "  if factor == 0.0:\n",
        "    return tf.convert_to_tensor(image1)\n",
        "  if factor == 1.0:\n",
        "    return tf.convert_to_tensor(image2)\n",
        " \n",
        "  image1 = tf.cast(image1, dtype=tf.float32)\n",
        "  image2 = tf.cast(image2, dtype=tf.float32)\n",
        " \n",
        "  difference = image2 - image1\n",
        "  scaled = factor * difference\n",
        " \n",
        "  # Do addition in float.\n",
        "  temp = tf.cast(image1, dtype=tf.float32) + scaled\n",
        " \n",
        "  # Interpolate\n",
        "  if factor > 0.0 and factor < 1.0:\n",
        "    # Interpolation means we always stay within 0 and 255.\n",
        "    return tf.cast(temp, tf.uint8)\n",
        " \n",
        "  # Extrapolate:\n",
        "  #\n",
        "  # We need to clip and then cast.\n",
        "  return tf.cast(tf.clip_by_value(temp, 0.0, 255.0), tf.uint8)\n",
        "def Identity(image, _):\n",
        "    return image\n",
        "#Identity(test_image, 3)\n",
        "def AutoContrast(image, _):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        " \n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), dtype = tf.float32)\n",
        "    hi = tf.cast(tf.reduce_max(image), dtype = tf.float32)\n",
        " \n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "        scale = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale\n",
        "        im = tf.cast(im, dtype=tf.float32) * scale + offset\n",
        "        im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "        return tf.cast(im, tf.uint8)\n",
        " \n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        " \n",
        "AutoContrast(test_image, 3)\n",
        "def Equalize(image, _):\n",
        "  \"\"\"Implements Equalize function from PIL using TF ops.\"\"\"\n",
        "  def scale_channel(im, c):\n",
        "    \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n",
        "    im = tf.cast(im[:, :, c], tf.int32)\n",
        "    # Compute the histogram of the image channel.\n",
        "    histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
        " \n",
        "    # For the purposes of computing the step, filter out the nonzeros.\n",
        "    nonzero = tf.where(tf.not_equal(histo, 0))\n",
        "    nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
        "    step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
        " \n",
        "    def build_lut(histo, step):\n",
        "      # Compute the cumulative sum, shifting by step // 2\n",
        "      # and then normalization by step.\n",
        "      lut = (tf.cumsum(histo) + (step // 2)) // step\n",
        "      # Shift lut, prepending with 0.\n",
        "      lut = tf.concat([[0], lut[:-1]], 0)\n",
        "      # Clip the counts to be in range.  This is done\n",
        "      # in the C code for image.point.\n",
        "      return tf.clip_by_value(lut, 0, 255)\n",
        " \n",
        "    # If step is zero, return the original image.  Otherwise, build\n",
        "    # lut from the full histogram and step and then index from it.\n",
        "    result = tf.cond(tf.equal(step, 0),\n",
        "                     lambda: im,\n",
        "                     lambda: tf.gather(build_lut(histo, step), im))\n",
        " \n",
        "    return tf.cast(result, tf.uint8)\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image, 0)\n",
        "  s2 = scale_channel(image, 1)\n",
        "  s3 = scale_channel(image, 2)\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "Equalize(test_image, 1)\n",
        "def Rotate(image, degrees):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees = int(degrees)\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        " \n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  #image = contrib_image.rotate(wrap(image), radians)\n",
        "  image = tfa.image.rotate(image, radians)\n",
        "  #return unwrap(image, replace)\n",
        "  return image\n",
        "Rotate(test_image, 30.1)\n",
        "def Solarize(image, threshold=128):\n",
        "  # For each pixel in the image, select the pixel\n",
        "  # if the value is less than the threshold.\n",
        "  # Otherwise, subtract 255 from the pixel.\n",
        "  #image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
        "  #print(image)\n",
        "  \n",
        "  threshold = tf.cast(threshold, dtype=tf.uint8)\n",
        "  #print(threshold)\n",
        "  minus_value = tf.constant(255, dtype=tf.uint8)\n",
        "  #print(minus_value)\n",
        "  return tf.where(image < threshold, image, minus_value - image)\n",
        "Solarize(test_image, 10.0)\n",
        "def Color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  #factor = tf.cast(factor, dtype=tf.float32)\n",
        "  return blend(degenerate, image, factor)\n",
        "Color(test_image, 10.1)\n",
        " \n",
        " \n",
        " \n",
        "def Posterize(image, bits):\n",
        " \n",
        "  bits=int(bits)\n",
        "  #print(bits)\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  #print(shift)\n",
        "  #print(image)\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "Posterize(test_image, 1.1)\n",
        "def Contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        " \n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "Contrast(test_image, 10.1)\n",
        "def Brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "Brightness(test_image, 10.1)\n",
        "def _sharpness_image(image, factor):\n",
        "    orig_image = image\n",
        "    image_dtype = image.dtype\n",
        "    image_channels = image.shape[-1]\n",
        "    image = tf.cast(image, tf.float32)\n",
        " \n",
        "    # SMOOTH PIL Kernel.\n",
        "    kernel = (\n",
        "        tf.constant(\n",
        "            [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32, shape=[3, 3, 1, 1]\n",
        "        )\n",
        "        / 13.0\n",
        "    )\n",
        "    kernel = tf.tile(kernel, [1, 1, image_channels, 1])\n",
        " \n",
        "    # Apply kernel channel-wise.\n",
        "    degenerate = tf.nn.depthwise_conv2d(\n",
        "        image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\", dilations=[1, 1]\n",
        "    )\n",
        "    degenerate = tf.cast(degenerate, image_dtype)\n",
        " \n",
        "    # For the borders of the resulting image, fill in the values of the original image.\n",
        "    mask = tf.ones_like(degenerate)\n",
        "    padded_mask = tf.pad(mask, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    padded_degenerate = tf.pad(degenerate, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
        " \n",
        "    # Blend the final result.\n",
        "    blended = blend(result, orig_image, factor)\n",
        "    return tf.cast(blended, image_dtype)\n",
        " \n",
        " \n",
        "def Sharpness(image, factor):\n",
        "    \n",
        "        image_dims = tf.rank(image)\n",
        "        image = to_4D_image(image)\n",
        "        image = _sharpness_image(image, factor=factor)\n",
        "        return from_4D_image(image, image_dims)\n",
        "    #return tfa.image.sharpness(image, factor)\n",
        "Sharpness(test_image, 10.1)\n",
        " \n",
        "def ShearX(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"\n",
        "  # Shear parallel to x axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  level\n",
        "  #  0  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  \n",
        "  return tfa.image.shear_x(image, level, 0)\n",
        "ShearX(test_image,10)\n",
        "def ShearY(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"\n",
        "  # Shear parallel to y axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  0\n",
        "  #  level  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.shear_y(image, level, 0)\n",
        "ShearX(test_image,20)\n",
        "def wrap(image):\n",
        "  \"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
        "  extended = tf.concat([image, extended_channel], 2)\n",
        "  return extended\n",
        " \n",
        "def unwrap(image, replace):\n",
        "  \"\"\"Unwraps an image produced by wrap.\n",
        "  Where there is a 0 in the last channel for every spatial position,\n",
        "  the rest of the three channels in that spatial dimension are grayed\n",
        "  (set to 128).  Operations like translate and shear on a wrapped\n",
        "  Tensor will leave 0s in empty locations.  Some transformations look\n",
        "  at the intensity of values to do preprocessing, and we want these\n",
        "  empty pixels to assume the 'average' value, rather than pure black.\n",
        "  Args:\n",
        "    image: A 3D Image Tensor with 4 channels.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels.\n",
        "  Returns:\n",
        "    image: A 3D image Tensor with 3 channels.\n",
        "  \"\"\"\n",
        "  image_shape = tf.shape(image)\n",
        "  # Flatten the spatial dimensions.\n",
        "  flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
        " \n",
        "  # Find all pixels where the last channel is zero.\n",
        "  alpha_channel = flattened_image[:, 3]\n",
        " \n",
        "  replace = tf.concat([replace, tf.ones([1], image.dtype)], 0)\n",
        " \n",
        "  # Where they are zero, fill them in with 'replace'.\n",
        "  flattened_image = tf.where(\n",
        "      tf.equal(alpha_channel, 0),\n",
        "      tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
        "      flattened_image)\n",
        " \n",
        "  image = tf.reshape(flattened_image, image_shape)\n",
        "  image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], 3])\n",
        "  return image\n",
        " \n",
        "def TranslateX(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [-pixels, 0])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [pixels, 0], replace=0)\n",
        "TranslateX(test_image, 10)\n",
        "def TranslateY(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [0, -pixels])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [0, pixels], replace=0)\n",
        "TranslateY(test_image, 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024, 1024, 3), dtype=uint8, numpy=\n",
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[167, 219,  63],\n",
              "        [184, 139,  32],\n",
              "        [  8, 163,  53],\n",
              "        ...,\n",
              "        [226, 225,  36],\n",
              "        [ 65, 240,  40],\n",
              "        [  3, 182,   0]],\n",
              "\n",
              "       [[221,  15,  81],\n",
              "        [134,  89,  66],\n",
              "        [253, 226, 203],\n",
              "        ...,\n",
              "        [100, 159,  51],\n",
              "        [ 92, 168, 188],\n",
              "        [240, 141, 187]],\n",
              "\n",
              "       [[ 64,  40,  60],\n",
              "        [153,  57, 138],\n",
              "        [196, 221,  46],\n",
              "        ...,\n",
              "        [ 56,  31, 204],\n",
              "        [121, 162, 178],\n",
              "        [197,  19,  52]]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws5Tg2JZpE7g"
      },
      "source": [
        "class RandomResizedCrop:\n",
        "    \"\"\"Torchvision's variant of crop a random part of the input and rescale it to some size.\n",
        "    Args:\n",
        "        height (int): height after crop and resize.\n",
        "        width (int): width after crop and resize.\n",
        "        scale ((float, float)): range of size of the origin size cropped\n",
        "        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped\n",
        "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
        "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
        "            Default: cv2.INTER_LINEAR.\n",
        "        p (float): probability of applying the transform. Default: 1.\n",
        "    Targets:\n",
        "        image, mask, bboxes, keypoints\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        org_height,\n",
        "        org_width,\n",
        "        scale=(0.08, 1.0),\n",
        "        ratio=(0.75, 1.3333333333333333),\n",
        "    ):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.scale = scale\n",
        "        self.ratio = ratio\n",
        "        self.beforeheight = org_height\n",
        "        self.beforewidth = org_width\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start):\n",
        "        x1 = int((height - crop_height) * h_start)\n",
        "        x2 = x1 + crop_height\n",
        "        y1 = int((width - crop_width) * w_start)\n",
        "        y2 = y1 + crop_width\n",
        "        return x1, y1, x2, y2\n",
        "    \n",
        "    def __call__(self, img):\n",
        "\n",
        "        \n",
        "        area = img.shape[0] * img.shape[1]\n",
        "        #print(img.shape[0], img.shape[1])\n",
        "        for _attempt in range(10):\n",
        "            target_area = random.uniform(*self.scale) * area\n",
        "            log_ratio = (math.log(self.ratio[0]), math.log(self.ratio[1]))\n",
        "            aspect_ratio = math.exp(random.uniform(*log_ratio))\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            #print(w, h)\n",
        "            if 0 < w <= img.shape[1] and 0 < h <= img.shape[0]:\n",
        "                i = random.randint(0, img.shape[0] - h)\n",
        "                j = random.randint(0, img.shape[1] - w)\n",
        "                h_start = i * 1.0 / (img.shape[0] - h + 1e-10)\n",
        "                w_start = j * 1.0 / (img.shape[1] - w + 1e-10)\n",
        "                #print(h, w)\n",
        "                x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, h_start, w_start)\n",
        "                #print(h, w)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                img = img[x1:x2, y1:y2, :]\n",
        "                img = tf.image.resize(img, (self.height, self.width))\n",
        "                return tf.cast(img, dtype=tf.uint8)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        #print('central gogo')\n",
        "        in_ratio = img.shape[1] / img.shape[0]\n",
        "        if in_ratio < min(self.ratio):\n",
        "            w = img.shape[1]\n",
        "            h = int(round(w / min(self.ratio)))\n",
        "        elif in_ratio > max(self.ratio):\n",
        "            h = img.shape[0]\n",
        "            w = int(round(h * max(self.ratio)))\n",
        "        else:  # whole image\n",
        "            w = img.shape[1]\n",
        "            h = img.shape[0]\n",
        "        i = (img.shape[0] - h) // 2\n",
        "        j = (img.shape[1] - w) // 2\n",
        "        x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, i, j)\n",
        "        img = img[x1:x2, y1:y2, :]\n",
        "        img = tf.image.resize(img, (self.height, self.width))\n",
        "        return tf.cast(img, dtype=tf.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDsiU6PE6Zm"
      },
      "source": [
        "class Normalize:\n",
        "    \"\"\"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.\n",
        "    Args:\n",
        "        mean (float, list of float): mean values\n",
        "        std  (float, list of float): std values\n",
        "        max_pixel_value (float): maximum possible pixel value\n",
        "    Targets:\n",
        "        image\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mean=CFG.MEAN, std=CFG.STD, max_pixel_value=255.0, always_apply=False, p=1.0\n",
        "    ):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.max_pixel_value = max_pixel_value\n",
        "\n",
        "\n",
        "    \n",
        "    def normalize_image(self, img, mean, std, max_pixel_value=255.0):\n",
        "        mean = tf.convert_to_tensor(mean, dtype=tf.float32)\n",
        "        mean = mean * max_pixel_value\n",
        "\n",
        "        std = tf.convert_to_tensor(std, dtype=tf.float32)\n",
        "        std = std * max_pixel_value\n",
        "\n",
        "        denominator = tf.math.reciprocal(std)\n",
        "\n",
        "        #print('before cast', img)\n",
        "        img = tf.cast(img, dtype = tf.float32)\n",
        "        #print('after cast', img)\n",
        "        #img = img - mean\n",
        "        #img = img * denominator\n",
        "        img = img / 255.\n",
        "        return img\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.normalize_image(img, self.mean, self.std)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivUmviTzRd6"
      },
      "source": [
        "class CoarseDropout:\n",
        "  def __init__(self, max_holes, size=0.06):\n",
        "    self.size = size\n",
        "    self.max_holes = max_holes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __call__(self, image):\n",
        "      #holes = []\n",
        "      P = random.uniform(0,1)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      for _n in range(self.max_holes):\n",
        "          hole_height = height * self.size * P\n",
        "          hole_width = width * self.size * P\n",
        "          hole_height = int(hole_height)\n",
        "          hole_width = int(hole_width)\n",
        "          y1 = random.randint(0, height - hole_height)\n",
        "          x1 = random.randint(0, width- hole_width)\n",
        "          y2 = y1 + hole_height\n",
        "          x2 = x1 + hole_width\n",
        "          #holes.append((y1, x1, y2, x2))\n",
        "        \n",
        "          one = image[y1:y2,0:x1,:]\n",
        "          two = tf.zeros([y2-y1,x2-x1,3], dtype=tf.uint8) \n",
        "          three = image[y1:y2,x2:width,:]\n",
        "          middle = tf.concat([one,two,three],axis=1)\n",
        "          image = tf.concat([image[0:y1,:,:],middle,image[y2:height,:,:]],axis=0)\n",
        "      \n",
        "          \n",
        "      image = tf.cast(image, dtype=tf.uint8)\n",
        "      return image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtmKcRRnLJS"
      },
      "source": [
        "def augment_list():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        (Rotate, -30, 30),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        (ShearX, -0.2, 0.2),\n",
        "        (ShearY, -0.2, 0.2),\n",
        "        (TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        (TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyHDbDpnfBk"
      },
      "source": [
        "import random\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqGkm0mLoW0"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    #print(image.shape, label.shape)\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    cutmix_start = 0.0\n",
        "    imgs = []; labs = []\n",
        "    \n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],cutmix_start,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM2),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM1),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)\n",
        "        b = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM2 * tf.math.sqrt(1-a),tf.int32) * P\n",
        "        HEIGHT = tf.cast( DIM1 * tf.math.sqrt(1-b), tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-HEIGHT//2)\n",
        "        yb = tf.math.minimum(DIM1,y+HEIGHT//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM2,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM2,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        cutmix_img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM1,:,:]],axis=0)\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_left_right(cutmix_img)\n",
        "        if p_v_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_up_down(cutmix_img)\n",
        "        if p_transpose > 0.5:\n",
        "            cutmix_img = tf.image.transpose(cutmix_img)\n",
        "        #cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #cutmix_img = tf.image.resize(cutmix_img, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #mixup_image = (1-a)*img1 + a*img2\n",
        "        cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #imgs.append(mixup_image)\n",
        "        imgs.append(cutmix_img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*HEIGHT/DIM1/DIM2,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2\n",
        " \n",
        " \n",
        " \n",
        "def mixup(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with mixup applied\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
        "        # CHOOSE RANDOM\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)*P # this is beta dist with alpha=1.0\n",
        "        # MAKE MIXUP IMAGE\n",
        "        img1 = image[j,]\n",
        "        img2 = image[k,]\n",
        "        #mixup_image = (1-0.5)*img1 + 0.5*img2\n",
        "        mixup_image = (1-a)*img1 + a*img2\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            mixup_image = tf.image.flip_left_right(mixup_image)\n",
        "        #if p_v_flip > 0.5:\n",
        "        #    mixup_image = tf.image.flip_up_down(mixup_image)\n",
        "        #if p_transpose > 0.5:\n",
        "        #    mixup_image = tf.image.transpose(mixup_image)\n",
        "        mixup_image = Normalize(CFG.MEAN, CFG.STD)(mixup_image)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        imgs.append(mixup_image)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxFwBse-yv"
      },
      "source": [
        "def real_data_augment(image, label):\n",
        "    k = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    if k < 0.33:\n",
        "        image2, label2 = mixup(image, label)\n",
        "    #elif (k >= -2) and (k < 0):\n",
        "    #    image2, label2 = cutmix(image, label)\n",
        "    else:\n",
        "        image2, label2 = data_augment(image, label)\n",
        " \n",
        "    return image2, label2 \n",
        " \n",
        "def prep_for_val(image, label):\n",
        "    \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(30)\n",
        "    #randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.85, 1.0))\n",
        " \n",
        "    #P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            img = tf.image.resize(img, [DIM1, DIM2])\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        " \n",
        " \n",
        "def data_augment(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(1)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.95, 1.0))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        " \n",
        "            img = randomcrop(img)\n",
        " \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            #if p_v_flip >= 0.5:\n",
        "            #    img = tf.image.flip_up_down(img)\n",
        "            #if p_transpose >= 0.5:\n",
        "            #    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "            #        img = tf.image.transpose(img)\n",
        " \n",
        "            #img = coarse(img)\n",
        "            img = randaug(img)\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECrHNVz2S4Dk",
        "outputId": "570227e0-3d2a-4dae-cf4c-db46fdbda1a3"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8RTuBuSEpg"
      },
      "source": [
        "def decode_tr_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    \n",
        "    return image\n",
        " \n",
        "def decode_val_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    label = tf.reshape(label, [CFG.NUMBER_OF_CLASSES])\n",
        "    return image, label\n",
        "\n",
        "def decode_test_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def decode_just_test_image(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def decode_val_image_for_tta(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.99,1.0))\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = randomcrop(image)\n",
        "    if p_flip > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    if p_v_flip > 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "        if p_transpose > 0.5:\n",
        "            image = tf.image.transpose(image)\n",
        "    image = normalize(image) \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def read_tfrecord(example, labeled=True):\n",
        "    \"\"\"\n",
        "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
        "        2. Decode image.\n",
        "        3. If 'labeled' returns (image, label) if not (image, name).\n",
        "    \"\"\"\n",
        "    if labeled:\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'label': tf.io.VarLenFeature(dtype=tf.float32), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], tf.sparse.to_dense(example['label'])\n",
        "    else:\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], example['image_id']\n",
        "\n",
        "def read_test_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], example['image_id']\n",
        "\n",
        "def read_test_image_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw']\n",
        " \n",
        "def load_dataset(filenames, validation, labeled=True, ordered=False, ):\n",
        "    \"\"\"\n",
        "        Create a Tensorflow dataset from TFRecords.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        " \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    if validation == False:\n",
        " \n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = False), num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = True), num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if (validation == True) and (labeled == False):\n",
        "        pass\n",
        "    elif (validation == False) and (labeled == True):\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : decode_val_image(image, label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    #else:\n",
        "    #        dataset = dataset.map(prep_for_val, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_test_dataset(FILENAMES, return_image_name=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()   \n",
        "    \n",
        "    \n",
        "    if return_image_name:\n",
        "        dataset = dataset.map(lambda example : read_test_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image, label : decode_test_image(image, label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_test_image_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image : decode_just_test_image(image), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    #dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset_for_tta(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if validation == False:\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVAoSVZoB-1"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    print(n)\n",
        "    return np.sum(n)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDqawNTsn1vX"
      },
      "source": [
        "from tensorflow_addons.utils.types import FloatTensorLike\n",
        " \n",
        "from typing import Union, Callable, Dict\n",
        "from typeguard import typechecked\n",
        " \n",
        " \n",
        "class CosineDecayRAdam(tfa.optimizers.RectifiedAdam):\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype)\n",
        "        wd_t = self._decayed_wd(var_dtype)\n",
        "        m = self.get_slot(var, \"m\")\n",
        "        v = self.get_slot(var, \"v\")\n",
        "        beta_1_t = self._get_hyper(\"beta_1\", var_dtype)\n",
        "        beta_2_t = self._get_hyper(\"beta_2\", var_dtype)\n",
        "        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_power = tf.pow(beta_1_t, local_step)\n",
        "        beta_2_power = tf.pow(beta_2_t, local_step)\n",
        " \n",
        "        if self._initial_total_steps > 0:\n",
        "            total_steps = self._get_hyper(\"total_steps\", var_dtype)\n",
        "            warmup_steps = total_steps * self._get_hyper(\"warmup_proportion\", var_dtype)\n",
        "            min_lr = self._get_hyper(\"min_lr\", var_dtype)\n",
        "            decay_steps = tf.maximum(total_steps - warmup_steps, 1)\n",
        "            decay_rate = (min_lr - lr_t) / decay_steps\n",
        "            pi = tf.constant(3.141592)\n",
        "            cos = tf.math.cos(pi * ((local_step - warmup_steps) / (total_steps - warmup_steps))) + tf.constant(1.)\n",
        "            lr_t = tf.where(\n",
        "                local_step <= warmup_steps,\n",
        "                lr_t * (local_step / warmup_steps),\n",
        "                #lr_t + decay_rate * tf.minimum(local_step - warmup_steps, decay_steps),\n",
        "                min_lr + (lr_t - min_lr) / 2. * cos\n",
        "            )\n",
        " \n",
        "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
        "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
        " \n",
        "        m_t = m.assign(\n",
        "            beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking\n",
        "        )\n",
        "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
        " \n",
        "        v_t = v.assign(\n",
        "            beta_2_t * v + (1.0 - beta_2_t) * tf.square(grad),\n",
        "            use_locking=self._use_locking,\n",
        "        )\n",
        "        if self.amsgrad:\n",
        "            vhat = self.get_slot(var, \"vhat\")\n",
        "            vhat_t = vhat.assign(tf.maximum(vhat, v_t), use_locking=self._use_locking)\n",
        "            v_corr_t = tf.sqrt(vhat_t / (1.0 - beta_2_power))\n",
        "        else:\n",
        "            vhat_t = None\n",
        "            v_corr_t = tf.sqrt(v_t / (1.0 - beta_2_power))\n",
        " \n",
        "        r_t = tf.sqrt(\n",
        "            (sma_t - 4.0)\n",
        "            / (sma_inf - 4.0)\n",
        "            * (sma_t - 2.0)\n",
        "            / (sma_inf - 2.0)\n",
        "            * sma_inf\n",
        "            / sma_t\n",
        "        )\n",
        " \n",
        "        sma_threshold = self._get_hyper(\"sma_threshold\", var_dtype)\n",
        "        var_t = tf.where(\n",
        "            sma_t >= sma_threshold, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t\n",
        "        )\n",
        " \n",
        "        if self._has_weight_decay:\n",
        "            var_t += wd_t * var\n",
        " \n",
        "        var_update = var.assign_sub(lr_t * var_t, use_locking=self._use_locking)\n",
        " \n",
        "        updates = [var_update, m_t, v_t]\n",
        "        if self.amsgrad:\n",
        "            updates.append(vhat_t)\n",
        "        return tf.group(*updates)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZCnkM3BCN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2623902-e615-4f4a-f5de-ccd11cb21d36"
      },
      "source": [
        "LEARNING_RATE = 1e-5 * REPLICAS # -> LB->8921\n",
        " \n",
        "# RandomCropedSized FIX\n",
        "# Cosine Decay Radam\n",
        " \n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; normal_oof_pred = []; pred_max = []\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "seed_everything(SEED)\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    TRAINING_IMAGES = TRAINING_FILENAMES\n",
        " \n",
        "    train_dataset = get_dataset(TRAINING_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True, validation=False)\n",
        "    val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        " \n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tf.keras.backend.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"), \n",
        "                                                    monitor = 'val_auc', \n",
        "                                                    save_best_only = True,\n",
        "                                                    mode = 'max')\n",
        "    history = model.fit(train_dataset,  \n",
        "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                        epochs = CFG.EPOCHS,\n",
        "                        callbacks = [checkpoint],\n",
        "                        validation_data = val_dataset,\n",
        "                        verbose = 1,\n",
        "                        ).history\n",
        "    print(f\"#### FOLD {fold+1} without TTA VAL_AUC = {np.max(history['val_auc']):.3f}\")\n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
            "71680000/71678424 [==============================] - 2s 0us/step\n",
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 481s 1s/step - loss: 0.6916 - auc: 0.4895 - val_loss: 0.6862 - val_auc: 0.5121\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 937ms/step - loss: 0.6024 - auc: 0.5022 - val_loss: 0.5637 - val_auc: 0.5724\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.3572 - auc: 0.5427 - val_loss: 0.2910 - val_auc: 0.7030\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.2557 - auc: 0.6872 - val_loss: 0.2582 - val_auc: 0.8274\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.1980 - auc: 0.8011 - val_loss: 0.2610 - val_auc: 0.8692\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1759 - auc: 0.8231 - val_loss: 0.1835 - val_auc: 0.8951\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1665 - auc: 0.8106 - val_loss: 0.2098 - val_auc: 0.9018\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1535 - auc: 0.8148 - val_loss: 0.1574 - val_auc: 0.9159\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1514 - auc: 0.8314 - val_loss: 0.1476 - val_auc: 0.9251\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1423 - auc: 0.8527 - val_loss: 0.1310 - val_auc: 0.9319\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1395 - auc: 0.8631 - val_loss: 0.1291 - val_auc: 0.9319\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1413 - auc: 0.8305 - val_loss: 0.1220 - val_auc: 0.9358\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1422 - auc: 0.8354 - val_loss: 0.1177 - val_auc: 0.9412\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1275 - auc: 0.8730 - val_loss: 0.1156 - val_auc: 0.9396\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1330 - auc: 0.8396 - val_loss: 0.1202 - val_auc: 0.9338\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1216 - auc: 0.8727 - val_loss: 0.1108 - val_auc: 0.9427\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1325 - auc: 0.8288 - val_loss: 0.1080 - val_auc: 0.9456\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1242 - auc: 0.8672 - val_loss: 0.1138 - val_auc: 0.9487\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1168 - auc: 0.8372 - val_loss: 0.1087 - val_auc: 0.9448\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1119 - auc: 0.8753 - val_loss: 0.1118 - val_auc: 0.9465\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1117 - auc: 0.8886 - val_loss: 0.1245 - val_auc: 0.9374\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1103 - auc: 0.8693 - val_loss: 0.1101 - val_auc: 0.9480\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1042 - auc: 0.8922 - val_loss: 0.1103 - val_auc: 0.9415\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1062 - auc: 0.8831 - val_loss: 0.1088 - val_auc: 0.9457\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1046 - auc: 0.8650 - val_loss: 0.1038 - val_auc: 0.9510\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1045 - auc: 0.8600 - val_loss: 0.1055 - val_auc: 0.9527\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1041 - auc: 0.8742 - val_loss: 0.1066 - val_auc: 0.9505\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0981 - auc: 0.8907 - val_loss: 0.1016 - val_auc: 0.9538\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0919 - auc: 0.8917 - val_loss: 0.1054 - val_auc: 0.9509\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0911 - auc: 0.9174 - val_loss: 0.1012 - val_auc: 0.9520\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0891 - auc: 0.8957 - val_loss: 0.1158 - val_auc: 0.9473\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0883 - auc: 0.9099 - val_loss: 0.1041 - val_auc: 0.9516\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0882 - auc: 0.9067 - val_loss: 0.1037 - val_auc: 0.9535\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0894 - auc: 0.8761 - val_loss: 0.1059 - val_auc: 0.9515\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 954ms/step - loss: 0.0769 - auc: 0.9397 - val_loss: 0.1082 - val_auc: 0.9492\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0855 - auc: 0.8815 - val_loss: 0.1069 - val_auc: 0.9508\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0820 - auc: 0.9009 - val_loss: 0.1086 - val_auc: 0.9508\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0822 - auc: 0.8912 - val_loss: 0.1082 - val_auc: 0.9491\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0829 - auc: 0.8995 - val_loss: 0.1054 - val_auc: 0.9505\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0766 - auc: 0.9139 - val_loss: 0.1078 - val_auc: 0.9483\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0841 - auc: 0.8784 - val_loss: 0.1089 - val_auc: 0.9470\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.0833 - auc: 0.8838 - val_loss: 0.1069 - val_auc: 0.9492\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0796 - auc: 0.8923 - val_loss: 0.1082 - val_auc: 0.9478\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.0732 - auc: 0.9253 - val_loss: 0.1097 - val_auc: 0.9480\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0748 - auc: 0.9053 - val_loss: 0.1101 - val_auc: 0.9470\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0793 - auc: 0.8957 - val_loss: 0.1102 - val_auc: 0.9465\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0753 - auc: 0.9044 - val_loss: 0.1095 - val_auc: 0.9478\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0791 - auc: 0.8875 - val_loss: 0.1098 - val_auc: 0.9484\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0773 - auc: 0.9046 - val_loss: 0.1099 - val_auc: 0.9482\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0743 - auc: 0.9106 - val_loss: 0.1099 - val_auc: 0.9475\n",
            "#### FOLD 1 without TTA VAL_AUC = 0.954\n",
            "[1490, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 486s 1s/step - loss: 0.6992 - auc: 0.4972 - val_loss: 0.6909 - val_auc: 0.5220\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 938ms/step - loss: 0.6134 - auc: 0.5025 - val_loss: 0.5548 - val_auc: 0.5552\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.3664 - auc: 0.5428 - val_loss: 0.2877 - val_auc: 0.6765\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.2566 - auc: 0.6801 - val_loss: 0.2456 - val_auc: 0.7953\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.2080 - auc: 0.7887 - val_loss: 0.2139 - val_auc: 0.8531\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1789 - auc: 0.8202 - val_loss: 0.1756 - val_auc: 0.8880\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1680 - auc: 0.8014 - val_loss: 0.1647 - val_auc: 0.9046\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1640 - auc: 0.8163 - val_loss: 0.1509 - val_auc: 0.9174\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1572 - auc: 0.8195 - val_loss: 0.1426 - val_auc: 0.9246\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1447 - auc: 0.8421 - val_loss: 0.1532 - val_auc: 0.9290\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.1425 - auc: 0.8700 - val_loss: 0.1303 - val_auc: 0.9355\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1449 - auc: 0.8422 - val_loss: 0.1318 - val_auc: 0.9387\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1494 - auc: 0.8121 - val_loss: 0.1238 - val_auc: 0.9421\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1343 - auc: 0.8688 - val_loss: 0.1218 - val_auc: 0.9431\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1346 - auc: 0.8417 - val_loss: 0.1194 - val_auc: 0.9463\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 52s 998ms/step - loss: 0.1304 - auc: 0.8667 - val_loss: 0.1184 - val_auc: 0.9469\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1358 - auc: 0.8423 - val_loss: 0.1195 - val_auc: 0.9426\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1239 - auc: 0.8736 - val_loss: 0.1165 - val_auc: 0.9493\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1251 - auc: 0.8458 - val_loss: 0.1179 - val_auc: 0.9494\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 47s 901ms/step - loss: 0.1158 - auc: 0.8729 - val_loss: 0.1111 - val_auc: 0.9551\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.1149 - auc: 0.8912 - val_loss: 0.1098 - val_auc: 0.9557\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1163 - auc: 0.8682 - val_loss: 0.1125 - val_auc: 0.9563\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1117 - auc: 0.9012 - val_loss: 0.1120 - val_auc: 0.9519\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1107 - auc: 0.8791 - val_loss: 0.1100 - val_auc: 0.9526\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1159 - auc: 0.8657 - val_loss: 0.1108 - val_auc: 0.9557\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1129 - auc: 0.8616 - val_loss: 0.1089 - val_auc: 0.9584\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1119 - auc: 0.8540 - val_loss: 0.1080 - val_auc: 0.9567\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1009 - auc: 0.8929 - val_loss: 0.1109 - val_auc: 0.9567\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0987 - auc: 0.8961 - val_loss: 0.1188 - val_auc: 0.9499\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0934 - auc: 0.9163 - val_loss: 0.1145 - val_auc: 0.9518\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1004 - auc: 0.8952 - val_loss: 0.1137 - val_auc: 0.9516\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 901ms/step - loss: 0.0955 - auc: 0.8937 - val_loss: 0.1153 - val_auc: 0.9492\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0949 - auc: 0.9004 - val_loss: 0.1160 - val_auc: 0.9511\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0957 - auc: 0.8828 - val_loss: 0.1184 - val_auc: 0.9490\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0821 - auc: 0.9366 - val_loss: 0.1160 - val_auc: 0.9520\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0926 - auc: 0.8662 - val_loss: 0.1145 - val_auc: 0.9492\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0854 - auc: 0.8986 - val_loss: 0.1128 - val_auc: 0.9531\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.0874 - auc: 0.8962 - val_loss: 0.1214 - val_auc: 0.9477\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0869 - auc: 0.8901 - val_loss: 0.1170 - val_auc: 0.9488\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0806 - auc: 0.9131 - val_loss: 0.1188 - val_auc: 0.9489\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0891 - auc: 0.8735 - val_loss: 0.1174 - val_auc: 0.9484\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0867 - auc: 0.8792 - val_loss: 0.1140 - val_auc: 0.9487\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0831 - auc: 0.8903 - val_loss: 0.1181 - val_auc: 0.9470\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 46s 894ms/step - loss: 0.0726 - auc: 0.9252 - val_loss: 0.1169 - val_auc: 0.9471\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0759 - auc: 0.9155 - val_loss: 0.1154 - val_auc: 0.9470\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0793 - auc: 0.8844 - val_loss: 0.1168 - val_auc: 0.9471\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0753 - auc: 0.9011 - val_loss: 0.1165 - val_auc: 0.9472\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0795 - auc: 0.8983 - val_loss: 0.1169 - val_auc: 0.9473\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0772 - auc: 0.8955 - val_loss: 0.1168 - val_auc: 0.9470\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 46s 896ms/step - loss: 0.0759 - auc: 0.9029 - val_loss: 0.1168 - val_auc: 0.9470\n",
            "#### FOLD 2 without TTA VAL_AUC = 0.958\n",
            "[1490, 1501, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 487s 1s/step - loss: 0.6921 - auc: 0.4953 - val_loss: 0.6925 - val_auc: 0.5222\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 941ms/step - loss: 0.5998 - auc: 0.4952 - val_loss: 0.5519 - val_auc: 0.5938\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.3480 - auc: 0.5488 - val_loss: 0.2905 - val_auc: 0.6948\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.2510 - auc: 0.6947 - val_loss: 0.2257 - val_auc: 0.8256\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.2000 - auc: 0.7986 - val_loss: 0.1729 - val_auc: 0.8882\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1742 - auc: 0.8260 - val_loss: 0.1620 - val_auc: 0.9049\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1708 - auc: 0.7909 - val_loss: 0.1601 - val_auc: 0.9156\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1623 - auc: 0.8231 - val_loss: 0.1445 - val_auc: 0.9264\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1536 - auc: 0.8297 - val_loss: 0.1391 - val_auc: 0.9274\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1431 - auc: 0.8568 - val_loss: 0.1315 - val_auc: 0.9290\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1483 - auc: 0.8644 - val_loss: 0.1261 - val_auc: 0.9330\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1437 - auc: 0.8317 - val_loss: 0.1246 - val_auc: 0.9345\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1410 - auc: 0.8253 - val_loss: 0.1298 - val_auc: 0.9347\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1321 - auc: 0.8687 - val_loss: 0.1199 - val_auc: 0.9439\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1358 - auc: 0.8467 - val_loss: 0.1218 - val_auc: 0.9394\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 47s 908ms/step - loss: 0.1274 - auc: 0.8764 - val_loss: 0.1216 - val_auc: 0.9386\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1313 - auc: 0.8477 - val_loss: 0.1154 - val_auc: 0.9436\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1225 - auc: 0.8701 - val_loss: 0.1171 - val_auc: 0.9400\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1231 - auc: 0.8520 - val_loss: 0.1111 - val_auc: 0.9474\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1154 - auc: 0.8752 - val_loss: 0.1212 - val_auc: 0.9409\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1161 - auc: 0.8895 - val_loss: 0.1180 - val_auc: 0.9414\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1182 - auc: 0.8771 - val_loss: 0.1080 - val_auc: 0.9497\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1096 - auc: 0.8966 - val_loss: 0.1124 - val_auc: 0.9441\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1070 - auc: 0.8838 - val_loss: 0.1092 - val_auc: 0.9511\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1129 - auc: 0.8711 - val_loss: 0.1239 - val_auc: 0.9311\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1102 - auc: 0.8701 - val_loss: 0.1239 - val_auc: 0.9368\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1123 - auc: 0.8653 - val_loss: 0.1088 - val_auc: 0.9497\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1022 - auc: 0.8967 - val_loss: 0.1146 - val_auc: 0.9456\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0950 - auc: 0.9000 - val_loss: 0.1078 - val_auc: 0.9529\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0957 - auc: 0.9151 - val_loss: 0.1074 - val_auc: 0.9542\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0954 - auc: 0.9009 - val_loss: 0.1079 - val_auc: 0.9537\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 51s 982ms/step - loss: 0.0924 - auc: 0.9047 - val_loss: 0.1075 - val_auc: 0.9568\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0908 - auc: 0.9004 - val_loss: 0.1163 - val_auc: 0.9497\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0960 - auc: 0.8837 - val_loss: 0.1191 - val_auc: 0.9412\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0836 - auc: 0.9374 - val_loss: 0.1127 - val_auc: 0.9512\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0917 - auc: 0.8770 - val_loss: 0.1129 - val_auc: 0.9454\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0850 - auc: 0.9009 - val_loss: 0.1154 - val_auc: 0.9408\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0842 - auc: 0.8891 - val_loss: 0.1164 - val_auc: 0.9465\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0867 - auc: 0.8935 - val_loss: 0.1144 - val_auc: 0.9458\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0803 - auc: 0.9147 - val_loss: 0.1178 - val_auc: 0.9444\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0871 - auc: 0.8816 - val_loss: 0.1138 - val_auc: 0.9463\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0868 - auc: 0.8853 - val_loss: 0.1119 - val_auc: 0.9503\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0791 - auc: 0.8954 - val_loss: 0.1188 - val_auc: 0.9449\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0728 - auc: 0.9262 - val_loss: 0.1164 - val_auc: 0.9461\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0752 - auc: 0.9175 - val_loss: 0.1166 - val_auc: 0.9464\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0829 - auc: 0.8967 - val_loss: 0.1145 - val_auc: 0.9467\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0739 - auc: 0.9174 - val_loss: 0.1160 - val_auc: 0.9462\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0785 - auc: 0.8870 - val_loss: 0.1159 - val_auc: 0.9470\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0770 - auc: 0.8915 - val_loss: 0.1159 - val_auc: 0.9466\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0734 - auc: 0.9094 - val_loss: 0.1164 - val_auc: 0.9467\n",
            "#### FOLD 3 without TTA VAL_AUC = 0.957\n",
            "[1490, 1501, 1500, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 492s 1s/step - loss: 0.6927 - auc: 0.5049 - val_loss: 0.7064 - val_auc: 0.4971\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.6117 - auc: 0.4989 - val_loss: 0.5407 - val_auc: 0.5676\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.3574 - auc: 0.5427 - val_loss: 0.2666 - val_auc: 0.6928\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.2461 - auc: 0.7045 - val_loss: 0.2155 - val_auc: 0.8268\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1919 - auc: 0.7932 - val_loss: 0.1806 - val_auc: 0.8656\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.1721 - auc: 0.8229 - val_loss: 0.1817 - val_auc: 0.8864\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1660 - auc: 0.7988 - val_loss: 0.1742 - val_auc: 0.8919\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1597 - auc: 0.8328 - val_loss: 0.1664 - val_auc: 0.9024\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1540 - auc: 0.8346 - val_loss: 0.1521 - val_auc: 0.9035\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1493 - auc: 0.8448 - val_loss: 0.1404 - val_auc: 0.9200\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1392 - auc: 0.8692 - val_loss: 0.1372 - val_auc: 0.9216\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1435 - auc: 0.8396 - val_loss: 0.1309 - val_auc: 0.9262\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1408 - auc: 0.8302 - val_loss: 0.1230 - val_auc: 0.9334\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1342 - auc: 0.8747 - val_loss: 0.1218 - val_auc: 0.9332\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1339 - auc: 0.8449 - val_loss: 0.1165 - val_auc: 0.9405\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1285 - auc: 0.8672 - val_loss: 0.1152 - val_auc: 0.9441\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1368 - auc: 0.8294 - val_loss: 0.1142 - val_auc: 0.9390\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1243 - auc: 0.8767 - val_loss: 0.1108 - val_auc: 0.9455\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1291 - auc: 0.8507 - val_loss: 0.1156 - val_auc: 0.9424\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1165 - auc: 0.8828 - val_loss: 0.1076 - val_auc: 0.9512\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1187 - auc: 0.8729 - val_loss: 0.1052 - val_auc: 0.9517\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1158 - auc: 0.8664 - val_loss: 0.1067 - val_auc: 0.9519\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1066 - auc: 0.8920 - val_loss: 0.1096 - val_auc: 0.9492\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1118 - auc: 0.8733 - val_loss: 0.1195 - val_auc: 0.9408\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1078 - auc: 0.8696 - val_loss: 0.1075 - val_auc: 0.9493\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1119 - auc: 0.8653 - val_loss: 0.1078 - val_auc: 0.9533\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1104 - auc: 0.8666 - val_loss: 0.1115 - val_auc: 0.9486\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1003 - auc: 0.8936 - val_loss: 0.1087 - val_auc: 0.9534\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0995 - auc: 0.8986 - val_loss: 0.1128 - val_auc: 0.9467\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0954 - auc: 0.9145 - val_loss: 0.1160 - val_auc: 0.9441\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0954 - auc: 0.8913 - val_loss: 0.1106 - val_auc: 0.9479\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0952 - auc: 0.8989 - val_loss: 0.1133 - val_auc: 0.9470\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0915 - auc: 0.9090 - val_loss: 0.1160 - val_auc: 0.9447\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 954ms/step - loss: 0.0982 - auc: 0.8767 - val_loss: 0.1136 - val_auc: 0.9462\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0821 - auc: 0.9408 - val_loss: 0.1173 - val_auc: 0.9489\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0966 - auc: 0.8731 - val_loss: 0.1106 - val_auc: 0.9511\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0876 - auc: 0.9089 - val_loss: 0.1104 - val_auc: 0.9514\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0868 - auc: 0.9021 - val_loss: 0.1145 - val_auc: 0.9464\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0846 - auc: 0.8983 - val_loss: 0.1141 - val_auc: 0.9454\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0774 - auc: 0.9116 - val_loss: 0.1144 - val_auc: 0.9456\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 47s 904ms/step - loss: 0.0875 - auc: 0.8764 - val_loss: 0.1170 - val_auc: 0.9429\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0832 - auc: 0.8774 - val_loss: 0.1134 - val_auc: 0.9457\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0812 - auc: 0.8837 - val_loss: 0.1151 - val_auc: 0.9454\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0698 - auc: 0.9306 - val_loss: 0.1159 - val_auc: 0.9444\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 52s 1s/step - loss: 0.0741 - auc: 0.9043 - val_loss: 0.1155 - val_auc: 0.9445\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.0790 - auc: 0.8946 - val_loss: 0.1150 - val_auc: 0.9459\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0736 - auc: 0.9131 - val_loss: 0.1156 - val_auc: 0.9453\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0768 - auc: 0.8811 - val_loss: 0.1155 - val_auc: 0.9456\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0750 - auc: 0.8985 - val_loss: 0.1154 - val_auc: 0.9455\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0737 - auc: 0.9081 - val_loss: 0.1156 - val_auc: 0.9454\n",
            "#### FOLD 4 without TTA VAL_AUC = 0.953\n",
            "[1490, 1501, 1500, 1495, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 487s 1s/step - loss: 0.6967 - auc: 0.4969 - val_loss: 0.6499 - val_auc: 0.5019\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.6061 - auc: 0.4909 - val_loss: 0.5422 - val_auc: 0.5686\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.3525 - auc: 0.5444 - val_loss: 0.2939 - val_auc: 0.7118\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.2520 - auc: 0.7072 - val_loss: 0.2128 - val_auc: 0.8278\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.2019 - auc: 0.7985 - val_loss: 0.1968 - val_auc: 0.8601\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1716 - auc: 0.8161 - val_loss: 0.1639 - val_auc: 0.8933\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1735 - auc: 0.7976 - val_loss: 0.1567 - val_auc: 0.9115\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1569 - auc: 0.8251 - val_loss: 0.1492 - val_auc: 0.9212\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1554 - auc: 0.8330 - val_loss: 0.1437 - val_auc: 0.9290\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1467 - auc: 0.8329 - val_loss: 0.1590 - val_auc: 0.9336\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1414 - auc: 0.8763 - val_loss: 0.1276 - val_auc: 0.9363\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1498 - auc: 0.8228 - val_loss: 0.1239 - val_auc: 0.9402\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1441 - auc: 0.8321 - val_loss: 0.1282 - val_auc: 0.9422\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1320 - auc: 0.8656 - val_loss: 0.1191 - val_auc: 0.9462\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.1403 - auc: 0.8410 - val_loss: 0.1147 - val_auc: 0.9487\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1308 - auc: 0.8763 - val_loss: 0.1217 - val_auc: 0.9484\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1327 - auc: 0.8409 - val_loss: 0.1084 - val_auc: 0.9505\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1274 - auc: 0.8671 - val_loss: 0.1073 - val_auc: 0.9524\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 47s 907ms/step - loss: 0.1321 - auc: 0.8435 - val_loss: 0.1031 - val_auc: 0.9569\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1194 - auc: 0.8767 - val_loss: 0.1041 - val_auc: 0.9516\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1170 - auc: 0.8841 - val_loss: 0.1024 - val_auc: 0.9539\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1163 - auc: 0.8767 - val_loss: 0.1096 - val_auc: 0.9558\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1081 - auc: 0.9051 - val_loss: 0.0984 - val_auc: 0.9581\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1111 - auc: 0.8877 - val_loss: 0.1013 - val_auc: 0.9547\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1139 - auc: 0.8641 - val_loss: 0.1024 - val_auc: 0.9551\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1132 - auc: 0.8643 - val_loss: 0.1017 - val_auc: 0.9550\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1165 - auc: 0.8592 - val_loss: 0.0995 - val_auc: 0.9602\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1047 - auc: 0.8911 - val_loss: 0.0990 - val_auc: 0.9569\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0993 - auc: 0.9031 - val_loss: 0.1022 - val_auc: 0.9558\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0955 - auc: 0.9156 - val_loss: 0.0987 - val_auc: 0.9579\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0999 - auc: 0.8944 - val_loss: 0.1042 - val_auc: 0.9579\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.0960 - auc: 0.8996 - val_loss: 0.0993 - val_auc: 0.9596\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0942 - auc: 0.9039 - val_loss: 0.1024 - val_auc: 0.9574\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 48s 921ms/step - loss: 0.0953 - auc: 0.8844 - val_loss: 0.0997 - val_auc: 0.9588\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0836 - auc: 0.9360 - val_loss: 0.1019 - val_auc: 0.9561\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0939 - auc: 0.8779 - val_loss: 0.1035 - val_auc: 0.9553\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0870 - auc: 0.9111 - val_loss: 0.1007 - val_auc: 0.9589\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0885 - auc: 0.8897 - val_loss: 0.1006 - val_auc: 0.9597\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.0885 - auc: 0.8970 - val_loss: 0.0993 - val_auc: 0.9613\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0815 - auc: 0.9157 - val_loss: 0.1051 - val_auc: 0.9539\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0898 - auc: 0.8725 - val_loss: 0.1048 - val_auc: 0.9533\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0890 - auc: 0.8790 - val_loss: 0.1035 - val_auc: 0.9563\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0824 - auc: 0.8889 - val_loss: 0.1050 - val_auc: 0.9554\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0741 - auc: 0.9289 - val_loss: 0.1019 - val_auc: 0.9567\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0778 - auc: 0.9135 - val_loss: 0.1032 - val_auc: 0.9564\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0813 - auc: 0.8903 - val_loss: 0.1031 - val_auc: 0.9563\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 45s 864ms/step - loss: 0.0774 - auc: 0.9065 - val_loss: 0.1020 - val_auc: 0.9555\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0790 - auc: 0.8841 - val_loss: 0.1004 - val_auc: 0.9568\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0794 - auc: 0.8850 - val_loss: 0.1038 - val_auc: 0.9563\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0758 - auc: 0.9053 - val_loss: 0.1041 - val_auc: 0.9556\n",
            "#### FOLD 5 without TTA VAL_AUC = 0.961\n",
            "[1490, 1501, 1500, 1495, 1501, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 499s 1s/step - loss: 0.7023 - auc: 0.5116 - val_loss: 0.6651 - val_auc: 0.5061\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.6176 - auc: 0.4866 - val_loss: 0.5661 - val_auc: 0.5577\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.3566 - auc: 0.5456 - val_loss: 0.3018 - val_auc: 0.6998\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.2553 - auc: 0.6623 - val_loss: 0.2333 - val_auc: 0.7998\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.2010 - auc: 0.7831 - val_loss: 0.2000 - val_auc: 0.8701\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1750 - auc: 0.8192 - val_loss: 0.1687 - val_auc: 0.9010\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1686 - auc: 0.8020 - val_loss: 0.1536 - val_auc: 0.9154\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1581 - auc: 0.8288 - val_loss: 0.1494 - val_auc: 0.9194\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1548 - auc: 0.8254 - val_loss: 0.1352 - val_auc: 0.9306\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1477 - auc: 0.8482 - val_loss: 0.1279 - val_auc: 0.9308\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1417 - auc: 0.8740 - val_loss: 0.1281 - val_auc: 0.9416\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1437 - auc: 0.8306 - val_loss: 0.1189 - val_auc: 0.9448\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1437 - auc: 0.8338 - val_loss: 0.1164 - val_auc: 0.9453\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 48s 918ms/step - loss: 0.1354 - auc: 0.8705 - val_loss: 0.1132 - val_auc: 0.9505\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1353 - auc: 0.8464 - val_loss: 0.1111 - val_auc: 0.9525\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1338 - auc: 0.8601 - val_loss: 0.1391 - val_auc: 0.9469\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1329 - auc: 0.8364 - val_loss: 0.1084 - val_auc: 0.9565\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1257 - auc: 0.8696 - val_loss: 0.1092 - val_auc: 0.9551\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1316 - auc: 0.8596 - val_loss: 0.1124 - val_auc: 0.9566\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1166 - auc: 0.8739 - val_loss: 0.1039 - val_auc: 0.9565\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1176 - auc: 0.8840 - val_loss: 0.1031 - val_auc: 0.9568\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1133 - auc: 0.8696 - val_loss: 0.1075 - val_auc: 0.9620\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1072 - auc: 0.8903 - val_loss: 0.1026 - val_auc: 0.9551\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1146 - auc: 0.8851 - val_loss: 0.1012 - val_auc: 0.9603\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1152 - auc: 0.8658 - val_loss: 0.1029 - val_auc: 0.9552\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1111 - auc: 0.8668 - val_loss: 0.1041 - val_auc: 0.9572\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1119 - auc: 0.8680 - val_loss: 0.1006 - val_auc: 0.9588\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1006 - auc: 0.8959 - val_loss: 0.1042 - val_auc: 0.9560\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0985 - auc: 0.8985 - val_loss: 0.1064 - val_auc: 0.9556\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0946 - auc: 0.9189 - val_loss: 0.1030 - val_auc: 0.9564\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0952 - auc: 0.8920 - val_loss: 0.1022 - val_auc: 0.9578\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0954 - auc: 0.9031 - val_loss: 0.1007 - val_auc: 0.9584\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0935 - auc: 0.9056 - val_loss: 0.1014 - val_auc: 0.9567\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 973ms/step - loss: 0.0982 - auc: 0.8871 - val_loss: 0.1037 - val_auc: 0.9563\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0813 - auc: 0.9401 - val_loss: 0.1054 - val_auc: 0.9537\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.0933 - auc: 0.8746 - val_loss: 0.1020 - val_auc: 0.9582\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 973ms/step - loss: 0.0872 - auc: 0.9087 - val_loss: 0.1043 - val_auc: 0.9578\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0886 - auc: 0.8975 - val_loss: 0.1042 - val_auc: 0.9537\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0860 - auc: 0.9015 - val_loss: 0.1034 - val_auc: 0.9550\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 913ms/step - loss: 0.0800 - auc: 0.9206 - val_loss: 0.1045 - val_auc: 0.9535\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0881 - auc: 0.8863 - val_loss: 0.1032 - val_auc: 0.9545\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0882 - auc: 0.8746 - val_loss: 0.1039 - val_auc: 0.9543\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0804 - auc: 0.8933 - val_loss: 0.1064 - val_auc: 0.9535\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0721 - auc: 0.9314 - val_loss: 0.1057 - val_auc: 0.9506\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0736 - auc: 0.9034 - val_loss: 0.1060 - val_auc: 0.9506\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0787 - auc: 0.8862 - val_loss: 0.1063 - val_auc: 0.9536\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0760 - auc: 0.9158 - val_loss: 0.1059 - val_auc: 0.9537\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0768 - auc: 0.9028 - val_loss: 0.1061 - val_auc: 0.9537\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 48s 916ms/step - loss: 0.0763 - auc: 0.8960 - val_loss: 0.1060 - val_auc: 0.9538\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0732 - auc: 0.9080 - val_loss: 0.1060 - val_auc: 0.9538\n",
            "#### FOLD 6 without TTA VAL_AUC = 0.962\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 495s 1s/step - loss: 0.6848 - auc: 0.4895 - val_loss: 0.7269 - val_auc: 0.4967\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 939ms/step - loss: 0.6023 - auc: 0.5045 - val_loss: 0.5396 - val_auc: 0.5758\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.3450 - auc: 0.5565 - val_loss: 0.2727 - val_auc: 0.7205\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.2460 - auc: 0.7080 - val_loss: 0.2025 - val_auc: 0.8568\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1968 - auc: 0.7956 - val_loss: 0.1741 - val_auc: 0.8899\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1744 - auc: 0.8260 - val_loss: 0.1558 - val_auc: 0.9050\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1662 - auc: 0.8023 - val_loss: 0.1537 - val_auc: 0.9216\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1558 - auc: 0.8160 - val_loss: 0.1433 - val_auc: 0.9290\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1576 - auc: 0.8317 - val_loss: 0.1390 - val_auc: 0.9357\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.1452 - auc: 0.8481 - val_loss: 0.1284 - val_auc: 0.9373\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 48s 919ms/step - loss: 0.1406 - auc: 0.8774 - val_loss: 0.1289 - val_auc: 0.9388\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1465 - auc: 0.8260 - val_loss: 0.1181 - val_auc: 0.9458\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 971ms/step - loss: 0.1399 - auc: 0.8361 - val_loss: 0.1247 - val_auc: 0.9491\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1309 - auc: 0.8702 - val_loss: 0.1145 - val_auc: 0.9528\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1321 - auc: 0.8473 - val_loss: 0.1086 - val_auc: 0.9525\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1293 - auc: 0.8777 - val_loss: 0.1164 - val_auc: 0.9515\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1316 - auc: 0.8327 - val_loss: 0.1055 - val_auc: 0.9567\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1247 - auc: 0.8753 - val_loss: 0.1039 - val_auc: 0.9595\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1258 - auc: 0.8396 - val_loss: 0.1058 - val_auc: 0.9566\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1161 - auc: 0.8678 - val_loss: 0.1019 - val_auc: 0.9606\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1153 - auc: 0.8928 - val_loss: 0.1033 - val_auc: 0.9552\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1163 - auc: 0.8700 - val_loss: 0.1035 - val_auc: 0.9567\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1058 - auc: 0.8942 - val_loss: 0.1020 - val_auc: 0.9563\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.1108 - auc: 0.8772 - val_loss: 0.1054 - val_auc: 0.9554\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.1109 - auc: 0.8734 - val_loss: 0.1014 - val_auc: 0.9580\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1144 - auc: 0.8566 - val_loss: 0.1057 - val_auc: 0.9548\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1086 - auc: 0.8615 - val_loss: 0.1003 - val_auc: 0.9587\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1016 - auc: 0.8942 - val_loss: 0.1022 - val_auc: 0.9561\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0974 - auc: 0.9057 - val_loss: 0.1014 - val_auc: 0.9572\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0963 - auc: 0.9181 - val_loss: 0.1048 - val_auc: 0.9543\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0983 - auc: 0.8949 - val_loss: 0.1007 - val_auc: 0.9566\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0919 - auc: 0.9091 - val_loss: 0.1048 - val_auc: 0.9563\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0900 - auc: 0.8967 - val_loss: 0.1035 - val_auc: 0.9560\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.0955 - auc: 0.8799 - val_loss: 0.1060 - val_auc: 0.9560\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0821 - auc: 0.9456 - val_loss: 0.1067 - val_auc: 0.9559\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0976 - auc: 0.8670 - val_loss: 0.1051 - val_auc: 0.9567\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0857 - auc: 0.9078 - val_loss: 0.1067 - val_auc: 0.9555\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0856 - auc: 0.9006 - val_loss: 0.1074 - val_auc: 0.9513\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0852 - auc: 0.8983 - val_loss: 0.1048 - val_auc: 0.9530\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0781 - auc: 0.9154 - val_loss: 0.1046 - val_auc: 0.9525\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0872 - auc: 0.8724 - val_loss: 0.1051 - val_auc: 0.9531\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0843 - auc: 0.8797 - val_loss: 0.1068 - val_auc: 0.9523\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0814 - auc: 0.8925 - val_loss: 0.1082 - val_auc: 0.9533\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.0723 - auc: 0.9327 - val_loss: 0.1036 - val_auc: 0.9547\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0774 - auc: 0.9122 - val_loss: 0.1033 - val_auc: 0.9551\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0783 - auc: 0.8888 - val_loss: 0.1035 - val_auc: 0.9542\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.0749 - auc: 0.9088 - val_loss: 0.1044 - val_auc: 0.9546\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0781 - auc: 0.8829 - val_loss: 0.1049 - val_auc: 0.9545\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0767 - auc: 0.8984 - val_loss: 0.1051 - val_auc: 0.9545\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0694 - auc: 0.9049 - val_loss: 0.1052 - val_auc: 0.9545\n",
            "#### FOLD 7 without TTA VAL_AUC = 0.961\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 496s 1s/step - loss: 0.7071 - auc: 0.5090 - val_loss: 0.6831 - val_auc: 0.4913\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.6165 - auc: 0.5052 - val_loss: 0.5683 - val_auc: 0.5336\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.3526 - auc: 0.5491 - val_loss: 0.3055 - val_auc: 0.6615\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.2545 - auc: 0.6673 - val_loss: 0.2266 - val_auc: 0.7888\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 47s 909ms/step - loss: 0.2011 - auc: 0.7874 - val_loss: 0.2073 - val_auc: 0.8424\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1750 - auc: 0.8219 - val_loss: 0.1731 - val_auc: 0.8836\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1702 - auc: 0.7897 - val_loss: 0.1657 - val_auc: 0.9043\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1588 - auc: 0.8142 - val_loss: 0.1481 - val_auc: 0.9149\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1563 - auc: 0.8217 - val_loss: 0.1446 - val_auc: 0.9214\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1476 - auc: 0.8443 - val_loss: 0.1411 - val_auc: 0.9215\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1498 - auc: 0.8763 - val_loss: 0.1316 - val_auc: 0.9276\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1452 - auc: 0.8305 - val_loss: 0.1260 - val_auc: 0.9304\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1399 - auc: 0.8361 - val_loss: 0.1245 - val_auc: 0.9363\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1314 - auc: 0.8709 - val_loss: 0.1176 - val_auc: 0.9386\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1346 - auc: 0.8382 - val_loss: 0.1164 - val_auc: 0.9410\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1270 - auc: 0.8828 - val_loss: 0.1179 - val_auc: 0.9430\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1339 - auc: 0.8353 - val_loss: 0.1137 - val_auc: 0.9454\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1247 - auc: 0.8727 - val_loss: 0.1109 - val_auc: 0.9432\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1286 - auc: 0.8398 - val_loss: 0.1119 - val_auc: 0.9441\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1215 - auc: 0.8694 - val_loss: 0.1117 - val_auc: 0.9462\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1163 - auc: 0.8842 - val_loss: 0.1078 - val_auc: 0.9478\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1156 - auc: 0.8697 - val_loss: 0.1109 - val_auc: 0.9497\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1078 - auc: 0.9051 - val_loss: 0.1106 - val_auc: 0.9438\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 47s 902ms/step - loss: 0.1125 - auc: 0.8822 - val_loss: 0.1147 - val_auc: 0.9447\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1116 - auc: 0.8678 - val_loss: 0.1088 - val_auc: 0.9444\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1167 - auc: 0.8628 - val_loss: 0.1081 - val_auc: 0.9451\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1094 - auc: 0.8646 - val_loss: 0.1055 - val_auc: 0.9485\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1035 - auc: 0.8986 - val_loss: 0.1164 - val_auc: 0.9410\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0995 - auc: 0.9000 - val_loss: 0.1088 - val_auc: 0.9443\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0944 - auc: 0.9132 - val_loss: 0.1092 - val_auc: 0.9412\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1007 - auc: 0.8936 - val_loss: 0.1111 - val_auc: 0.9406\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0911 - auc: 0.9029 - val_loss: 0.1059 - val_auc: 0.9506\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0940 - auc: 0.8976 - val_loss: 0.1063 - val_auc: 0.9471\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0955 - auc: 0.8726 - val_loss: 0.1100 - val_auc: 0.9433\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.0828 - auc: 0.9368 - val_loss: 0.1121 - val_auc: 0.9422\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 47s 910ms/step - loss: 0.0953 - auc: 0.8774 - val_loss: 0.1111 - val_auc: 0.9396\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0881 - auc: 0.9076 - val_loss: 0.1062 - val_auc: 0.9500\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0889 - auc: 0.9043 - val_loss: 0.1100 - val_auc: 0.9444\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 47s 908ms/step - loss: 0.0865 - auc: 0.9048 - val_loss: 0.1092 - val_auc: 0.9438\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0839 - auc: 0.9100 - val_loss: 0.1070 - val_auc: 0.9453\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0893 - auc: 0.8761 - val_loss: 0.1082 - val_auc: 0.9445\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0900 - auc: 0.8814 - val_loss: 0.1092 - val_auc: 0.9430\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0845 - auc: 0.8924 - val_loss: 0.1112 - val_auc: 0.9396\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0771 - auc: 0.9256 - val_loss: 0.1112 - val_auc: 0.9404\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.0797 - auc: 0.9112 - val_loss: 0.1093 - val_auc: 0.9463\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0836 - auc: 0.8885 - val_loss: 0.1097 - val_auc: 0.9443\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0809 - auc: 0.9108 - val_loss: 0.1106 - val_auc: 0.9428\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.0800 - auc: 0.8880 - val_loss: 0.1111 - val_auc: 0.9429\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0802 - auc: 0.9004 - val_loss: 0.1111 - val_auc: 0.9433\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 47s 903ms/step - loss: 0.0783 - auc: 0.9121 - val_loss: 0.1110 - val_auc: 0.9432\n",
            "#### FOLD 8 without TTA VAL_AUC = 0.951\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 489s 1s/step - loss: 0.7094 - auc: 0.5000 - val_loss: 0.6767 - val_auc: 0.4511\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 940ms/step - loss: 0.6171 - auc: 0.4947 - val_loss: 0.5461 - val_auc: 0.4978\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.3664 - auc: 0.5408 - val_loss: 0.2922 - val_auc: 0.6526\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.2595 - auc: 0.6576 - val_loss: 0.2307 - val_auc: 0.7781\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.2010 - auc: 0.7871 - val_loss: 0.1959 - val_auc: 0.8573\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 51s 993ms/step - loss: 0.1751 - auc: 0.8248 - val_loss: 0.1713 - val_auc: 0.8841\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1702 - auc: 0.8043 - val_loss: 0.1566 - val_auc: 0.9038\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1562 - auc: 0.8203 - val_loss: 0.1527 - val_auc: 0.9131\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 47s 899ms/step - loss: 0.1568 - auc: 0.8301 - val_loss: 0.1420 - val_auc: 0.9200\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1487 - auc: 0.8413 - val_loss: 0.1366 - val_auc: 0.9249\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1449 - auc: 0.8737 - val_loss: 0.1277 - val_auc: 0.9329\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1449 - auc: 0.8279 - val_loss: 0.1246 - val_auc: 0.9363\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1415 - auc: 0.8334 - val_loss: 0.1445 - val_auc: 0.9394\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1313 - auc: 0.8787 - val_loss: 0.1192 - val_auc: 0.9433\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1359 - auc: 0.8418 - val_loss: 0.1160 - val_auc: 0.9474\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1271 - auc: 0.8813 - val_loss: 0.1171 - val_auc: 0.9519\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1342 - auc: 0.8381 - val_loss: 0.1116 - val_auc: 0.9518\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1237 - auc: 0.8755 - val_loss: 0.1110 - val_auc: 0.9478\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1291 - auc: 0.8515 - val_loss: 0.1101 - val_auc: 0.9515\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1210 - auc: 0.8725 - val_loss: 0.1064 - val_auc: 0.9567\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1152 - auc: 0.8986 - val_loss: 0.1070 - val_auc: 0.9605\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1154 - auc: 0.8620 - val_loss: 0.1063 - val_auc: 0.9564\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1129 - auc: 0.9025 - val_loss: 0.1057 - val_auc: 0.9568\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1109 - auc: 0.8756 - val_loss: 0.1021 - val_auc: 0.9615\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1158 - auc: 0.8654 - val_loss: 0.1024 - val_auc: 0.9606\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1152 - auc: 0.8640 - val_loss: 0.1065 - val_auc: 0.9523\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 49s 942ms/step - loss: 0.1061 - auc: 0.8637 - val_loss: 0.1021 - val_auc: 0.9655\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1026 - auc: 0.8963 - val_loss: 0.1021 - val_auc: 0.9648\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1020 - auc: 0.8968 - val_loss: 0.1022 - val_auc: 0.9614\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0971 - auc: 0.9128 - val_loss: 0.1022 - val_auc: 0.9596\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1003 - auc: 0.8948 - val_loss: 0.1040 - val_auc: 0.9598\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.1001 - auc: 0.9136 - val_loss: 0.1044 - val_auc: 0.9553\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0975 - auc: 0.9015 - val_loss: 0.1010 - val_auc: 0.9597\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0991 - auc: 0.8880 - val_loss: 0.1065 - val_auc: 0.9516\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 46s 893ms/step - loss: 0.0850 - auc: 0.9309 - val_loss: 0.1027 - val_auc: 0.9598\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0944 - auc: 0.8832 - val_loss: 0.1026 - val_auc: 0.9583\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0891 - auc: 0.8965 - val_loss: 0.1058 - val_auc: 0.9554\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0875 - auc: 0.8954 - val_loss: 0.1058 - val_auc: 0.9548\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0890 - auc: 0.8889 - val_loss: 0.1023 - val_auc: 0.9550\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.0844 - auc: 0.9122 - val_loss: 0.1041 - val_auc: 0.9557\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0951 - auc: 0.8766 - val_loss: 0.1029 - val_auc: 0.9552\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0900 - auc: 0.8911 - val_loss: 0.1032 - val_auc: 0.9543\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0843 - auc: 0.9013 - val_loss: 0.1058 - val_auc: 0.9530\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0793 - auc: 0.9249 - val_loss: 0.1056 - val_auc: 0.9531\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0789 - auc: 0.9110 - val_loss: 0.1050 - val_auc: 0.9518\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0821 - auc: 0.8985 - val_loss: 0.1060 - val_auc: 0.9515\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0780 - auc: 0.9100 - val_loss: 0.1054 - val_auc: 0.9522\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0796 - auc: 0.8969 - val_loss: 0.1051 - val_auc: 0.9524\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0827 - auc: 0.9014 - val_loss: 0.1053 - val_auc: 0.9539\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 47s 898ms/step - loss: 0.0770 - auc: 0.9088 - val_loss: 0.1053 - val_auc: 0.9525\n",
            "#### FOLD 9 without TTA VAL_AUC = 0.965\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 490s 1s/step - loss: 0.7052 - auc: 0.5008 - val_loss: 0.6932 - val_auc: 0.4937\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.6163 - auc: 0.4954 - val_loss: 0.5677 - val_auc: 0.5259\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.3591 - auc: 0.5316 - val_loss: 0.2918 - val_auc: 0.6520\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.2580 - auc: 0.6675 - val_loss: 0.2240 - val_auc: 0.7970\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.2030 - auc: 0.7958 - val_loss: 0.1819 - val_auc: 0.8569\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1760 - auc: 0.8128 - val_loss: 0.1632 - val_auc: 0.8888\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1674 - auc: 0.8030 - val_loss: 0.1621 - val_auc: 0.9032\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1614 - auc: 0.8248 - val_loss: 0.1657 - val_auc: 0.9146\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1517 - auc: 0.8098 - val_loss: 0.1462 - val_auc: 0.9196\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1492 - auc: 0.8520 - val_loss: 0.1354 - val_auc: 0.9272\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.1408 - auc: 0.8672 - val_loss: 0.1273 - val_auc: 0.9310\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1495 - auc: 0.8280 - val_loss: 0.1235 - val_auc: 0.9373\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.1450 - auc: 0.8235 - val_loss: 0.1237 - val_auc: 0.9392\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1370 - auc: 0.8794 - val_loss: 0.1180 - val_auc: 0.9441\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 48s 915ms/step - loss: 0.1352 - auc: 0.8383 - val_loss: 0.1291 - val_auc: 0.9382\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1286 - auc: 0.8734 - val_loss: 0.1211 - val_auc: 0.9342\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1422 - auc: 0.8311 - val_loss: 0.1169 - val_auc: 0.9433\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1302 - auc: 0.8830 - val_loss: 0.1223 - val_auc: 0.9360\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1254 - auc: 0.8476 - val_loss: 0.1162 - val_auc: 0.9464\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.1217 - auc: 0.8759 - val_loss: 0.1139 - val_auc: 0.9466\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1195 - auc: 0.8835 - val_loss: 0.1139 - val_auc: 0.9433\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1134 - auc: 0.8723 - val_loss: 0.1145 - val_auc: 0.9428\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1143 - auc: 0.8999 - val_loss: 0.1153 - val_auc: 0.9467\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1134 - auc: 0.8805 - val_loss: 0.1132 - val_auc: 0.9470\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1143 - auc: 0.8711 - val_loss: 0.1350 - val_auc: 0.9265\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1183 - auc: 0.8593 - val_loss: 0.1168 - val_auc: 0.9358\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1146 - auc: 0.8607 - val_loss: 0.1148 - val_auc: 0.9432\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1073 - auc: 0.8969 - val_loss: 0.1185 - val_auc: 0.9354\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1025 - auc: 0.9040 - val_loss: 0.1127 - val_auc: 0.9411\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0982 - auc: 0.9162 - val_loss: 0.1134 - val_auc: 0.9395\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0984 - auc: 0.8939 - val_loss: 0.1170 - val_auc: 0.9401\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0963 - auc: 0.8966 - val_loss: 0.1151 - val_auc: 0.9418\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0957 - auc: 0.8983 - val_loss: 0.1184 - val_auc: 0.9349\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0965 - auc: 0.8809 - val_loss: 0.1189 - val_auc: 0.9357\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0858 - auc: 0.9341 - val_loss: 0.1163 - val_auc: 0.9392\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0995 - auc: 0.8773 - val_loss: 0.1214 - val_auc: 0.9275\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0906 - auc: 0.9086 - val_loss: 0.1175 - val_auc: 0.9348\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0905 - auc: 0.8935 - val_loss: 0.1175 - val_auc: 0.9319\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0897 - auc: 0.8984 - val_loss: 0.1223 - val_auc: 0.9321\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0849 - auc: 0.9094 - val_loss: 0.1168 - val_auc: 0.9352\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0902 - auc: 0.8763 - val_loss: 0.1180 - val_auc: 0.9330\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0889 - auc: 0.8823 - val_loss: 0.1174 - val_auc: 0.9353\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0829 - auc: 0.8937 - val_loss: 0.1186 - val_auc: 0.9323\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0795 - auc: 0.9257 - val_loss: 0.1203 - val_auc: 0.9258\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0804 - auc: 0.9072 - val_loss: 0.1181 - val_auc: 0.9326\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0841 - auc: 0.8889 - val_loss: 0.1180 - val_auc: 0.9333\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0784 - auc: 0.9018 - val_loss: 0.1196 - val_auc: 0.9317\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0830 - auc: 0.8857 - val_loss: 0.1195 - val_auc: 0.9334\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0805 - auc: 0.9040 - val_loss: 0.1196 - val_auc: 0.9329\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0783 - auc: 0.9155 - val_loss: 0.1200 - val_auc: 0.9321\n",
            "#### FOLD 10 without TTA VAL_AUC = 0.947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXjYZ-Rewt-"
      },
      "source": [
        "#Inference B4512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eZByBYeuDMi",
        "outputId": "f4474b2e-97dc-4291-9a0c-482c4db9d0c2"
      },
      "source": [
        "pred_probs"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00058419, 0.00160271, 0.00180632, ..., 0.00783676, 0.16997021,\n",
              "       0.41400138], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPmlTjd8exx8",
        "outputId": "b39c32cb-da0e-4b77-a82d-62b9b7161479"
      },
      "source": [
        "#model prediction\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = []; sub_names = [];\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob = model.predict(ds_test, verbose=1)\n",
        "    pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "total_sub_names = np.concatenate(sub_names)\n",
        "total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = total_sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(total_pred_sub_probs, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1490]\n",
            "6/6 [==============================] - 17s 186ms/step\n",
            "12/12 [==============================] - 17s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 17s 187ms/step\n",
            "12/12 [==============================] - 18s 187ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 17s 188ms/step\n",
            "12/12 [==============================] - 17s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 17s 187ms/step\n",
            "12/12 [==============================] - 17s 189ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 17s 186ms/step\n",
            "12/12 [==============================] - 17s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1494]\n",
            "6/6 [==============================] - 17s 187ms/step\n",
            "12/12 [==============================] - 18s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 17s 186ms/step\n",
            "12/12 [==============================] - 17s 186ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1516]\n",
            "6/6 [==============================] - 17s 185ms/step\n",
            "12/12 [==============================] - 17s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1508]\n",
            "6/6 [==============================] - 17s 186ms/step\n",
            "12/12 [==============================] - 17s 190ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 17s 186ms/step\n",
            "12/12 [==============================] - 18s 185ms/step\n",
            "total auc: 0.9591012053000189\n",
            "class 14 auc: 0.992116755134953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.001806</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.000970</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>0.000862</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>0.000903</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.000838</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.999272</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.999932</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.820485</td>\n",
              "      <td>0.009715</td>\n",
              "      <td>0.035910</td>\n",
              "      <td>0.973262</td>\n",
              "      <td>0.053898</td>\n",
              "      <td>0.438125</td>\n",
              "      <td>0.640152</td>\n",
              "      <td>0.524846</td>\n",
              "      <td>0.086989</td>\n",
              "      <td>0.426743</td>\n",
              "      <td>0.034501</td>\n",
              "      <td>0.345256</td>\n",
              "      <td>0.004968</td>\n",
              "      <td>0.608434</td>\n",
              "      <td>0.004773</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.999993</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.944786</td>\n",
              "      <td>0.018695</td>\n",
              "      <td>0.011175</td>\n",
              "      <td>0.546646</td>\n",
              "      <td>0.865793</td>\n",
              "      <td>0.001839</td>\n",
              "      <td>0.123728</td>\n",
              "      <td>0.942145</td>\n",
              "      <td>0.954520</td>\n",
              "      <td>0.095503</td>\n",
              "      <td>0.027574</td>\n",
              "      <td>0.133841</td>\n",
              "      <td>0.008041</td>\n",
              "      <td>0.074320</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.001337  0.999272     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.000155  0.999932     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.608434  0.004773     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.000064  0.999993     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.074320  0.003596     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "rek_1tb81wnM",
        "outputId": "6c6c177a-a5e5-40a2-c98f-2d8d5f9d361c"
      },
      "source": [
        "df_sub"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "      <td>0.004978</td>\n",
              "      <td>0.002241</td>\n",
              "      <td>0.002472</td>\n",
              "      <td>0.004594</td>\n",
              "      <td>0.001809</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.003363</td>\n",
              "      <td>0.004259</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.004604</td>\n",
              "      <td>0.003498</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>0.005589</td>\n",
              "      <td>0.993069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "      <td>0.996179</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>0.268284</td>\n",
              "      <td>0.956285</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.013147</td>\n",
              "      <td>0.002487</td>\n",
              "      <td>0.018729</td>\n",
              "      <td>0.122174</td>\n",
              "      <td>0.140713</td>\n",
              "      <td>0.005812</td>\n",
              "      <td>0.218308</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>0.002698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.001151</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.999901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "      <td>0.854467</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.013643</td>\n",
              "      <td>0.971118</td>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.004229</td>\n",
              "      <td>0.015943</td>\n",
              "      <td>0.011947</td>\n",
              "      <td>0.055547</td>\n",
              "      <td>0.014499</td>\n",
              "      <td>0.260382</td>\n",
              "      <td>0.001227</td>\n",
              "      <td>0.040456</td>\n",
              "      <td>0.018104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5967</th>\n",
              "      <td>fe619a02b19b72ad527dc3e8642f4afd</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.014843</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.025875</td>\n",
              "      <td>0.009626</td>\n",
              "      <td>0.004853</td>\n",
              "      <td>0.002507</td>\n",
              "      <td>0.007834</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>0.049233</td>\n",
              "      <td>0.964304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>fe62409506fa9ca50424e85c378d30da</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.000348</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.000564</td>\n",
              "      <td>0.999752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>fe9e6f46bf0cb223e745dc1919564bd2</td>\n",
              "      <td>0.002548</td>\n",
              "      <td>0.002944</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.008496</td>\n",
              "      <td>0.003980</td>\n",
              "      <td>0.006425</td>\n",
              "      <td>0.009815</td>\n",
              "      <td>0.008736</td>\n",
              "      <td>0.005094</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>0.002241</td>\n",
              "      <td>0.003292</td>\n",
              "      <td>0.004852</td>\n",
              "      <td>0.994287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>fec9ed851b88f98a1c964179c5340d54</td>\n",
              "      <td>0.165491</td>\n",
              "      <td>0.155439</td>\n",
              "      <td>0.721637</td>\n",
              "      <td>0.098772</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.063225</td>\n",
              "      <td>0.054374</td>\n",
              "      <td>0.383856</td>\n",
              "      <td>0.901687</td>\n",
              "      <td>0.580689</td>\n",
              "      <td>0.073423</td>\n",
              "      <td>0.281018</td>\n",
              "      <td>0.031659</td>\n",
              "      <td>0.379554</td>\n",
              "      <td>0.038771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>fed370b0c413ea8bb9881636a6018ed2</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.999463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5972 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name    class0  ...   class13   class14\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9  0.004978  ...  0.005589  0.993069\n",
              "1     004f33259ee4aef671c2b95d54e4be68  0.000012  ...  0.000024  0.999997\n",
              "2     008bdde2af2462e86fd373a445d0f4cd  0.996179  ...  0.066917  0.002698\n",
              "3     009bc039326338823ca3aa84381f17f1  0.000118  ...  0.000314  0.999901\n",
              "4     00a2145de1886cb9eb88869c85d74080  0.854467  ...  0.040456  0.018104\n",
              "...                                ...       ...  ...       ...       ...\n",
              "5967  fe619a02b19b72ad527dc3e8642f4afd  0.014151  ...  0.049233  0.964304\n",
              "5968  fe62409506fa9ca50424e85c378d30da  0.000319  ...  0.000564  0.999752\n",
              "5969  fe9e6f46bf0cb223e745dc1919564bd2  0.002548  ...  0.004852  0.994287\n",
              "5970  fec9ed851b88f98a1c964179c5340d54  0.165491  ...  0.379554  0.038771\n",
              "5971  fed370b0c413ea8bb9881636a6018ed2  0.000588  ...  0.000646  0.999463\n",
              "\n",
              "[5972 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akBcfLDedqCu"
      },
      "source": [
        "# Inference DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m1hZdOmudtC5",
        "outputId": "2e21f913-3935-4d40-9aba-651826736b86"
      },
      "source": [
        "#model prediction\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = []; sub_names = [];\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = DenseNet201(weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD_DENSENET_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"DenseNet Model{CFG.NET} has been loaded\")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob = model.predict(ds_test, verbose=1)\n",
        "    pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "total_sub_names = np.concatenate(sub_names)\n",
        "total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = total_sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(total_pred_sub_probs, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1490]\n",
            "6/6 [==============================] - 42s 283ms/step\n",
            "12/12 [==============================] - 43s 282ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1501]\n",
            "6/6 [==============================] - 40s 286ms/step\n",
            "12/12 [==============================] - 42s 286ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1500]\n",
            "6/6 [==============================] - 40s 283ms/step\n",
            "12/12 [==============================] - 41s 289ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1495]\n",
            "6/6 [==============================] - 40s 285ms/step\n",
            "12/12 [==============================] - 43s 290ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1501]\n",
            "6/6 [==============================] - 42s 284ms/step\n",
            "12/12 [==============================] - 40s 285ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1494]\n",
            "6/6 [==============================] - 40s 283ms/step\n",
            "12/12 [==============================] - 43s 286ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1495]\n",
            "6/6 [==============================] - 42s 285ms/step\n",
            "12/12 [==============================] - 43s 286ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1516]\n",
            "6/6 [==============================] - 42s 282ms/step\n",
            "12/12 [==============================] - 43s 288ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1508]\n",
            "6/6 [==============================] - 42s 283ms/step\n",
            "12/12 [==============================] - 41s 288ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1500]\n",
            "6/6 [==============================] - 40s 286ms/step\n",
            "12/12 [==============================] - 43s 285ms/step\n",
            "total auc: 0.9529051791118306\n",
            "class 14 auc: 0.9890739849679303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001225</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.002121</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.002139</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.002575</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>0.998202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.002371</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.005221</td>\n",
              "      <td>0.003202</td>\n",
              "      <td>0.004513</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.004478</td>\n",
              "      <td>0.003829</td>\n",
              "      <td>0.004607</td>\n",
              "      <td>0.002472</td>\n",
              "      <td>0.997272</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.664114</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>0.028032</td>\n",
              "      <td>0.830702</td>\n",
              "      <td>0.046796</td>\n",
              "      <td>0.240386</td>\n",
              "      <td>0.457719</td>\n",
              "      <td>0.571947</td>\n",
              "      <td>0.089162</td>\n",
              "      <td>0.178943</td>\n",
              "      <td>0.045744</td>\n",
              "      <td>0.099033</td>\n",
              "      <td>0.011544</td>\n",
              "      <td>0.512904</td>\n",
              "      <td>0.024070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>0.004798</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>0.005435</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.022135</td>\n",
              "      <td>0.009931</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.003066</td>\n",
              "      <td>0.994180</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.966398</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.016248</td>\n",
              "      <td>0.167216</td>\n",
              "      <td>0.462104</td>\n",
              "      <td>0.008271</td>\n",
              "      <td>0.078319</td>\n",
              "      <td>0.514315</td>\n",
              "      <td>0.429669</td>\n",
              "      <td>0.068471</td>\n",
              "      <td>0.023668</td>\n",
              "      <td>0.021563</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.133308</td>\n",
              "      <td>0.022219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.001723  0.998202     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.002472  0.997272     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.512904  0.024070     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.003066  0.994180     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.133308  0.022219     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-eNsRRjKzXz"
      },
      "source": [
        "# Inference 768-B4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRoDyuHtK_Gg"
      },
      "source": [
        "class CFG:\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 768\n",
        "    OBJ_HEIGHT = 768\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 7e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 15\n",
        "    #CLASS_WEIGHT = {0:1.42629, 1:1.29648, 2:1.28211, 3:1.05131, 4:1.26954}\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        " \n",
        "    NET = 4\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    #GCS_PATH_2019 = 'gs://kds-2ae4f2c9141c2ce643fa1d59c544fc258a02543d9cd46d9149ba8c5a'\n",
        "    #GCS_PATH = 'gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df'\n",
        "    #If Ten fold\n",
        "    GCS_PATH = 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/vin_2classifier'"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0EPw3woK1fS",
        "outputId": "8a8d0280-77eb-4fbd-d532-7d2ce6127a71"
      },
      "source": [
        "#model prediction\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = []; sub_names = [];\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob = model.predict(ds_test, verbose=1)\n",
        "    pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "total_sub_names = np.concatenate(sub_names)\n",
        "total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = total_sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(total_pred_sub_probs, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1490]\n",
            "6/6 [==============================] - 23s 412ms/step\n",
            "12/12 [==============================] - 25s 414ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 23s 414ms/step\n",
            "12/12 [==============================] - 24s 414ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 22s 412ms/step\n",
            "12/12 [==============================] - 24s 412ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 22s 413ms/step\n",
            "12/12 [==============================] - 24s 406ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 22s 403ms/step\n",
            "12/12 [==============================] - 25s 408ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1494]\n",
            "6/6 [==============================] - 25s 417ms/step\n",
            "12/12 [==============================] - 24s 409ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 22s 405ms/step\n",
            "12/12 [==============================] - 24s 409ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1516]\n",
            "6/6 [==============================] - 22s 415ms/step\n",
            "12/12 [==============================] - 24s 406ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1508]\n",
            "6/6 [==============================] - 22s 414ms/step\n",
            "12/12 [==============================] - 24s 405ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTg6kmymFETD"
      },
      "source": [
        "# MODEL ENSEMBLE\n",
        "dense512 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_OOF.csv'))\n",
        "eff4 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_OOF.csv'))\n",
        "eff4768 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_OOF.csv'))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRnyEJp0dLLG",
        "outputId": "089223ec-d984-4040-b9de-a98d66dac40b"
      },
      "source": [
        "ensemble = dense512.copy()\n",
        "ensemble[[f'class{x}' for x in range(15)]] =0*dense512[[f'class{x}' for x in range(15)]].values + 1*eff4[[f'class{x}' for x in range(15)]].values\n",
        "ensemble_values = ensemble[[f'class{x}' for x in range(15)]].values\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "        ind_class_roc.append(roc_auc_score(true[:,i], ensemble_values[:,i]))\n",
        "print(ind_class_roc[-1])\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.992116755134953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQIeBkioFprr",
        "outputId": "ab3e807a-cd65-45c1-fae7-898a33608c6b"
      },
      "source": [
        "ind_class_roc = []\n",
        "max_ind_class = 0\n",
        "max_a = 0\n",
        "max_b = 0\n",
        "max_c = 0\n",
        "for a, b, c in zip(np.linspace(0,1,30),np.linspace(0,1,30),np.linspace(0,1,30)):\n",
        "    ensemble = dense512.copy()\n",
        "    ensemble[[f'class{x}' for x in range(15)]] =\\\n",
        "    a*dense512[[f'class{x}' for x in range(15)]].values +\\\n",
        "    b*eff4[[f'class{x}' for x in range(15)]].values +\\\n",
        "    c*eff4768[[f'class{x}' for x in range(15)]].values\n",
        "    ensemble_values = ensemble[[f'class{x}' for x in range(15)]].values\n",
        "    for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "        ind_class_roc.append(roc_auc_score(true[:,i], ensemble_values[:,i]))\n",
        "    #print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "    #print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "    if max_ind_class < ind_class_roc[-1]:\n",
        "        max_ind_class = ind_class_roc[-1]\n",
        "        max_a = a\n",
        "        max_b = b\n",
        "        max_c = c\n",
        "print(f\"max auc at a:{max_a}\", max_ind_class)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max auc at a:0.20603015075376885 0.9933891260183624\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}