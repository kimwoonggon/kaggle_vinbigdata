{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(TPU-B4512)+InferenceOtherModel 10FoldVinBigDataMultilabel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1sgYRMlCd8Nu1g3Tefr+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoonggon/kaggle_vinbigdata/blob/main/(TPU_B4512)%2BInferenceOtherModel_10FoldVinBigDataMultilabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbJWFGLTJ9A",
        "outputId": "25c22440-f27c-40a9-e3d3-8846bc6bfabb"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_vL8ic3HcZ",
        "outputId": "4901982b-270d-41c4-bce6-3a9124a2aa05"
      },
      "source": [
        "#!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "#!pip install -U tensorflow-addons==0.9.1\n",
        "!pip install -U tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import requests\n",
        "import os\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xX204k2Ktd"
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPVid4aN0du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81086270-f063-483a-cb3e-9c784a021fc3"
      },
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "!pip install gcsfs #gcp 파일 로드\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/49/2dbc00f89ab9e7513faee7927ea0c649d68eb721108aee860380eaf86ff4/gcsfs-0.8.0-py2.py3-none-any.whl\n",
            "Collecting fsspec>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.28.0)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Collecting ujson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/4e/50e8e4cf5f00b537095711c2c86ac4d7191aed2b4fffd5a19f06898f6929/ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.8.0->gcsfs) (3.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (54.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (20.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.8.0->gcsfs) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: fsspec, async-timeout, multidict, yarl, aiohttp, ujson, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-0.9.0 gcsfs-0.8.0 multidict-5.1.0 ujson-4.0.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NERnp6GCrxgr"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CFiVVS4Q82",
        "outputId": "5c07c19d-a69d-43c1-ef26-234941ec549b"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.48.65.154:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ylvljm1eIu",
        "outputId": "550b780f-1a1c-4b29-99d4-ac8ba9c10a33"
      },
      "source": [
        "MIXED_PRECISION = True\n",
        "XLA_ACCELERATE = True\n",
        " \n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "    if tpu: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
        "    else: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        " \n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed precision enabled\n",
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqZy4Kipt7v"
      },
      "source": [
        "class CFG:\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 512\n",
        "    OBJ_HEIGHT = 512\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 7e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 15\n",
        "    #CLASS_WEIGHT = {0:1.42629, 1:1.29648, 2:1.28211, 3:1.05131, 4:1.26954}\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        " \n",
        "    NET = 4\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    #GCS_PATH_2019 = 'gs://kds-2ae4f2c9141c2ce643fa1d59c544fc258a02543d9cd46d9149ba8c5a'\n",
        "    #GCS_PATH = 'gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df'\n",
        "    #If Ten fold\n",
        "    GCS_PATH = 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/vin_2classifier'\n",
        "    \n",
        "    #RANDAUG_NUM = 2\n",
        "    #RANDAUG_MAGNITUDE = 22"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXd8pFJ1fmR",
        "outputId": "fc9dc50d-af7c-4a4c-a43f-1b09b16b6ec9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import efficientnet.tfkeras as efn\n",
        "# Configuration\n",
        "effnets = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]\n",
        " \n",
        "TTA_NUM = CFG.TTA_NUM\n",
        "TOTALWIDTH = CFG.WIDTH\n",
        "TOTALHEIGHT = CFG.HEIGHT\n",
        "HEIGHT = CFG.OBJ_HEIGHT\n",
        "WIDTH = CFG.OBJ_WIDTH\n",
        "IMAGE_SIZE = [HEIGHT, WIDTH]\n",
        "NET = CFG.NET\n",
        "BATCH_SIZE = CFG.BATCH_SIZE\n",
        "AUG_BATCH = BATCH_SIZE\n",
        "CHANNELS = CFG.CHANNELS\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "GCS_PATH = CFG.GCS_PATH\n",
        "ROOT_PATH = CFG.ROOT_PATH\n",
        "EPOCHS = CFG.EPOCHS\n",
        "SEED = CFG.SEED\n",
        "LEARNING_RATE = CFG.LEARNING_RATE\n",
        "NUMBER_OF_CLASSES = CFG.NUMBER_OF_CLASSES\n",
        " \n",
        "#class_weight = CFG.CLASS_WEIGHT\n",
        " \n",
        "IMAGE_MEAN = CFG.MEAN\n",
        "IMAGE_STD = CFG.STD \n",
        "FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH + '/train*')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+\"/test*\")\n",
        "#FILENAMES_2019 = tf.io.gfile.glob(CFG.GCS_PATH_2019+ '/train*')\n",
        "print(FILENAMES)\n",
        "print(TEST_FILENAMES)\n",
        "#print(FILENAMES_2019)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold0-1490.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold1-1501.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold2-1500.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold3-1495.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold4-1501.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold5-1494.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold6-1495.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold7-1516.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold8-1508.tfrecords', 'gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/train2019_fold9-1500.tfrecords']\n",
            "['gs://kds-04e00660084e8a3430b69e0e476690d104b5d26947c620cdca94b6c7/test-3000.tfrecords']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SOJUTcaXH2a",
        "outputId": "232be8bf-75e1-4054-c018-a23d1829ddd1"
      },
      "source": [
        "test_image = tf.cast(tf.random.uniform(shape=(1024,1024,3),minval = 0,maxval = 255,dtype=tf.int32), dtype=tf.uint8)\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow_addons.image.utils import to_4D_image, from_4D_image \n",
        "import inspect\n",
        "import math\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import image as contrib_image\n",
        "#from tensorflow.contrib import training as contrib_training\n",
        "def blend(image1, image2, factor):\n",
        "  \"\"\"Blend image1 and image2 using 'factor'.\n",
        "  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n",
        "  A value of 1.0 means only image2 is used.  A value between 0.0 and\n",
        "  1.0 means we linearly interpolate the pixel values between the two\n",
        "  images.  A value greater than 1.0 \"extrapolates\" the difference\n",
        "  between the two pixel values, and we clip the results to values\n",
        "  between 0 and 255.\n",
        "  Args:\n",
        "    image1: An image Tensor of type uint8.\n",
        "    image2: An image Tensor of type uint8.\n",
        "    factor: A floating point value above 0.0.\n",
        "  Returns:\n",
        "    A blended image Tensor of type uint8.\n",
        "  \"\"\"\n",
        "  if factor == 0.0:\n",
        "    return tf.convert_to_tensor(image1)\n",
        "  if factor == 1.0:\n",
        "    return tf.convert_to_tensor(image2)\n",
        " \n",
        "  image1 = tf.cast(image1, dtype=tf.float32)\n",
        "  image2 = tf.cast(image2, dtype=tf.float32)\n",
        " \n",
        "  difference = image2 - image1\n",
        "  scaled = factor * difference\n",
        " \n",
        "  # Do addition in float.\n",
        "  temp = tf.cast(image1, dtype=tf.float32) + scaled\n",
        " \n",
        "  # Interpolate\n",
        "  if factor > 0.0 and factor < 1.0:\n",
        "    # Interpolation means we always stay within 0 and 255.\n",
        "    return tf.cast(temp, tf.uint8)\n",
        " \n",
        "  # Extrapolate:\n",
        "  #\n",
        "  # We need to clip and then cast.\n",
        "  return tf.cast(tf.clip_by_value(temp, 0.0, 255.0), tf.uint8)\n",
        "def Identity(image, _):\n",
        "    return image\n",
        "#Identity(test_image, 3)\n",
        "def AutoContrast(image, _):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        " \n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), dtype = tf.float32)\n",
        "    hi = tf.cast(tf.reduce_max(image), dtype = tf.float32)\n",
        " \n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "        scale = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale\n",
        "        im = tf.cast(im, dtype=tf.float32) * scale + offset\n",
        "        im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "        return tf.cast(im, tf.uint8)\n",
        " \n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        " \n",
        "AutoContrast(test_image, 3)\n",
        "def Equalize(image, _):\n",
        "  \"\"\"Implements Equalize function from PIL using TF ops.\"\"\"\n",
        "  def scale_channel(im, c):\n",
        "    \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n",
        "    im = tf.cast(im[:, :, c], tf.int32)\n",
        "    # Compute the histogram of the image channel.\n",
        "    histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
        " \n",
        "    # For the purposes of computing the step, filter out the nonzeros.\n",
        "    nonzero = tf.where(tf.not_equal(histo, 0))\n",
        "    nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
        "    step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
        " \n",
        "    def build_lut(histo, step):\n",
        "      # Compute the cumulative sum, shifting by step // 2\n",
        "      # and then normalization by step.\n",
        "      lut = (tf.cumsum(histo) + (step // 2)) // step\n",
        "      # Shift lut, prepending with 0.\n",
        "      lut = tf.concat([[0], lut[:-1]], 0)\n",
        "      # Clip the counts to be in range.  This is done\n",
        "      # in the C code for image.point.\n",
        "      return tf.clip_by_value(lut, 0, 255)\n",
        " \n",
        "    # If step is zero, return the original image.  Otherwise, build\n",
        "    # lut from the full histogram and step and then index from it.\n",
        "    result = tf.cond(tf.equal(step, 0),\n",
        "                     lambda: im,\n",
        "                     lambda: tf.gather(build_lut(histo, step), im))\n",
        " \n",
        "    return tf.cast(result, tf.uint8)\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image, 0)\n",
        "  s2 = scale_channel(image, 1)\n",
        "  s3 = scale_channel(image, 2)\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "Equalize(test_image, 1)\n",
        "def Rotate(image, degrees):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees = int(degrees)\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        " \n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  #image = contrib_image.rotate(wrap(image), radians)\n",
        "  image = tfa.image.rotate(image, radians)\n",
        "  #return unwrap(image, replace)\n",
        "  return image\n",
        "Rotate(test_image, 30.1)\n",
        "def Solarize(image, threshold=128):\n",
        "  # For each pixel in the image, select the pixel\n",
        "  # if the value is less than the threshold.\n",
        "  # Otherwise, subtract 255 from the pixel.\n",
        "  #image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
        "  #print(image)\n",
        "  \n",
        "  threshold = tf.cast(threshold, dtype=tf.uint8)\n",
        "  #print(threshold)\n",
        "  minus_value = tf.constant(255, dtype=tf.uint8)\n",
        "  #print(minus_value)\n",
        "  return tf.where(image < threshold, image, minus_value - image)\n",
        "Solarize(test_image, 10.0)\n",
        "def Color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  #factor = tf.cast(factor, dtype=tf.float32)\n",
        "  return blend(degenerate, image, factor)\n",
        "Color(test_image, 10.1)\n",
        " \n",
        " \n",
        " \n",
        "def Posterize(image, bits):\n",
        " \n",
        "  bits=int(bits)\n",
        "  #print(bits)\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  #print(shift)\n",
        "  #print(image)\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "Posterize(test_image, 1.1)\n",
        "def Contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        " \n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "Contrast(test_image, 10.1)\n",
        "def Brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "Brightness(test_image, 10.1)\n",
        "def _sharpness_image(image, factor):\n",
        "    orig_image = image\n",
        "    image_dtype = image.dtype\n",
        "    image_channels = image.shape[-1]\n",
        "    image = tf.cast(image, tf.float32)\n",
        " \n",
        "    # SMOOTH PIL Kernel.\n",
        "    kernel = (\n",
        "        tf.constant(\n",
        "            [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32, shape=[3, 3, 1, 1]\n",
        "        )\n",
        "        / 13.0\n",
        "    )\n",
        "    kernel = tf.tile(kernel, [1, 1, image_channels, 1])\n",
        " \n",
        "    # Apply kernel channel-wise.\n",
        "    degenerate = tf.nn.depthwise_conv2d(\n",
        "        image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\", dilations=[1, 1]\n",
        "    )\n",
        "    degenerate = tf.cast(degenerate, image_dtype)\n",
        " \n",
        "    # For the borders of the resulting image, fill in the values of the original image.\n",
        "    mask = tf.ones_like(degenerate)\n",
        "    padded_mask = tf.pad(mask, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    padded_degenerate = tf.pad(degenerate, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
        " \n",
        "    # Blend the final result.\n",
        "    blended = blend(result, orig_image, factor)\n",
        "    return tf.cast(blended, image_dtype)\n",
        " \n",
        " \n",
        "def Sharpness(image, factor):\n",
        "    \n",
        "        image_dims = tf.rank(image)\n",
        "        image = to_4D_image(image)\n",
        "        image = _sharpness_image(image, factor=factor)\n",
        "        return from_4D_image(image, image_dims)\n",
        "    #return tfa.image.sharpness(image, factor)\n",
        "Sharpness(test_image, 10.1)\n",
        " \n",
        "def ShearX(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"\n",
        "  # Shear parallel to x axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  level\n",
        "  #  0  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  \n",
        "  return tfa.image.shear_x(image, level, 0)\n",
        "ShearX(test_image,10)\n",
        "def ShearY(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"\n",
        "  # Shear parallel to y axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  0\n",
        "  #  level  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.shear_y(image, level, 0)\n",
        "ShearX(test_image,20)\n",
        "def wrap(image):\n",
        "  \"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
        "  extended = tf.concat([image, extended_channel], 2)\n",
        "  return extended\n",
        " \n",
        "def unwrap(image, replace):\n",
        "  \"\"\"Unwraps an image produced by wrap.\n",
        "  Where there is a 0 in the last channel for every spatial position,\n",
        "  the rest of the three channels in that spatial dimension are grayed\n",
        "  (set to 128).  Operations like translate and shear on a wrapped\n",
        "  Tensor will leave 0s in empty locations.  Some transformations look\n",
        "  at the intensity of values to do preprocessing, and we want these\n",
        "  empty pixels to assume the 'average' value, rather than pure black.\n",
        "  Args:\n",
        "    image: A 3D Image Tensor with 4 channels.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels.\n",
        "  Returns:\n",
        "    image: A 3D image Tensor with 3 channels.\n",
        "  \"\"\"\n",
        "  image_shape = tf.shape(image)\n",
        "  # Flatten the spatial dimensions.\n",
        "  flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
        " \n",
        "  # Find all pixels where the last channel is zero.\n",
        "  alpha_channel = flattened_image[:, 3]\n",
        " \n",
        "  replace = tf.concat([replace, tf.ones([1], image.dtype)], 0)\n",
        " \n",
        "  # Where they are zero, fill them in with 'replace'.\n",
        "  flattened_image = tf.where(\n",
        "      tf.equal(alpha_channel, 0),\n",
        "      tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
        "      flattened_image)\n",
        " \n",
        "  image = tf.reshape(flattened_image, image_shape)\n",
        "  image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], 3])\n",
        "  return image\n",
        " \n",
        "def TranslateX(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [-pixels, 0])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [pixels, 0], replace=0)\n",
        "TranslateX(test_image, 10)\n",
        "def TranslateY(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [0, -pixels])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [0, pixels], replace=0)\n",
        "TranslateY(test_image, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024, 1024, 3), dtype=uint8, numpy=\n",
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 39, 105,  58],\n",
              "        [ 48, 200,  14],\n",
              "        [252, 153, 184],\n",
              "        ...,\n",
              "        [165, 188,  58],\n",
              "        [ 87, 130, 172],\n",
              "        [144, 150,  59]],\n",
              "\n",
              "       [[148, 176,  50],\n",
              "        [135, 190,   2],\n",
              "        [ 74,  76,  24],\n",
              "        ...,\n",
              "        [204, 167,  36],\n",
              "        [124,  47,  90],\n",
              "        [139,  52, 186]],\n",
              "\n",
              "       [[  4,  41,  39],\n",
              "        [178, 146,  49],\n",
              "        [ 78,  61, 117],\n",
              "        ...,\n",
              "        [ 59, 143,  83],\n",
              "        [115,  34, 162],\n",
              "        [235,  28,  56]]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws5Tg2JZpE7g"
      },
      "source": [
        "class RandomResizedCrop:\n",
        "    \"\"\"Torchvision's variant of crop a random part of the input and rescale it to some size.\n",
        "    Args:\n",
        "        height (int): height after crop and resize.\n",
        "        width (int): width after crop and resize.\n",
        "        scale ((float, float)): range of size of the origin size cropped\n",
        "        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped\n",
        "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
        "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
        "            Default: cv2.INTER_LINEAR.\n",
        "        p (float): probability of applying the transform. Default: 1.\n",
        "    Targets:\n",
        "        image, mask, bboxes, keypoints\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        org_height,\n",
        "        org_width,\n",
        "        scale=(0.08, 1.0),\n",
        "        ratio=(0.75, 1.3333333333333333),\n",
        "    ):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.scale = scale\n",
        "        self.ratio = ratio\n",
        "        self.beforeheight = org_height\n",
        "        self.beforewidth = org_width\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start):\n",
        "        x1 = int((height - crop_height) * h_start)\n",
        "        x2 = x1 + crop_height\n",
        "        y1 = int((width - crop_width) * w_start)\n",
        "        y2 = y1 + crop_width\n",
        "        return x1, y1, x2, y2\n",
        "    \n",
        "    def __call__(self, img):\n",
        "\n",
        "        \n",
        "        area = img.shape[0] * img.shape[1]\n",
        "        #print(img.shape[0], img.shape[1])\n",
        "        for _attempt in range(10):\n",
        "            target_area = random.uniform(*self.scale) * area\n",
        "            log_ratio = (math.log(self.ratio[0]), math.log(self.ratio[1]))\n",
        "            aspect_ratio = math.exp(random.uniform(*log_ratio))\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            #print(w, h)\n",
        "            if 0 < w <= img.shape[1] and 0 < h <= img.shape[0]:\n",
        "                i = random.randint(0, img.shape[0] - h)\n",
        "                j = random.randint(0, img.shape[1] - w)\n",
        "                h_start = i * 1.0 / (img.shape[0] - h + 1e-10)\n",
        "                w_start = j * 1.0 / (img.shape[1] - w + 1e-10)\n",
        "                #print(h, w)\n",
        "                x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, h_start, w_start)\n",
        "                #print(h, w)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                img = img[x1:x2, y1:y2, :]\n",
        "                img = tf.image.resize(img, (self.height, self.width))\n",
        "                return tf.cast(img, dtype=tf.uint8)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        #print('central gogo')\n",
        "        in_ratio = img.shape[1] / img.shape[0]\n",
        "        if in_ratio < min(self.ratio):\n",
        "            w = img.shape[1]\n",
        "            h = int(round(w / min(self.ratio)))\n",
        "        elif in_ratio > max(self.ratio):\n",
        "            h = img.shape[0]\n",
        "            w = int(round(h * max(self.ratio)))\n",
        "        else:  # whole image\n",
        "            w = img.shape[1]\n",
        "            h = img.shape[0]\n",
        "        i = (img.shape[0] - h) // 2\n",
        "        j = (img.shape[1] - w) // 2\n",
        "        x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, i, j)\n",
        "        img = img[x1:x2, y1:y2, :]\n",
        "        img = tf.image.resize(img, (self.height, self.width))\n",
        "        return tf.cast(img, dtype=tf.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDsiU6PE6Zm"
      },
      "source": [
        "class Normalize:\n",
        "    \"\"\"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.\n",
        "    Args:\n",
        "        mean (float, list of float): mean values\n",
        "        std  (float, list of float): std values\n",
        "        max_pixel_value (float): maximum possible pixel value\n",
        "    Targets:\n",
        "        image\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mean=CFG.MEAN, std=CFG.STD, max_pixel_value=255.0, always_apply=False, p=1.0\n",
        "    ):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.max_pixel_value = max_pixel_value\n",
        "\n",
        "\n",
        "    \n",
        "    def normalize_image(self, img, mean, std, max_pixel_value=255.0):\n",
        "        mean = tf.convert_to_tensor(mean, dtype=tf.float32)\n",
        "        mean = mean * max_pixel_value\n",
        "\n",
        "        std = tf.convert_to_tensor(std, dtype=tf.float32)\n",
        "        std = std * max_pixel_value\n",
        "\n",
        "        denominator = tf.math.reciprocal(std)\n",
        "\n",
        "        #print('before cast', img)\n",
        "        img = tf.cast(img, dtype = tf.float32)\n",
        "        #print('after cast', img)\n",
        "        #img = img - mean\n",
        "        #img = img * denominator\n",
        "        img = img / 255.\n",
        "        return img\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.normalize_image(img, self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivUmviTzRd6"
      },
      "source": [
        "class CoarseDropout:\n",
        "  def __init__(self, max_holes, size=0.06):\n",
        "    self.size = size\n",
        "    self.max_holes = max_holes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __call__(self, image):\n",
        "      #holes = []\n",
        "      P = random.uniform(0,1)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      for _n in range(self.max_holes):\n",
        "          hole_height = height * self.size * P\n",
        "          hole_width = width * self.size * P\n",
        "          hole_height = int(hole_height)\n",
        "          hole_width = int(hole_width)\n",
        "          y1 = random.randint(0, height - hole_height)\n",
        "          x1 = random.randint(0, width- hole_width)\n",
        "          y2 = y1 + hole_height\n",
        "          x2 = x1 + hole_width\n",
        "          #holes.append((y1, x1, y2, x2))\n",
        "        \n",
        "          one = image[y1:y2,0:x1,:]\n",
        "          two = tf.zeros([y2-y1,x2-x1,3], dtype=tf.uint8) \n",
        "          three = image[y1:y2,x2:width,:]\n",
        "          middle = tf.concat([one,two,three],axis=1)\n",
        "          image = tf.concat([image[0:y1,:,:],middle,image[y2:height,:,:]],axis=0)\n",
        "      \n",
        "          \n",
        "      image = tf.cast(image, dtype=tf.uint8)\n",
        "      return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtmKcRRnLJS"
      },
      "source": [
        "def augment_list():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        (Rotate, -30, 30),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        (ShearX, -0.2, 0.2),\n",
        "        (ShearY, -0.2, 0.2),\n",
        "        (TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        (TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyHDbDpnfBk"
      },
      "source": [
        "import random\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqGkm0mLoW0"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    #print(image.shape, label.shape)\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    cutmix_start = 0.0\n",
        "    imgs = []; labs = []\n",
        "    \n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],cutmix_start,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM2),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM1),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)\n",
        "        b = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM2 * tf.math.sqrt(1-a),tf.int32) * P\n",
        "        HEIGHT = tf.cast( DIM1 * tf.math.sqrt(1-b), tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-HEIGHT//2)\n",
        "        yb = tf.math.minimum(DIM1,y+HEIGHT//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM2,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM2,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        cutmix_img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM1,:,:]],axis=0)\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_left_right(cutmix_img)\n",
        "        if p_v_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_up_down(cutmix_img)\n",
        "        if p_transpose > 0.5:\n",
        "            cutmix_img = tf.image.transpose(cutmix_img)\n",
        "        #cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #cutmix_img = tf.image.resize(cutmix_img, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #mixup_image = (1-a)*img1 + a*img2\n",
        "        cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #imgs.append(mixup_image)\n",
        "        imgs.append(cutmix_img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*HEIGHT/DIM1/DIM2,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2\n",
        " \n",
        " \n",
        " \n",
        "def mixup(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with mixup applied\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
        "        # CHOOSE RANDOM\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)*P # this is beta dist with alpha=1.0\n",
        "        # MAKE MIXUP IMAGE\n",
        "        img1 = image[j,]\n",
        "        img2 = image[k,]\n",
        "        #mixup_image = (1-0.5)*img1 + 0.5*img2\n",
        "        mixup_image = (1-a)*img1 + a*img2\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            mixup_image = tf.image.flip_left_right(mixup_image)\n",
        "        #if p_v_flip > 0.5:\n",
        "        #    mixup_image = tf.image.flip_up_down(mixup_image)\n",
        "        #if p_transpose > 0.5:\n",
        "        #    mixup_image = tf.image.transpose(mixup_image)\n",
        "        mixup_image = Normalize(CFG.MEAN, CFG.STD)(mixup_image)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        imgs.append(mixup_image)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxFwBse-yv"
      },
      "source": [
        "def real_data_augment(image, label):\n",
        "    k = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    if k < 0.33:\n",
        "        image2, label2 = mixup(image, label)\n",
        "    #elif (k >= -2) and (k < 0):\n",
        "    #    image2, label2 = cutmix(image, label)\n",
        "    else:\n",
        "        image2, label2 = data_augment(image, label)\n",
        " \n",
        "    return image2, label2 \n",
        " \n",
        "def prep_for_val(image, label):\n",
        "    \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(30)\n",
        "    #randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.85, 1.0))\n",
        " \n",
        "    #P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            img = tf.image.resize(img, [DIM1, DIM2])\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        " \n",
        " \n",
        "def data_augment(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(1)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.95, 1.0))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        " \n",
        "            img = randomcrop(img)\n",
        " \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            #if p_v_flip >= 0.5:\n",
        "            #    img = tf.image.flip_up_down(img)\n",
        "            #if p_transpose >= 0.5:\n",
        "            #    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "            #        img = tf.image.transpose(img)\n",
        " \n",
        "            #img = coarse(img)\n",
        "            img = randaug(img)\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECrHNVz2S4Dk",
        "outputId": "bfdf5ab3-2a35-46dd-a239-7dba0af16b4a"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8RTuBuSEpg"
      },
      "source": [
        "def decode_tr_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    \n",
        "    return image\n",
        " \n",
        "def decode_val_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    label = tf.reshape(label, [CFG.NUMBER_OF_CLASSES])\n",
        "    return image, label\n",
        "\n",
        "def decode_test_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def decode_just_test_image(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def decode_val_image_for_tta(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.99,1.0))\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = randomcrop(image)\n",
        "    if p_flip > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    if p_v_flip > 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "        if p_transpose > 0.5:\n",
        "            image = tf.image.transpose(image)\n",
        "    image = normalize(image) \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def read_tfrecord(example, labeled=True):\n",
        "    \"\"\"\n",
        "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
        "        2. Decode image.\n",
        "        3. If 'labeled' returns (image, label) if not (image, name).\n",
        "    \"\"\"\n",
        "    if labeled:\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'label': tf.io.VarLenFeature(dtype=tf.float32), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], tf.sparse.to_dense(example['label'])\n",
        "    else:\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], example['image_id']\n",
        "\n",
        "def read_test_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw'], example['image_id']\n",
        "\n",
        "def read_test_image_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image_raw']\n",
        " \n",
        "def load_dataset(filenames, validation, labeled=True, ordered=False, ):\n",
        "    \"\"\"\n",
        "        Create a Tensorflow dataset from TFRecords.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        " \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    if validation == False:\n",
        " \n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = False), num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = True), num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if (validation == True) and (labeled == False):\n",
        "        pass\n",
        "    elif (validation == False) and (labeled == True):\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : decode_val_image(image, label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    #else:\n",
        "    #        dataset = dataset.map(prep_for_val, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_test_dataset(FILENAMES, return_image_name=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()   \n",
        "    \n",
        "    \n",
        "    if return_image_name:\n",
        "        dataset = dataset.map(lambda example : read_test_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image, label : decode_test_image(image, label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_test_image_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image : decode_just_test_image(image), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset_for_tta(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if validation == False:\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVAoSVZoB-1"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    print(n)\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDqawNTsn1vX"
      },
      "source": [
        "from tensorflow_addons.utils.types import FloatTensorLike\n",
        " \n",
        "from typing import Union, Callable, Dict\n",
        "from typeguard import typechecked\n",
        " \n",
        " \n",
        "class CosineDecayRAdam(tfa.optimizers.RectifiedAdam):\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype)\n",
        "        wd_t = self._decayed_wd(var_dtype)\n",
        "        m = self.get_slot(var, \"m\")\n",
        "        v = self.get_slot(var, \"v\")\n",
        "        beta_1_t = self._get_hyper(\"beta_1\", var_dtype)\n",
        "        beta_2_t = self._get_hyper(\"beta_2\", var_dtype)\n",
        "        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_power = tf.pow(beta_1_t, local_step)\n",
        "        beta_2_power = tf.pow(beta_2_t, local_step)\n",
        " \n",
        "        if self._initial_total_steps > 0:\n",
        "            total_steps = self._get_hyper(\"total_steps\", var_dtype)\n",
        "            warmup_steps = total_steps * self._get_hyper(\"warmup_proportion\", var_dtype)\n",
        "            min_lr = self._get_hyper(\"min_lr\", var_dtype)\n",
        "            decay_steps = tf.maximum(total_steps - warmup_steps, 1)\n",
        "            decay_rate = (min_lr - lr_t) / decay_steps\n",
        "            pi = tf.constant(3.141592)\n",
        "            cos = tf.math.cos(pi * ((local_step - warmup_steps) / (total_steps - warmup_steps))) + tf.constant(1.)\n",
        "            lr_t = tf.where(\n",
        "                local_step <= warmup_steps,\n",
        "                lr_t * (local_step / warmup_steps),\n",
        "                #lr_t + decay_rate * tf.minimum(local_step - warmup_steps, decay_steps),\n",
        "                min_lr + (lr_t - min_lr) / 2. * cos\n",
        "            )\n",
        " \n",
        "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
        "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
        " \n",
        "        m_t = m.assign(\n",
        "            beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking\n",
        "        )\n",
        "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
        " \n",
        "        v_t = v.assign(\n",
        "            beta_2_t * v + (1.0 - beta_2_t) * tf.square(grad),\n",
        "            use_locking=self._use_locking,\n",
        "        )\n",
        "        if self.amsgrad:\n",
        "            vhat = self.get_slot(var, \"vhat\")\n",
        "            vhat_t = vhat.assign(tf.maximum(vhat, v_t), use_locking=self._use_locking)\n",
        "            v_corr_t = tf.sqrt(vhat_t / (1.0 - beta_2_power))\n",
        "        else:\n",
        "            vhat_t = None\n",
        "            v_corr_t = tf.sqrt(v_t / (1.0 - beta_2_power))\n",
        " \n",
        "        r_t = tf.sqrt(\n",
        "            (sma_t - 4.0)\n",
        "            / (sma_inf - 4.0)\n",
        "            * (sma_t - 2.0)\n",
        "            / (sma_inf - 2.0)\n",
        "            * sma_inf\n",
        "            / sma_t\n",
        "        )\n",
        " \n",
        "        sma_threshold = self._get_hyper(\"sma_threshold\", var_dtype)\n",
        "        var_t = tf.where(\n",
        "            sma_t >= sma_threshold, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t\n",
        "        )\n",
        " \n",
        "        if self._has_weight_decay:\n",
        "            var_t += wd_t * var\n",
        " \n",
        "        var_update = var.assign_sub(lr_t * var_t, use_locking=self._use_locking)\n",
        " \n",
        "        updates = [var_update, m_t, v_t]\n",
        "        if self.amsgrad:\n",
        "            updates.append(vhat_t)\n",
        "        return tf.group(*updates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZCnkM3BCN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2623902-e615-4f4a-f5de-ccd11cb21d36"
      },
      "source": [
        "LEARNING_RATE = 1e-5 * REPLICAS # -> LB->8921\n",
        " \n",
        "# RandomCropedSized FIX\n",
        "# Cosine Decay Radam\n",
        " \n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; normal_oof_pred = []; pred_max = []\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "seed_everything(SEED)\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    TRAINING_IMAGES = TRAINING_FILENAMES\n",
        " \n",
        "    train_dataset = get_dataset(TRAINING_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True, validation=False)\n",
        "    val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        " \n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tf.keras.backend.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"), \n",
        "                                                    monitor = 'val_auc', \n",
        "                                                    save_best_only = True,\n",
        "                                                    mode = 'max')\n",
        "    history = model.fit(train_dataset,  \n",
        "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                        epochs = CFG.EPOCHS,\n",
        "                        callbacks = [checkpoint],\n",
        "                        validation_data = val_dataset,\n",
        "                        verbose = 1,\n",
        "                        ).history\n",
        "    print(f\"#### FOLD {fold+1} without TTA VAL_AUC = {np.max(history['val_auc']):.3f}\")\n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n",
            "71680000/71678424 [==============================] - 2s 0us/step\n",
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 481s 1s/step - loss: 0.6916 - auc: 0.4895 - val_loss: 0.6862 - val_auc: 0.5121\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 937ms/step - loss: 0.6024 - auc: 0.5022 - val_loss: 0.5637 - val_auc: 0.5724\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.3572 - auc: 0.5427 - val_loss: 0.2910 - val_auc: 0.7030\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.2557 - auc: 0.6872 - val_loss: 0.2582 - val_auc: 0.8274\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.1980 - auc: 0.8011 - val_loss: 0.2610 - val_auc: 0.8692\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1759 - auc: 0.8231 - val_loss: 0.1835 - val_auc: 0.8951\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1665 - auc: 0.8106 - val_loss: 0.2098 - val_auc: 0.9018\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1535 - auc: 0.8148 - val_loss: 0.1574 - val_auc: 0.9159\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1514 - auc: 0.8314 - val_loss: 0.1476 - val_auc: 0.9251\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1423 - auc: 0.8527 - val_loss: 0.1310 - val_auc: 0.9319\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1395 - auc: 0.8631 - val_loss: 0.1291 - val_auc: 0.9319\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1413 - auc: 0.8305 - val_loss: 0.1220 - val_auc: 0.9358\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1422 - auc: 0.8354 - val_loss: 0.1177 - val_auc: 0.9412\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1275 - auc: 0.8730 - val_loss: 0.1156 - val_auc: 0.9396\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1330 - auc: 0.8396 - val_loss: 0.1202 - val_auc: 0.9338\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1216 - auc: 0.8727 - val_loss: 0.1108 - val_auc: 0.9427\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1325 - auc: 0.8288 - val_loss: 0.1080 - val_auc: 0.9456\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1242 - auc: 0.8672 - val_loss: 0.1138 - val_auc: 0.9487\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1168 - auc: 0.8372 - val_loss: 0.1087 - val_auc: 0.9448\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1119 - auc: 0.8753 - val_loss: 0.1118 - val_auc: 0.9465\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1117 - auc: 0.8886 - val_loss: 0.1245 - val_auc: 0.9374\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1103 - auc: 0.8693 - val_loss: 0.1101 - val_auc: 0.9480\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1042 - auc: 0.8922 - val_loss: 0.1103 - val_auc: 0.9415\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1062 - auc: 0.8831 - val_loss: 0.1088 - val_auc: 0.9457\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1046 - auc: 0.8650 - val_loss: 0.1038 - val_auc: 0.9510\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1045 - auc: 0.8600 - val_loss: 0.1055 - val_auc: 0.9527\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1041 - auc: 0.8742 - val_loss: 0.1066 - val_auc: 0.9505\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0981 - auc: 0.8907 - val_loss: 0.1016 - val_auc: 0.9538\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0919 - auc: 0.8917 - val_loss: 0.1054 - val_auc: 0.9509\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0911 - auc: 0.9174 - val_loss: 0.1012 - val_auc: 0.9520\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0891 - auc: 0.8957 - val_loss: 0.1158 - val_auc: 0.9473\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0883 - auc: 0.9099 - val_loss: 0.1041 - val_auc: 0.9516\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0882 - auc: 0.9067 - val_loss: 0.1037 - val_auc: 0.9535\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0894 - auc: 0.8761 - val_loss: 0.1059 - val_auc: 0.9515\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 954ms/step - loss: 0.0769 - auc: 0.9397 - val_loss: 0.1082 - val_auc: 0.9492\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0855 - auc: 0.8815 - val_loss: 0.1069 - val_auc: 0.9508\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0820 - auc: 0.9009 - val_loss: 0.1086 - val_auc: 0.9508\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0822 - auc: 0.8912 - val_loss: 0.1082 - val_auc: 0.9491\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0829 - auc: 0.8995 - val_loss: 0.1054 - val_auc: 0.9505\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0766 - auc: 0.9139 - val_loss: 0.1078 - val_auc: 0.9483\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0841 - auc: 0.8784 - val_loss: 0.1089 - val_auc: 0.9470\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.0833 - auc: 0.8838 - val_loss: 0.1069 - val_auc: 0.9492\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0796 - auc: 0.8923 - val_loss: 0.1082 - val_auc: 0.9478\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.0732 - auc: 0.9253 - val_loss: 0.1097 - val_auc: 0.9480\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0748 - auc: 0.9053 - val_loss: 0.1101 - val_auc: 0.9470\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0793 - auc: 0.8957 - val_loss: 0.1102 - val_auc: 0.9465\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0753 - auc: 0.9044 - val_loss: 0.1095 - val_auc: 0.9478\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0791 - auc: 0.8875 - val_loss: 0.1098 - val_auc: 0.9484\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0773 - auc: 0.9046 - val_loss: 0.1099 - val_auc: 0.9482\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0743 - auc: 0.9106 - val_loss: 0.1099 - val_auc: 0.9475\n",
            "#### FOLD 1 without TTA VAL_AUC = 0.954\n",
            "[1490, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 486s 1s/step - loss: 0.6992 - auc: 0.4972 - val_loss: 0.6909 - val_auc: 0.5220\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 938ms/step - loss: 0.6134 - auc: 0.5025 - val_loss: 0.5548 - val_auc: 0.5552\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.3664 - auc: 0.5428 - val_loss: 0.2877 - val_auc: 0.6765\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.2566 - auc: 0.6801 - val_loss: 0.2456 - val_auc: 0.7953\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.2080 - auc: 0.7887 - val_loss: 0.2139 - val_auc: 0.8531\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1789 - auc: 0.8202 - val_loss: 0.1756 - val_auc: 0.8880\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1680 - auc: 0.8014 - val_loss: 0.1647 - val_auc: 0.9046\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1640 - auc: 0.8163 - val_loss: 0.1509 - val_auc: 0.9174\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1572 - auc: 0.8195 - val_loss: 0.1426 - val_auc: 0.9246\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1447 - auc: 0.8421 - val_loss: 0.1532 - val_auc: 0.9290\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.1425 - auc: 0.8700 - val_loss: 0.1303 - val_auc: 0.9355\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1449 - auc: 0.8422 - val_loss: 0.1318 - val_auc: 0.9387\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1494 - auc: 0.8121 - val_loss: 0.1238 - val_auc: 0.9421\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1343 - auc: 0.8688 - val_loss: 0.1218 - val_auc: 0.9431\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1346 - auc: 0.8417 - val_loss: 0.1194 - val_auc: 0.9463\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 52s 998ms/step - loss: 0.1304 - auc: 0.8667 - val_loss: 0.1184 - val_auc: 0.9469\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1358 - auc: 0.8423 - val_loss: 0.1195 - val_auc: 0.9426\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1239 - auc: 0.8736 - val_loss: 0.1165 - val_auc: 0.9493\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1251 - auc: 0.8458 - val_loss: 0.1179 - val_auc: 0.9494\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 47s 901ms/step - loss: 0.1158 - auc: 0.8729 - val_loss: 0.1111 - val_auc: 0.9551\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.1149 - auc: 0.8912 - val_loss: 0.1098 - val_auc: 0.9557\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1163 - auc: 0.8682 - val_loss: 0.1125 - val_auc: 0.9563\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1117 - auc: 0.9012 - val_loss: 0.1120 - val_auc: 0.9519\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1107 - auc: 0.8791 - val_loss: 0.1100 - val_auc: 0.9526\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1159 - auc: 0.8657 - val_loss: 0.1108 - val_auc: 0.9557\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1129 - auc: 0.8616 - val_loss: 0.1089 - val_auc: 0.9584\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1119 - auc: 0.8540 - val_loss: 0.1080 - val_auc: 0.9567\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1009 - auc: 0.8929 - val_loss: 0.1109 - val_auc: 0.9567\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0987 - auc: 0.8961 - val_loss: 0.1188 - val_auc: 0.9499\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0934 - auc: 0.9163 - val_loss: 0.1145 - val_auc: 0.9518\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1004 - auc: 0.8952 - val_loss: 0.1137 - val_auc: 0.9516\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 901ms/step - loss: 0.0955 - auc: 0.8937 - val_loss: 0.1153 - val_auc: 0.9492\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0949 - auc: 0.9004 - val_loss: 0.1160 - val_auc: 0.9511\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0957 - auc: 0.8828 - val_loss: 0.1184 - val_auc: 0.9490\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0821 - auc: 0.9366 - val_loss: 0.1160 - val_auc: 0.9520\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0926 - auc: 0.8662 - val_loss: 0.1145 - val_auc: 0.9492\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0854 - auc: 0.8986 - val_loss: 0.1128 - val_auc: 0.9531\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.0874 - auc: 0.8962 - val_loss: 0.1214 - val_auc: 0.9477\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0869 - auc: 0.8901 - val_loss: 0.1170 - val_auc: 0.9488\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0806 - auc: 0.9131 - val_loss: 0.1188 - val_auc: 0.9489\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0891 - auc: 0.8735 - val_loss: 0.1174 - val_auc: 0.9484\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0867 - auc: 0.8792 - val_loss: 0.1140 - val_auc: 0.9487\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0831 - auc: 0.8903 - val_loss: 0.1181 - val_auc: 0.9470\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 46s 894ms/step - loss: 0.0726 - auc: 0.9252 - val_loss: 0.1169 - val_auc: 0.9471\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0759 - auc: 0.9155 - val_loss: 0.1154 - val_auc: 0.9470\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0793 - auc: 0.8844 - val_loss: 0.1168 - val_auc: 0.9471\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0753 - auc: 0.9011 - val_loss: 0.1165 - val_auc: 0.9472\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0795 - auc: 0.8983 - val_loss: 0.1169 - val_auc: 0.9473\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0772 - auc: 0.8955 - val_loss: 0.1168 - val_auc: 0.9470\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 46s 896ms/step - loss: 0.0759 - auc: 0.9029 - val_loss: 0.1168 - val_auc: 0.9470\n",
            "#### FOLD 2 without TTA VAL_AUC = 0.958\n",
            "[1490, 1501, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 487s 1s/step - loss: 0.6921 - auc: 0.4953 - val_loss: 0.6925 - val_auc: 0.5222\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 941ms/step - loss: 0.5998 - auc: 0.4952 - val_loss: 0.5519 - val_auc: 0.5938\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.3480 - auc: 0.5488 - val_loss: 0.2905 - val_auc: 0.6948\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.2510 - auc: 0.6947 - val_loss: 0.2257 - val_auc: 0.8256\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.2000 - auc: 0.7986 - val_loss: 0.1729 - val_auc: 0.8882\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1742 - auc: 0.8260 - val_loss: 0.1620 - val_auc: 0.9049\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1708 - auc: 0.7909 - val_loss: 0.1601 - val_auc: 0.9156\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1623 - auc: 0.8231 - val_loss: 0.1445 - val_auc: 0.9264\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1536 - auc: 0.8297 - val_loss: 0.1391 - val_auc: 0.9274\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1431 - auc: 0.8568 - val_loss: 0.1315 - val_auc: 0.9290\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1483 - auc: 0.8644 - val_loss: 0.1261 - val_auc: 0.9330\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1437 - auc: 0.8317 - val_loss: 0.1246 - val_auc: 0.9345\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1410 - auc: 0.8253 - val_loss: 0.1298 - val_auc: 0.9347\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1321 - auc: 0.8687 - val_loss: 0.1199 - val_auc: 0.9439\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1358 - auc: 0.8467 - val_loss: 0.1218 - val_auc: 0.9394\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 47s 908ms/step - loss: 0.1274 - auc: 0.8764 - val_loss: 0.1216 - val_auc: 0.9386\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1313 - auc: 0.8477 - val_loss: 0.1154 - val_auc: 0.9436\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1225 - auc: 0.8701 - val_loss: 0.1171 - val_auc: 0.9400\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1231 - auc: 0.8520 - val_loss: 0.1111 - val_auc: 0.9474\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1154 - auc: 0.8752 - val_loss: 0.1212 - val_auc: 0.9409\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1161 - auc: 0.8895 - val_loss: 0.1180 - val_auc: 0.9414\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1182 - auc: 0.8771 - val_loss: 0.1080 - val_auc: 0.9497\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1096 - auc: 0.8966 - val_loss: 0.1124 - val_auc: 0.9441\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1070 - auc: 0.8838 - val_loss: 0.1092 - val_auc: 0.9511\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1129 - auc: 0.8711 - val_loss: 0.1239 - val_auc: 0.9311\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1102 - auc: 0.8701 - val_loss: 0.1239 - val_auc: 0.9368\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1123 - auc: 0.8653 - val_loss: 0.1088 - val_auc: 0.9497\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1022 - auc: 0.8967 - val_loss: 0.1146 - val_auc: 0.9456\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0950 - auc: 0.9000 - val_loss: 0.1078 - val_auc: 0.9529\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0957 - auc: 0.9151 - val_loss: 0.1074 - val_auc: 0.9542\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0954 - auc: 0.9009 - val_loss: 0.1079 - val_auc: 0.9537\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 51s 982ms/step - loss: 0.0924 - auc: 0.9047 - val_loss: 0.1075 - val_auc: 0.9568\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0908 - auc: 0.9004 - val_loss: 0.1163 - val_auc: 0.9497\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0960 - auc: 0.8837 - val_loss: 0.1191 - val_auc: 0.9412\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0836 - auc: 0.9374 - val_loss: 0.1127 - val_auc: 0.9512\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0917 - auc: 0.8770 - val_loss: 0.1129 - val_auc: 0.9454\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0850 - auc: 0.9009 - val_loss: 0.1154 - val_auc: 0.9408\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0842 - auc: 0.8891 - val_loss: 0.1164 - val_auc: 0.9465\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0867 - auc: 0.8935 - val_loss: 0.1144 - val_auc: 0.9458\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0803 - auc: 0.9147 - val_loss: 0.1178 - val_auc: 0.9444\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0871 - auc: 0.8816 - val_loss: 0.1138 - val_auc: 0.9463\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0868 - auc: 0.8853 - val_loss: 0.1119 - val_auc: 0.9503\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0791 - auc: 0.8954 - val_loss: 0.1188 - val_auc: 0.9449\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0728 - auc: 0.9262 - val_loss: 0.1164 - val_auc: 0.9461\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0752 - auc: 0.9175 - val_loss: 0.1166 - val_auc: 0.9464\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0829 - auc: 0.8967 - val_loss: 0.1145 - val_auc: 0.9467\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0739 - auc: 0.9174 - val_loss: 0.1160 - val_auc: 0.9462\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0785 - auc: 0.8870 - val_loss: 0.1159 - val_auc: 0.9470\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0770 - auc: 0.8915 - val_loss: 0.1159 - val_auc: 0.9466\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0734 - auc: 0.9094 - val_loss: 0.1164 - val_auc: 0.9467\n",
            "#### FOLD 3 without TTA VAL_AUC = 0.957\n",
            "[1490, 1501, 1500, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 492s 1s/step - loss: 0.6927 - auc: 0.5049 - val_loss: 0.7064 - val_auc: 0.4971\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.6117 - auc: 0.4989 - val_loss: 0.5407 - val_auc: 0.5676\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.3574 - auc: 0.5427 - val_loss: 0.2666 - val_auc: 0.6928\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.2461 - auc: 0.7045 - val_loss: 0.2155 - val_auc: 0.8268\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1919 - auc: 0.7932 - val_loss: 0.1806 - val_auc: 0.8656\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.1721 - auc: 0.8229 - val_loss: 0.1817 - val_auc: 0.8864\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1660 - auc: 0.7988 - val_loss: 0.1742 - val_auc: 0.8919\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1597 - auc: 0.8328 - val_loss: 0.1664 - val_auc: 0.9024\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1540 - auc: 0.8346 - val_loss: 0.1521 - val_auc: 0.9035\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1493 - auc: 0.8448 - val_loss: 0.1404 - val_auc: 0.9200\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1392 - auc: 0.8692 - val_loss: 0.1372 - val_auc: 0.9216\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1435 - auc: 0.8396 - val_loss: 0.1309 - val_auc: 0.9262\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1408 - auc: 0.8302 - val_loss: 0.1230 - val_auc: 0.9334\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1342 - auc: 0.8747 - val_loss: 0.1218 - val_auc: 0.9332\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1339 - auc: 0.8449 - val_loss: 0.1165 - val_auc: 0.9405\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1285 - auc: 0.8672 - val_loss: 0.1152 - val_auc: 0.9441\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1368 - auc: 0.8294 - val_loss: 0.1142 - val_auc: 0.9390\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1243 - auc: 0.8767 - val_loss: 0.1108 - val_auc: 0.9455\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1291 - auc: 0.8507 - val_loss: 0.1156 - val_auc: 0.9424\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1165 - auc: 0.8828 - val_loss: 0.1076 - val_auc: 0.9512\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1187 - auc: 0.8729 - val_loss: 0.1052 - val_auc: 0.9517\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1158 - auc: 0.8664 - val_loss: 0.1067 - val_auc: 0.9519\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1066 - auc: 0.8920 - val_loss: 0.1096 - val_auc: 0.9492\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1118 - auc: 0.8733 - val_loss: 0.1195 - val_auc: 0.9408\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1078 - auc: 0.8696 - val_loss: 0.1075 - val_auc: 0.9493\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1119 - auc: 0.8653 - val_loss: 0.1078 - val_auc: 0.9533\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1104 - auc: 0.8666 - val_loss: 0.1115 - val_auc: 0.9486\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1003 - auc: 0.8936 - val_loss: 0.1087 - val_auc: 0.9534\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0995 - auc: 0.8986 - val_loss: 0.1128 - val_auc: 0.9467\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0954 - auc: 0.9145 - val_loss: 0.1160 - val_auc: 0.9441\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0954 - auc: 0.8913 - val_loss: 0.1106 - val_auc: 0.9479\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0952 - auc: 0.8989 - val_loss: 0.1133 - val_auc: 0.9470\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0915 - auc: 0.9090 - val_loss: 0.1160 - val_auc: 0.9447\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 954ms/step - loss: 0.0982 - auc: 0.8767 - val_loss: 0.1136 - val_auc: 0.9462\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0821 - auc: 0.9408 - val_loss: 0.1173 - val_auc: 0.9489\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0966 - auc: 0.8731 - val_loss: 0.1106 - val_auc: 0.9511\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0876 - auc: 0.9089 - val_loss: 0.1104 - val_auc: 0.9514\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0868 - auc: 0.9021 - val_loss: 0.1145 - val_auc: 0.9464\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0846 - auc: 0.8983 - val_loss: 0.1141 - val_auc: 0.9454\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0774 - auc: 0.9116 - val_loss: 0.1144 - val_auc: 0.9456\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 47s 904ms/step - loss: 0.0875 - auc: 0.8764 - val_loss: 0.1170 - val_auc: 0.9429\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0832 - auc: 0.8774 - val_loss: 0.1134 - val_auc: 0.9457\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0812 - auc: 0.8837 - val_loss: 0.1151 - val_auc: 0.9454\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0698 - auc: 0.9306 - val_loss: 0.1159 - val_auc: 0.9444\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 52s 1s/step - loss: 0.0741 - auc: 0.9043 - val_loss: 0.1155 - val_auc: 0.9445\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.0790 - auc: 0.8946 - val_loss: 0.1150 - val_auc: 0.9459\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0736 - auc: 0.9131 - val_loss: 0.1156 - val_auc: 0.9453\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0768 - auc: 0.8811 - val_loss: 0.1155 - val_auc: 0.9456\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0750 - auc: 0.8985 - val_loss: 0.1154 - val_auc: 0.9455\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0737 - auc: 0.9081 - val_loss: 0.1156 - val_auc: 0.9454\n",
            "#### FOLD 4 without TTA VAL_AUC = 0.953\n",
            "[1490, 1501, 1500, 1495, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 487s 1s/step - loss: 0.6967 - auc: 0.4969 - val_loss: 0.6499 - val_auc: 0.5019\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.6061 - auc: 0.4909 - val_loss: 0.5422 - val_auc: 0.5686\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.3525 - auc: 0.5444 - val_loss: 0.2939 - val_auc: 0.7118\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.2520 - auc: 0.7072 - val_loss: 0.2128 - val_auc: 0.8278\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.2019 - auc: 0.7985 - val_loss: 0.1968 - val_auc: 0.8601\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1716 - auc: 0.8161 - val_loss: 0.1639 - val_auc: 0.8933\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1735 - auc: 0.7976 - val_loss: 0.1567 - val_auc: 0.9115\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1569 - auc: 0.8251 - val_loss: 0.1492 - val_auc: 0.9212\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1554 - auc: 0.8330 - val_loss: 0.1437 - val_auc: 0.9290\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1467 - auc: 0.8329 - val_loss: 0.1590 - val_auc: 0.9336\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1414 - auc: 0.8763 - val_loss: 0.1276 - val_auc: 0.9363\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1498 - auc: 0.8228 - val_loss: 0.1239 - val_auc: 0.9402\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1441 - auc: 0.8321 - val_loss: 0.1282 - val_auc: 0.9422\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1320 - auc: 0.8656 - val_loss: 0.1191 - val_auc: 0.9462\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.1403 - auc: 0.8410 - val_loss: 0.1147 - val_auc: 0.9487\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1308 - auc: 0.8763 - val_loss: 0.1217 - val_auc: 0.9484\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1327 - auc: 0.8409 - val_loss: 0.1084 - val_auc: 0.9505\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1274 - auc: 0.8671 - val_loss: 0.1073 - val_auc: 0.9524\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 47s 907ms/step - loss: 0.1321 - auc: 0.8435 - val_loss: 0.1031 - val_auc: 0.9569\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1194 - auc: 0.8767 - val_loss: 0.1041 - val_auc: 0.9516\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1170 - auc: 0.8841 - val_loss: 0.1024 - val_auc: 0.9539\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1163 - auc: 0.8767 - val_loss: 0.1096 - val_auc: 0.9558\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1081 - auc: 0.9051 - val_loss: 0.0984 - val_auc: 0.9581\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1111 - auc: 0.8877 - val_loss: 0.1013 - val_auc: 0.9547\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1139 - auc: 0.8641 - val_loss: 0.1024 - val_auc: 0.9551\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1132 - auc: 0.8643 - val_loss: 0.1017 - val_auc: 0.9550\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1165 - auc: 0.8592 - val_loss: 0.0995 - val_auc: 0.9602\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1047 - auc: 0.8911 - val_loss: 0.0990 - val_auc: 0.9569\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0993 - auc: 0.9031 - val_loss: 0.1022 - val_auc: 0.9558\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0955 - auc: 0.9156 - val_loss: 0.0987 - val_auc: 0.9579\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0999 - auc: 0.8944 - val_loss: 0.1042 - val_auc: 0.9579\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.0960 - auc: 0.8996 - val_loss: 0.0993 - val_auc: 0.9596\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0942 - auc: 0.9039 - val_loss: 0.1024 - val_auc: 0.9574\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 48s 921ms/step - loss: 0.0953 - auc: 0.8844 - val_loss: 0.0997 - val_auc: 0.9588\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0836 - auc: 0.9360 - val_loss: 0.1019 - val_auc: 0.9561\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0939 - auc: 0.8779 - val_loss: 0.1035 - val_auc: 0.9553\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0870 - auc: 0.9111 - val_loss: 0.1007 - val_auc: 0.9589\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0885 - auc: 0.8897 - val_loss: 0.1006 - val_auc: 0.9597\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.0885 - auc: 0.8970 - val_loss: 0.0993 - val_auc: 0.9613\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0815 - auc: 0.9157 - val_loss: 0.1051 - val_auc: 0.9539\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0898 - auc: 0.8725 - val_loss: 0.1048 - val_auc: 0.9533\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0890 - auc: 0.8790 - val_loss: 0.1035 - val_auc: 0.9563\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0824 - auc: 0.8889 - val_loss: 0.1050 - val_auc: 0.9554\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0741 - auc: 0.9289 - val_loss: 0.1019 - val_auc: 0.9567\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0778 - auc: 0.9135 - val_loss: 0.1032 - val_auc: 0.9564\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0813 - auc: 0.8903 - val_loss: 0.1031 - val_auc: 0.9563\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 45s 864ms/step - loss: 0.0774 - auc: 0.9065 - val_loss: 0.1020 - val_auc: 0.9555\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0790 - auc: 0.8841 - val_loss: 0.1004 - val_auc: 0.9568\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0794 - auc: 0.8850 - val_loss: 0.1038 - val_auc: 0.9563\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0758 - auc: 0.9053 - val_loss: 0.1041 - val_auc: 0.9556\n",
            "#### FOLD 5 without TTA VAL_AUC = 0.961\n",
            "[1490, 1501, 1500, 1495, 1501, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 499s 1s/step - loss: 0.7023 - auc: 0.5116 - val_loss: 0.6651 - val_auc: 0.5061\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.6176 - auc: 0.4866 - val_loss: 0.5661 - val_auc: 0.5577\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.3566 - auc: 0.5456 - val_loss: 0.3018 - val_auc: 0.6998\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.2553 - auc: 0.6623 - val_loss: 0.2333 - val_auc: 0.7998\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.2010 - auc: 0.7831 - val_loss: 0.2000 - val_auc: 0.8701\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1750 - auc: 0.8192 - val_loss: 0.1687 - val_auc: 0.9010\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1686 - auc: 0.8020 - val_loss: 0.1536 - val_auc: 0.9154\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1581 - auc: 0.8288 - val_loss: 0.1494 - val_auc: 0.9194\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1548 - auc: 0.8254 - val_loss: 0.1352 - val_auc: 0.9306\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1477 - auc: 0.8482 - val_loss: 0.1279 - val_auc: 0.9308\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1417 - auc: 0.8740 - val_loss: 0.1281 - val_auc: 0.9416\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1437 - auc: 0.8306 - val_loss: 0.1189 - val_auc: 0.9448\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1437 - auc: 0.8338 - val_loss: 0.1164 - val_auc: 0.9453\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 48s 918ms/step - loss: 0.1354 - auc: 0.8705 - val_loss: 0.1132 - val_auc: 0.9505\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1353 - auc: 0.8464 - val_loss: 0.1111 - val_auc: 0.9525\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1338 - auc: 0.8601 - val_loss: 0.1391 - val_auc: 0.9469\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1329 - auc: 0.8364 - val_loss: 0.1084 - val_auc: 0.9565\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1257 - auc: 0.8696 - val_loss: 0.1092 - val_auc: 0.9551\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1316 - auc: 0.8596 - val_loss: 0.1124 - val_auc: 0.9566\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1166 - auc: 0.8739 - val_loss: 0.1039 - val_auc: 0.9565\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1176 - auc: 0.8840 - val_loss: 0.1031 - val_auc: 0.9568\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1133 - auc: 0.8696 - val_loss: 0.1075 - val_auc: 0.9620\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1072 - auc: 0.8903 - val_loss: 0.1026 - val_auc: 0.9551\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1146 - auc: 0.8851 - val_loss: 0.1012 - val_auc: 0.9603\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1152 - auc: 0.8658 - val_loss: 0.1029 - val_auc: 0.9552\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1111 - auc: 0.8668 - val_loss: 0.1041 - val_auc: 0.9572\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1119 - auc: 0.8680 - val_loss: 0.1006 - val_auc: 0.9588\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1006 - auc: 0.8959 - val_loss: 0.1042 - val_auc: 0.9560\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0985 - auc: 0.8985 - val_loss: 0.1064 - val_auc: 0.9556\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0946 - auc: 0.9189 - val_loss: 0.1030 - val_auc: 0.9564\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0952 - auc: 0.8920 - val_loss: 0.1022 - val_auc: 0.9578\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0954 - auc: 0.9031 - val_loss: 0.1007 - val_auc: 0.9584\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0935 - auc: 0.9056 - val_loss: 0.1014 - val_auc: 0.9567\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 973ms/step - loss: 0.0982 - auc: 0.8871 - val_loss: 0.1037 - val_auc: 0.9563\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0813 - auc: 0.9401 - val_loss: 0.1054 - val_auc: 0.9537\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.0933 - auc: 0.8746 - val_loss: 0.1020 - val_auc: 0.9582\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 973ms/step - loss: 0.0872 - auc: 0.9087 - val_loss: 0.1043 - val_auc: 0.9578\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0886 - auc: 0.8975 - val_loss: 0.1042 - val_auc: 0.9537\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0860 - auc: 0.9015 - val_loss: 0.1034 - val_auc: 0.9550\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 913ms/step - loss: 0.0800 - auc: 0.9206 - val_loss: 0.1045 - val_auc: 0.9535\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0881 - auc: 0.8863 - val_loss: 0.1032 - val_auc: 0.9545\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0882 - auc: 0.8746 - val_loss: 0.1039 - val_auc: 0.9543\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0804 - auc: 0.8933 - val_loss: 0.1064 - val_auc: 0.9535\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0721 - auc: 0.9314 - val_loss: 0.1057 - val_auc: 0.9506\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0736 - auc: 0.9034 - val_loss: 0.1060 - val_auc: 0.9506\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0787 - auc: 0.8862 - val_loss: 0.1063 - val_auc: 0.9536\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0760 - auc: 0.9158 - val_loss: 0.1059 - val_auc: 0.9537\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0768 - auc: 0.9028 - val_loss: 0.1061 - val_auc: 0.9537\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 48s 916ms/step - loss: 0.0763 - auc: 0.8960 - val_loss: 0.1060 - val_auc: 0.9538\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0732 - auc: 0.9080 - val_loss: 0.1060 - val_auc: 0.9538\n",
            "#### FOLD 6 without TTA VAL_AUC = 0.962\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 495s 1s/step - loss: 0.6848 - auc: 0.4895 - val_loss: 0.7269 - val_auc: 0.4967\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 939ms/step - loss: 0.6023 - auc: 0.5045 - val_loss: 0.5396 - val_auc: 0.5758\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.3450 - auc: 0.5565 - val_loss: 0.2727 - val_auc: 0.7205\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.2460 - auc: 0.7080 - val_loss: 0.2025 - val_auc: 0.8568\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1968 - auc: 0.7956 - val_loss: 0.1741 - val_auc: 0.8899\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1744 - auc: 0.8260 - val_loss: 0.1558 - val_auc: 0.9050\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1662 - auc: 0.8023 - val_loss: 0.1537 - val_auc: 0.9216\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.1558 - auc: 0.8160 - val_loss: 0.1433 - val_auc: 0.9290\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1576 - auc: 0.8317 - val_loss: 0.1390 - val_auc: 0.9357\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.1452 - auc: 0.8481 - val_loss: 0.1284 - val_auc: 0.9373\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 48s 919ms/step - loss: 0.1406 - auc: 0.8774 - val_loss: 0.1289 - val_auc: 0.9388\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1465 - auc: 0.8260 - val_loss: 0.1181 - val_auc: 0.9458\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 971ms/step - loss: 0.1399 - auc: 0.8361 - val_loss: 0.1247 - val_auc: 0.9491\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1309 - auc: 0.8702 - val_loss: 0.1145 - val_auc: 0.9528\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1321 - auc: 0.8473 - val_loss: 0.1086 - val_auc: 0.9525\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1293 - auc: 0.8777 - val_loss: 0.1164 - val_auc: 0.9515\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1316 - auc: 0.8327 - val_loss: 0.1055 - val_auc: 0.9567\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1247 - auc: 0.8753 - val_loss: 0.1039 - val_auc: 0.9595\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1258 - auc: 0.8396 - val_loss: 0.1058 - val_auc: 0.9566\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.1161 - auc: 0.8678 - val_loss: 0.1019 - val_auc: 0.9606\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.1153 - auc: 0.8928 - val_loss: 0.1033 - val_auc: 0.9552\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.1163 - auc: 0.8700 - val_loss: 0.1035 - val_auc: 0.9567\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1058 - auc: 0.8942 - val_loss: 0.1020 - val_auc: 0.9563\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.1108 - auc: 0.8772 - val_loss: 0.1054 - val_auc: 0.9554\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 47s 914ms/step - loss: 0.1109 - auc: 0.8734 - val_loss: 0.1014 - val_auc: 0.9580\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1144 - auc: 0.8566 - val_loss: 0.1057 - val_auc: 0.9548\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1086 - auc: 0.8615 - val_loss: 0.1003 - val_auc: 0.9587\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.1016 - auc: 0.8942 - val_loss: 0.1022 - val_auc: 0.9561\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0974 - auc: 0.9057 - val_loss: 0.1014 - val_auc: 0.9572\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0963 - auc: 0.9181 - val_loss: 0.1048 - val_auc: 0.9543\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0983 - auc: 0.8949 - val_loss: 0.1007 - val_auc: 0.9566\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0919 - auc: 0.9091 - val_loss: 0.1048 - val_auc: 0.9563\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0900 - auc: 0.8967 - val_loss: 0.1035 - val_auc: 0.9560\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 972ms/step - loss: 0.0955 - auc: 0.8799 - val_loss: 0.1060 - val_auc: 0.9560\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0821 - auc: 0.9456 - val_loss: 0.1067 - val_auc: 0.9559\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0976 - auc: 0.8670 - val_loss: 0.1051 - val_auc: 0.9567\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0857 - auc: 0.9078 - val_loss: 0.1067 - val_auc: 0.9555\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0856 - auc: 0.9006 - val_loss: 0.1074 - val_auc: 0.9513\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.0852 - auc: 0.8983 - val_loss: 0.1048 - val_auc: 0.9530\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0781 - auc: 0.9154 - val_loss: 0.1046 - val_auc: 0.9525\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0872 - auc: 0.8724 - val_loss: 0.1051 - val_auc: 0.9531\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 970ms/step - loss: 0.0843 - auc: 0.8797 - val_loss: 0.1068 - val_auc: 0.9523\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 969ms/step - loss: 0.0814 - auc: 0.8925 - val_loss: 0.1082 - val_auc: 0.9533\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.0723 - auc: 0.9327 - val_loss: 0.1036 - val_auc: 0.9547\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 968ms/step - loss: 0.0774 - auc: 0.9122 - val_loss: 0.1033 - val_auc: 0.9551\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0783 - auc: 0.8888 - val_loss: 0.1035 - val_auc: 0.9542\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 48s 917ms/step - loss: 0.0749 - auc: 0.9088 - val_loss: 0.1044 - val_auc: 0.9546\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0781 - auc: 0.8829 - val_loss: 0.1049 - val_auc: 0.9545\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0767 - auc: 0.8984 - val_loss: 0.1051 - val_auc: 0.9545\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 967ms/step - loss: 0.0694 - auc: 0.9049 - val_loss: 0.1052 - val_auc: 0.9545\n",
            "#### FOLD 7 without TTA VAL_AUC = 0.961\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 496s 1s/step - loss: 0.7071 - auc: 0.5090 - val_loss: 0.6831 - val_auc: 0.4913\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 943ms/step - loss: 0.6165 - auc: 0.5052 - val_loss: 0.5683 - val_auc: 0.5336\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.3526 - auc: 0.5491 - val_loss: 0.3055 - val_auc: 0.6615\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.2545 - auc: 0.6673 - val_loss: 0.2266 - val_auc: 0.7888\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 47s 909ms/step - loss: 0.2011 - auc: 0.7874 - val_loss: 0.2073 - val_auc: 0.8424\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1750 - auc: 0.8219 - val_loss: 0.1731 - val_auc: 0.8836\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1702 - auc: 0.7897 - val_loss: 0.1657 - val_auc: 0.9043\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1588 - auc: 0.8142 - val_loss: 0.1481 - val_auc: 0.9149\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1563 - auc: 0.8217 - val_loss: 0.1446 - val_auc: 0.9214\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.1476 - auc: 0.8443 - val_loss: 0.1411 - val_auc: 0.9215\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1498 - auc: 0.8763 - val_loss: 0.1316 - val_auc: 0.9276\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1452 - auc: 0.8305 - val_loss: 0.1260 - val_auc: 0.9304\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1399 - auc: 0.8361 - val_loss: 0.1245 - val_auc: 0.9363\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1314 - auc: 0.8709 - val_loss: 0.1176 - val_auc: 0.9386\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1346 - auc: 0.8382 - val_loss: 0.1164 - val_auc: 0.9410\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1270 - auc: 0.8828 - val_loss: 0.1179 - val_auc: 0.9430\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.1339 - auc: 0.8353 - val_loss: 0.1137 - val_auc: 0.9454\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1247 - auc: 0.8727 - val_loss: 0.1109 - val_auc: 0.9432\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1286 - auc: 0.8398 - val_loss: 0.1119 - val_auc: 0.9441\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1215 - auc: 0.8694 - val_loss: 0.1117 - val_auc: 0.9462\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1163 - auc: 0.8842 - val_loss: 0.1078 - val_auc: 0.9478\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1156 - auc: 0.8697 - val_loss: 0.1109 - val_auc: 0.9497\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.1078 - auc: 0.9051 - val_loss: 0.1106 - val_auc: 0.9438\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 47s 902ms/step - loss: 0.1125 - auc: 0.8822 - val_loss: 0.1147 - val_auc: 0.9447\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1116 - auc: 0.8678 - val_loss: 0.1088 - val_auc: 0.9444\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1167 - auc: 0.8628 - val_loss: 0.1081 - val_auc: 0.9451\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1094 - auc: 0.8646 - val_loss: 0.1055 - val_auc: 0.9485\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.1035 - auc: 0.8986 - val_loss: 0.1164 - val_auc: 0.9410\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0995 - auc: 0.9000 - val_loss: 0.1088 - val_auc: 0.9443\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.0944 - auc: 0.9132 - val_loss: 0.1092 - val_auc: 0.9412\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.1007 - auc: 0.8936 - val_loss: 0.1111 - val_auc: 0.9406\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0911 - auc: 0.9029 - val_loss: 0.1059 - val_auc: 0.9506\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0940 - auc: 0.8976 - val_loss: 0.1063 - val_auc: 0.9471\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0955 - auc: 0.8726 - val_loss: 0.1100 - val_auc: 0.9433\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 47s 911ms/step - loss: 0.0828 - auc: 0.9368 - val_loss: 0.1121 - val_auc: 0.9422\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 47s 910ms/step - loss: 0.0953 - auc: 0.8774 - val_loss: 0.1111 - val_auc: 0.9396\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0881 - auc: 0.9076 - val_loss: 0.1062 - val_auc: 0.9500\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0889 - auc: 0.9043 - val_loss: 0.1100 - val_auc: 0.9444\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 47s 908ms/step - loss: 0.0865 - auc: 0.9048 - val_loss: 0.1092 - val_auc: 0.9438\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0839 - auc: 0.9100 - val_loss: 0.1070 - val_auc: 0.9453\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 953ms/step - loss: 0.0893 - auc: 0.8761 - val_loss: 0.1082 - val_auc: 0.9445\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.0900 - auc: 0.8814 - val_loss: 0.1092 - val_auc: 0.9430\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.0845 - auc: 0.8924 - val_loss: 0.1112 - val_auc: 0.9396\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.0771 - auc: 0.9256 - val_loss: 0.1112 - val_auc: 0.9404\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 955ms/step - loss: 0.0797 - auc: 0.9112 - val_loss: 0.1093 - val_auc: 0.9463\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.0836 - auc: 0.8885 - val_loss: 0.1097 - val_auc: 0.9443\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0809 - auc: 0.9108 - val_loss: 0.1106 - val_auc: 0.9428\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 47s 906ms/step - loss: 0.0800 - auc: 0.8880 - val_loss: 0.1111 - val_auc: 0.9429\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.0802 - auc: 0.9004 - val_loss: 0.1111 - val_auc: 0.9433\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 47s 903ms/step - loss: 0.0783 - auc: 0.9121 - val_loss: 0.1110 - val_auc: 0.9432\n",
            "#### FOLD 8 without TTA VAL_AUC = 0.951\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 489s 1s/step - loss: 0.7094 - auc: 0.5000 - val_loss: 0.6767 - val_auc: 0.4511\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 940ms/step - loss: 0.6171 - auc: 0.4947 - val_loss: 0.5461 - val_auc: 0.4978\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.3664 - auc: 0.5408 - val_loss: 0.2922 - val_auc: 0.6526\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.2595 - auc: 0.6576 - val_loss: 0.2307 - val_auc: 0.7781\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.2010 - auc: 0.7871 - val_loss: 0.1959 - val_auc: 0.8573\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 51s 993ms/step - loss: 0.1751 - auc: 0.8248 - val_loss: 0.1713 - val_auc: 0.8841\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1702 - auc: 0.8043 - val_loss: 0.1566 - val_auc: 0.9038\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1562 - auc: 0.8203 - val_loss: 0.1527 - val_auc: 0.9131\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 47s 899ms/step - loss: 0.1568 - auc: 0.8301 - val_loss: 0.1420 - val_auc: 0.9200\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1487 - auc: 0.8413 - val_loss: 0.1366 - val_auc: 0.9249\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1449 - auc: 0.8737 - val_loss: 0.1277 - val_auc: 0.9329\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1449 - auc: 0.8279 - val_loss: 0.1246 - val_auc: 0.9363\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1415 - auc: 0.8334 - val_loss: 0.1445 - val_auc: 0.9394\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1313 - auc: 0.8787 - val_loss: 0.1192 - val_auc: 0.9433\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1359 - auc: 0.8418 - val_loss: 0.1160 - val_auc: 0.9474\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1271 - auc: 0.8813 - val_loss: 0.1171 - val_auc: 0.9519\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 49s 951ms/step - loss: 0.1342 - auc: 0.8381 - val_loss: 0.1116 - val_auc: 0.9518\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1237 - auc: 0.8755 - val_loss: 0.1110 - val_auc: 0.9478\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1291 - auc: 0.8515 - val_loss: 0.1101 - val_auc: 0.9515\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1210 - auc: 0.8725 - val_loss: 0.1064 - val_auc: 0.9567\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 49s 952ms/step - loss: 0.1152 - auc: 0.8986 - val_loss: 0.1070 - val_auc: 0.9605\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1154 - auc: 0.8620 - val_loss: 0.1063 - val_auc: 0.9564\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.1129 - auc: 0.9025 - val_loss: 0.1057 - val_auc: 0.9568\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1109 - auc: 0.8756 - val_loss: 0.1021 - val_auc: 0.9615\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 49s 950ms/step - loss: 0.1158 - auc: 0.8654 - val_loss: 0.1024 - val_auc: 0.9606\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.1152 - auc: 0.8640 - val_loss: 0.1065 - val_auc: 0.9523\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 49s 942ms/step - loss: 0.1061 - auc: 0.8637 - val_loss: 0.1021 - val_auc: 0.9655\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.1026 - auc: 0.8963 - val_loss: 0.1021 - val_auc: 0.9648\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.1020 - auc: 0.8968 - val_loss: 0.1022 - val_auc: 0.9614\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.0971 - auc: 0.9128 - val_loss: 0.1022 - val_auc: 0.9596\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.1003 - auc: 0.8948 - val_loss: 0.1040 - val_auc: 0.9598\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 47s 900ms/step - loss: 0.1001 - auc: 0.9136 - val_loss: 0.1044 - val_auc: 0.9553\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0975 - auc: 0.9015 - val_loss: 0.1010 - val_auc: 0.9597\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0991 - auc: 0.8880 - val_loss: 0.1065 - val_auc: 0.9516\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 46s 893ms/step - loss: 0.0850 - auc: 0.9309 - val_loss: 0.1027 - val_auc: 0.9598\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0944 - auc: 0.8832 - val_loss: 0.1026 - val_auc: 0.9583\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0891 - auc: 0.8965 - val_loss: 0.1058 - val_auc: 0.9554\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0875 - auc: 0.8954 - val_loss: 0.1058 - val_auc: 0.9548\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 49s 945ms/step - loss: 0.0890 - auc: 0.8889 - val_loss: 0.1023 - val_auc: 0.9550\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 47s 897ms/step - loss: 0.0844 - auc: 0.9122 - val_loss: 0.1041 - val_auc: 0.9557\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 49s 947ms/step - loss: 0.0951 - auc: 0.8766 - val_loss: 0.1029 - val_auc: 0.9552\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0900 - auc: 0.8911 - val_loss: 0.1032 - val_auc: 0.9543\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 49s 948ms/step - loss: 0.0843 - auc: 0.9013 - val_loss: 0.1058 - val_auc: 0.9530\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0793 - auc: 0.9249 - val_loss: 0.1056 - val_auc: 0.9531\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0789 - auc: 0.9110 - val_loss: 0.1050 - val_auc: 0.9518\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 49s 949ms/step - loss: 0.0821 - auc: 0.8985 - val_loss: 0.1060 - val_auc: 0.9515\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0780 - auc: 0.9100 - val_loss: 0.1054 - val_auc: 0.9522\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 49s 946ms/step - loss: 0.0796 - auc: 0.8969 - val_loss: 0.1051 - val_auc: 0.9524\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.0827 - auc: 0.9014 - val_loss: 0.1053 - val_auc: 0.9539\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 47s 898ms/step - loss: 0.0770 - auc: 0.9088 - val_loss: 0.1053 - val_auc: 0.9525\n",
            "#### FOLD 9 without TTA VAL_AUC = 0.965\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508]\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 490s 1s/step - loss: 0.7052 - auc: 0.5008 - val_loss: 0.6932 - val_auc: 0.4937\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 49s 944ms/step - loss: 0.6163 - auc: 0.4954 - val_loss: 0.5677 - val_auc: 0.5259\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.3591 - auc: 0.5316 - val_loss: 0.2918 - val_auc: 0.6520\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 49s 954ms/step - loss: 0.2580 - auc: 0.6675 - val_loss: 0.2240 - val_auc: 0.7970\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.2030 - auc: 0.7958 - val_loss: 0.1819 - val_auc: 0.8569\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.1760 - auc: 0.8128 - val_loss: 0.1632 - val_auc: 0.8888\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1674 - auc: 0.8030 - val_loss: 0.1621 - val_auc: 0.9032\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1614 - auc: 0.8248 - val_loss: 0.1657 - val_auc: 0.9146\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1517 - auc: 0.8098 - val_loss: 0.1462 - val_auc: 0.9196\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1492 - auc: 0.8520 - val_loss: 0.1354 - val_auc: 0.9272\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.1408 - auc: 0.8672 - val_loss: 0.1273 - val_auc: 0.9310\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.1495 - auc: 0.8280 - val_loss: 0.1235 - val_auc: 0.9373\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 53s 1s/step - loss: 0.1450 - auc: 0.8235 - val_loss: 0.1237 - val_auc: 0.9392\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1370 - auc: 0.8794 - val_loss: 0.1180 - val_auc: 0.9441\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 48s 915ms/step - loss: 0.1352 - auc: 0.8383 - val_loss: 0.1291 - val_auc: 0.9382\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1286 - auc: 0.8734 - val_loss: 0.1211 - val_auc: 0.9342\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1422 - auc: 0.8311 - val_loss: 0.1169 - val_auc: 0.9433\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1302 - auc: 0.8830 - val_loss: 0.1223 - val_auc: 0.9360\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1254 - auc: 0.8476 - val_loss: 0.1162 - val_auc: 0.9464\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.1217 - auc: 0.8759 - val_loss: 0.1139 - val_auc: 0.9466\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 50s 955ms/step - loss: 0.1195 - auc: 0.8835 - val_loss: 0.1139 - val_auc: 0.9433\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.1134 - auc: 0.8723 - val_loss: 0.1145 - val_auc: 0.9428\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1143 - auc: 0.8999 - val_loss: 0.1153 - val_auc: 0.9467\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 50s 966ms/step - loss: 0.1134 - auc: 0.8805 - val_loss: 0.1132 - val_auc: 0.9470\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1143 - auc: 0.8711 - val_loss: 0.1350 - val_auc: 0.9265\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1183 - auc: 0.8593 - val_loss: 0.1168 - val_auc: 0.9358\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 50s 958ms/step - loss: 0.1146 - auc: 0.8607 - val_loss: 0.1148 - val_auc: 0.9432\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.1073 - auc: 0.8969 - val_loss: 0.1185 - val_auc: 0.9354\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.1025 - auc: 0.9040 - val_loss: 0.1127 - val_auc: 0.9411\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0982 - auc: 0.9162 - val_loss: 0.1134 - val_auc: 0.9395\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0984 - auc: 0.8939 - val_loss: 0.1170 - val_auc: 0.9401\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0963 - auc: 0.8966 - val_loss: 0.1151 - val_auc: 0.9418\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0957 - auc: 0.8983 - val_loss: 0.1184 - val_auc: 0.9349\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0965 - auc: 0.8809 - val_loss: 0.1189 - val_auc: 0.9357\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0858 - auc: 0.9341 - val_loss: 0.1163 - val_auc: 0.9392\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0995 - auc: 0.8773 - val_loss: 0.1214 - val_auc: 0.9275\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 50s 964ms/step - loss: 0.0906 - auc: 0.9086 - val_loss: 0.1175 - val_auc: 0.9348\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0905 - auc: 0.8935 - val_loss: 0.1175 - val_auc: 0.9319\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0897 - auc: 0.8984 - val_loss: 0.1223 - val_auc: 0.9321\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0849 - auc: 0.9094 - val_loss: 0.1168 - val_auc: 0.9352\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 50s 957ms/step - loss: 0.0902 - auc: 0.8763 - val_loss: 0.1180 - val_auc: 0.9330\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 50s 962ms/step - loss: 0.0889 - auc: 0.8823 - val_loss: 0.1174 - val_auc: 0.9353\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 50s 965ms/step - loss: 0.0829 - auc: 0.8937 - val_loss: 0.1186 - val_auc: 0.9323\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 50s 963ms/step - loss: 0.0795 - auc: 0.9257 - val_loss: 0.1203 - val_auc: 0.9258\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 50s 961ms/step - loss: 0.0804 - auc: 0.9072 - val_loss: 0.1181 - val_auc: 0.9326\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0841 - auc: 0.8889 - val_loss: 0.1180 - val_auc: 0.9333\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0784 - auc: 0.9018 - val_loss: 0.1196 - val_auc: 0.9317\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 50s 960ms/step - loss: 0.0830 - auc: 0.8857 - val_loss: 0.1195 - val_auc: 0.9334\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 50s 959ms/step - loss: 0.0805 - auc: 0.9040 - val_loss: 0.1196 - val_auc: 0.9329\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 50s 956ms/step - loss: 0.0783 - auc: 0.9155 - val_loss: 0.1200 - val_auc: 0.9321\n",
            "#### FOLD 10 without TTA VAL_AUC = 0.947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXjYZ-Rewt-"
      },
      "source": [
        "#Inference B4512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or1ZIKnzNEI8",
        "outputId": "a8694ec7-b0c4-4471-b659-ccae766c2f98"
      },
      "source": [
        "TEST_FILENAMES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df/test-3000.tfrecords']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZByBYeuDMi"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "test_gogo = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hCPkcNNNrPi",
        "outputId": "dc5859a9-e2a1-4aa7-cfee-a3d36289a60f"
      },
      "source": [
        "len(test_gogo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DulavZSdNH2f",
        "outputId": "95f84cdd-6c2d-4121-d0ce-1bb6f37d7a4e"
      },
      "source": [
        "for x in ds_test:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04771242 0.04771242 0.04771242]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.04771242 0.04771242 0.04771242]\n",
            "   ...\n",
            "   [0.01230935 0.01230935 0.01230935]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  [[0.04771242 0.04771242 0.04771242]\n",
            "   [0.05       0.05       0.05      ]\n",
            "   [0.04738562 0.04738562 0.04738562]\n",
            "   ...\n",
            "   [0.01535944 0.01535944 0.01535944]\n",
            "   [0.0127451  0.0127451  0.0127451 ]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  [[0.04989107 0.04989107 0.04989107]\n",
            "   [0.04738562 0.04738562 0.04738562]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   ...\n",
            "   [0.01514155 0.01514155 0.01514155]\n",
            "   [0.0120915  0.0120915  0.0120915 ]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.0620915  0.0620915  0.0620915 ]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.0247278  0.0247278  0.0247278 ]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02352941 0.02352941 0.02352941]]\n",
            "\n",
            "  [[0.0620915  0.0620915  0.0620915 ]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02516348 0.02516348 0.02516348]]\n",
            "\n",
            "  [[0.06263619 0.06263619 0.06263619]\n",
            "   [0.06045759 0.06045759 0.06045759]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02712426 0.02712426 0.02712426]\n",
            "   [0.0273421  0.0273421  0.0273421 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04629629 0.04629629 0.04629629]\n",
            "   [0.04444444 0.04444444 0.04444444]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.03594771 0.03594771 0.03594771]\n",
            "   [0.03562091 0.03562091 0.03562091]\n",
            "   [0.03583881 0.03583881 0.03583881]]\n",
            "\n",
            "  [[0.04084967 0.04084967 0.04084967]\n",
            "   [0.04019608 0.04019608 0.04019608]\n",
            "   [0.04281046 0.04281046 0.04281046]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01339877 0.01339877 0.01339877]]\n",
            "\n",
            "  [[0.03921569 0.03921569 0.03921569]\n",
            "   [0.04084967 0.04084967 0.04084967]\n",
            "   [0.04302832 0.04302832 0.04302832]\n",
            "   ...\n",
            "   [0.00664481 0.00664481 0.00664481]\n",
            "   [0.00424837 0.00424837 0.00424837]\n",
            "   [0.00729861 0.00729861 0.00729861]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.06775612 0.06775612 0.06775612]\n",
            "   [0.06633983 0.06633983 0.06633983]\n",
            "   [0.06655772 0.06655772 0.06655772]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.07189542 0.07189542 0.07189542]\n",
            "   [0.06666667 0.06666667 0.06666667]\n",
            "   [0.06470589 0.06470589 0.06470589]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.07058824 0.07058824 0.07058824]\n",
            "   [0.06862745 0.06862745 0.06862745]\n",
            "   [0.06612214 0.06612214 0.06612214]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03529412 0.03529412 0.03529412]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.03529412 0.03529412 0.03529412]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.03474945 0.03474945 0.03474945]\n",
            "   [0.03202614 0.03202614 0.03202614]\n",
            "   [0.03202614 0.03202614 0.03202614]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05163399 0.05163399 0.05163399]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05163398 0.05163398 0.05163398]\n",
            "   ...\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.00915001 0.00915001 0.00915001]]\n",
            "\n",
            "  [[0.05522876 0.05522876 0.05522876]\n",
            "   [0.05686275 0.05686275 0.05686275]\n",
            "   [0.05522876 0.05522876 0.05522876]\n",
            "   ...\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.00915001 0.00915001 0.00915001]]\n",
            "\n",
            "  [[0.03921473 0.03921473 0.03921473]\n",
            "   [0.03921473 0.03921473 0.03921473]\n",
            "   [0.03921473 0.03921473 0.03921473]\n",
            "   ...\n",
            "   [0.00915001 0.00915001 0.00915001]\n",
            "   [0.00915001 0.00915001 0.00915001]\n",
            "   [0.00533732 0.00533732 0.00533732]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.1888888  0.1888888  0.1888888 ]\n",
            "   [0.19019608 0.19019608 0.19019608]\n",
            "   [0.19803938 0.19803938 0.19803938]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.16960773 0.16960773 0.16960773]\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   [0.16274463 0.16274463 0.16274463]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.14705867 0.14705867 0.14705867]\n",
            "   [0.13725491 0.13725491 0.13725491]\n",
            "   [0.14379133 0.14379133 0.14379133]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.06481467 0.06481467 0.06481467]\n",
            "   [0.06601299 0.06601299 0.06601299]\n",
            "   [0.07047929 0.07047929 0.07047929]\n",
            "   ...\n",
            "   [0.09030504 0.09030504 0.09030504]\n",
            "   [0.08921581 0.08921581 0.08921581]\n",
            "   [0.09084975 0.09084975 0.09084975]]\n",
            "\n",
            "  [[0.05915033 0.05915033 0.05915033]\n",
            "   [0.06372549 0.06372549 0.06372549]\n",
            "   [0.07320262 0.07320262 0.07320262]\n",
            "   ...\n",
            "   [0.09771238 0.09771238 0.09771238]\n",
            "   [0.09411765 0.09411765 0.09411765]\n",
            "   [0.09379093 0.09379093 0.09379093]]\n",
            "\n",
            "  [[0.05893243 0.05893243 0.05893243]\n",
            "   [0.06470589 0.06470589 0.06470589]\n",
            "   [0.07973872 0.07973872 0.07973872]\n",
            "   ...\n",
            "   [0.0953156  0.0953156  0.0953156 ]\n",
            "   [0.09248358 0.09248358 0.09248358]\n",
            "   [0.09346421 0.09346421 0.09346421]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00457516 0.00457516 0.00457516]\n",
            "   [0.00457516 0.00457516 0.00457516]\n",
            "   [0.00457516 0.00457516 0.00457516]\n",
            "   ...\n",
            "   [0.00065359 0.00065359 0.00065359]\n",
            "   [0.00065359 0.00065359 0.00065359]\n",
            "   [0.00065359 0.00065359 0.00065359]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00337691 0.00337691 0.00337691]\n",
            "   [0.00228758 0.00228758 0.00228758]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.07549024 0.07549024 0.07549024]\n",
            "   [0.07941177 0.07941177 0.07941177]\n",
            "   [0.08169935 0.08169935 0.08169935]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00228758 0.00228758 0.00228758]\n",
            "   ...\n",
            "   [0.07581691 0.07581691 0.07581691]\n",
            "   [0.07352941 0.07352941 0.07352941]\n",
            "   [0.07450981 0.07450981 0.07450981]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00337691 0.00337691 0.00337691]\n",
            "   ...\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   [0.074183   0.074183   0.074183  ]\n",
            "   [0.07385621 0.07385621 0.07385621]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00718954 0.00718954 0.00718954]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.10359494 0.10359494 0.10359494]\n",
            "   [0.10522868 0.10522868 0.10522868]\n",
            "   [0.10522868 0.10522868 0.10522868]]\n",
            "\n",
            "  [[0.00718954 0.00718954 0.00718954]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.11045735 0.11045735 0.11045735]\n",
            "   [0.10392157 0.10392157 0.10392157]\n",
            "   [0.10555564 0.10555564 0.10555564]]\n",
            "\n",
            "  [[0.00718954 0.00718954 0.00718954]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.10969476 0.10969476 0.10969476]\n",
            "   [0.10751642 0.10751642 0.10751642]\n",
            "   [0.11241862 0.11241862 0.11241862]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.06034859 0.06034859 0.06034859]\n",
            "   [0.05686275 0.05686275 0.05686275]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.05522876 0.05522876 0.05522876]\n",
            "   [0.05686275 0.05686275 0.05686275]\n",
            "   [0.05686275 0.05686275 0.05686275]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.04956427 0.04956427 0.04956427]\n",
            "   [0.05359477 0.05359477 0.05359477]\n",
            "   [0.0543573  0.0543573  0.0543573 ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05544661 0.05544661 0.05544661]\n",
            "   [0.05653591 0.05653591 0.05653591]\n",
            "   [0.05435723 0.05435723 0.05435723]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.05882353 0.05882353 0.05882353]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05555555 0.05555555 0.05555555]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.0431363  0.0431363  0.0431363 ]\n",
            "   [0.0431363  0.0431363  0.0431363 ]\n",
            "   [0.03986832 0.03986832 0.03986832]\n",
            "   ...\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   [0.00522844 0.00522844 0.00522844]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00708061 0.00708061 0.00708061]\n",
            "   [0.00163399 0.00163399 0.00163399]\n",
            "   [0.00272331 0.00272331 0.00272331]\n",
            "   ...\n",
            "   [0.05479302 0.05479302 0.05479302]\n",
            "   [0.04901961 0.04901961 0.04901961]\n",
            "   [0.05250587 0.05250587 0.05250587]]\n",
            "\n",
            "  [[0.00522876 0.00522876 0.00522876]\n",
            "   [0.00196078 0.00196078 0.00196078]\n",
            "   [0.00196078 0.00196078 0.00196078]\n",
            "   ...\n",
            "   [0.05424828 0.05424828 0.05424828]\n",
            "   [0.04901961 0.04901961 0.04901961]\n",
            "   [0.05196102 0.05196102 0.05196102]]\n",
            "\n",
            "  [[0.00065359 0.00065359 0.00065359]\n",
            "   [0.00065359 0.00065359 0.00065359]\n",
            "   [0.00337691 0.00337691 0.00337691]\n",
            "   ...\n",
            "   [0.04880179 0.04880179 0.04880179]\n",
            "   [0.05228759 0.05228759 0.05228759]\n",
            "   [0.05468415 0.05468415 0.05468415]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.00032684 0.00032684 0.00032684]\n",
            "   [0.00718994 0.00718994 0.00718994]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.00261446 0.00261446 0.00261446]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.01470612 0.01470612 0.01470612]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.00904181 0.00904181 0.00904181]\n",
            "   [0.02189582 0.02189582 0.02189582]\n",
            "   [0.02875881 0.02875881 0.02875881]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09161229 0.09161229 0.09161229]\n",
            "   [0.09509816 0.09509816 0.09509816]\n",
            "   [0.09531605 0.09531605 0.09531605]\n",
            "   ...\n",
            "   [0.12091495 0.12091495 0.12091495]\n",
            "   [0.11143787 0.11143787 0.11143787]\n",
            "   [0.09596903 0.09596903 0.09596903]]\n",
            "\n",
            "  [[0.09509804 0.09509804 0.09509804]\n",
            "   [0.1        0.1        0.1       ]\n",
            "   [0.10490196 0.10490196 0.10490196]\n",
            "   ...\n",
            "   [0.12156839 0.12156839 0.12156839]\n",
            "   [0.10784314 0.10784314 0.10784314]\n",
            "   [0.0973853  0.0973853  0.0973853 ]]\n",
            "\n",
            "  [[0.09531593 0.09531593 0.09531593]\n",
            "   [0.10163407 0.10163407 0.10163407]\n",
            "   [0.10849674 0.10849674 0.10849674]\n",
            "   ...\n",
            "   [0.12385609 0.12385609 0.12385609]\n",
            "   [0.11078455 0.11078455 0.11078455]\n",
            "   [0.09662251 0.09662251 0.09662251]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.06993464 0.06993464 0.06993464]\n",
            "   [0.07189543 0.07189543 0.07189543]\n",
            "   [0.07385621 0.07385621 0.07385621]\n",
            "   ...\n",
            "   [0.01230943 0.01230943 0.01230943]\n",
            "   [0.01503268 0.01503268 0.01503268]\n",
            "   [0.01503268 0.01503268 0.01503268]]\n",
            "\n",
            "  [[0.06666667 0.06666667 0.06666667]\n",
            "   [0.06764706 0.06764706 0.06764706]\n",
            "   [0.06699346 0.06699346 0.06699346]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01078431 0.01078431 0.01078431]\n",
            "   [0.01143799 0.01143799 0.01143799]]\n",
            "\n",
            "  [[0.06394336 0.06394336 0.06394336]\n",
            "   [0.06666667 0.06666667 0.06666667]\n",
            "   [0.06339869 0.06339869 0.06339869]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01143791 0.01143791 0.01143791]\n",
            "   [0.0116558  0.0116558  0.0116558 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04379085 0.04379085 0.04379085]\n",
            "   [0.04477124 0.04477124 0.04477124]\n",
            "   [0.04575163 0.04575163 0.04575163]\n",
            "   ...\n",
            "   [0.05871458 0.05871458 0.05871458]\n",
            "   [0.05849673 0.05849673 0.05849673]\n",
            "   [0.05882353 0.05882353 0.05882353]]\n",
            "\n",
            "  [[0.04183007 0.04183007 0.04183007]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04117647 0.04117647 0.04117647]\n",
            "   ...\n",
            "   [0.05620907 0.05620907 0.05620907]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05686275 0.05686275 0.05686275]]\n",
            "\n",
            "  [[0.04313726 0.04313726 0.04313726]\n",
            "   [0.04477124 0.04477124 0.04477124]\n",
            "   [0.04259259 0.04259259 0.04259259]\n",
            "   ...\n",
            "   [0.05424828 0.05424828 0.05424828]\n",
            "   [0.05457516 0.05457516 0.05457516]\n",
            "   [0.05544649 0.05544649 0.05544649]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.48289752 0.48289752 0.48289752]\n",
            "   [0.48660088 0.48660088 0.48660088]\n",
            "   [0.48104584 0.48104584 0.48104584]\n",
            "   ...\n",
            "   [0.39727634 0.39727634 0.39727634]\n",
            "   [0.37777793 0.37777793 0.37777793]\n",
            "   [0.3827895  0.3827895  0.3827895 ]]\n",
            "\n",
            "  [[0.48137254 0.48137254 0.48137254]\n",
            "   [0.47254902 0.47254902 0.47254902]\n",
            "   [0.49150324 0.49150324 0.49150324]\n",
            "   ...\n",
            "   [0.39803898 0.39803898 0.39803898]\n",
            "   [0.38921568 0.38921568 0.38921568]\n",
            "   [0.40163454 0.40163454 0.40163454]]\n",
            "\n",
            "  [[0.4852942  0.4852942  0.4852942 ]\n",
            "   [0.4993475  0.4993475  0.4993475 ]\n",
            "   [0.5101313  0.5101313  0.5101313 ]\n",
            "   ...\n",
            "   [0.4047937  0.4047937  0.4047937 ]\n",
            "   [0.41372645 0.41372645 0.41372645]\n",
            "   [0.40795216 0.40795216 0.40795216]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05631808 0.05631808 0.05631808]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05947712 0.05947712 0.05947712]\n",
            "   ...\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]]\n",
            "\n",
            "  [[0.04117647 0.04117647 0.04117647]\n",
            "   [0.04019608 0.04019608 0.04019608]\n",
            "   [0.04084967 0.04084967 0.04084967]\n",
            "   ...\n",
            "   [0.01535944 0.01535944 0.01535944]\n",
            "   [0.01470588 0.01470588 0.01470588]\n",
            "   [0.01568628 0.01568628 0.01568628]]\n",
            "\n",
            "  [[0.03202614 0.03202614 0.03202614]\n",
            "   [0.03202614 0.03202614 0.03202614]\n",
            "   [0.03474946 0.03474946 0.03474946]\n",
            "   ...\n",
            "   [0.01557733 0.01557733 0.01557733]\n",
            "   [0.01535948 0.01535948 0.01535948]\n",
            "   [0.01568628 0.01568628 0.01568628]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01013076 0.01013076 0.01013076]\n",
            "   [0.01122006 0.01122006 0.01122006]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1.43790850e-02 1.43790850e-02 1.43790850e-02]\n",
            "   [2.54901964e-02 2.54901964e-02 2.54901964e-02]\n",
            "   [2.95206979e-02 2.95206979e-02 2.95206979e-02]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [3.26797424e-04 3.26797424e-04 3.26797424e-04]\n",
            "   [1.08905879e-04 1.08905879e-04 1.08905879e-04]]\n",
            "\n",
            "  [[1.30718965e-02 1.30718965e-02 1.30718965e-02]\n",
            "   [2.74509806e-02 2.74509806e-02 2.74509806e-02]\n",
            "   [2.71241851e-02 2.71241851e-02 2.71241851e-02]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [1.96078443e-03 1.96078443e-03 1.96078443e-03]\n",
            "   [6.53435185e-04 6.53435185e-04 6.53435185e-04]]\n",
            "\n",
            "  [[1.23093687e-02 1.23093687e-02 1.23093687e-02]\n",
            "   [3.10457535e-02 3.10457535e-02 3.10457535e-02]\n",
            "   [3.01742926e-02 3.01742926e-02 3.01742926e-02]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [3.26797075e-04 3.26797075e-04 3.26797075e-04]\n",
            "   [1.08905748e-04 1.08905748e-04 1.08905748e-04]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[5.88235306e-03 5.88235306e-03 5.88235306e-03]\n",
            "   [1.53594371e-02 1.53594371e-02 1.53594371e-02]\n",
            "   [1.55773284e-02 1.55773284e-02 1.55773284e-02]\n",
            "   ...\n",
            "   [3.72984380e-01 3.72984380e-01 3.72984380e-01]\n",
            "   [3.83660287e-01 3.83660287e-01 3.83660287e-01]\n",
            "   [2.48358831e-01 2.48358831e-01 2.48358831e-01]]\n",
            "\n",
            "  [[5.55555569e-03 5.55555569e-03 5.55555569e-03]\n",
            "   [1.27450982e-02 1.27450982e-02 1.27450982e-02]\n",
            "   [1.50326807e-02 1.50326807e-02 1.50326807e-02]\n",
            "   ...\n",
            "   [3.68627697e-01 3.68627697e-01 3.68627697e-01]\n",
            "   [3.93137246e-01 3.93137246e-01 3.93137246e-01]\n",
            "   [2.46070534e-01 2.46070534e-01 2.46070534e-01]]\n",
            "\n",
            "  [[5.77344699e-03 5.77344699e-03 5.77344699e-03]\n",
            "   [1.33987730e-02 1.33987730e-02 1.33987730e-02]\n",
            "   [1.50326807e-02 1.50326807e-02 1.50326807e-02]\n",
            "   ...\n",
            "   [3.72984469e-01 3.72984469e-01 3.72984469e-01]\n",
            "   [3.81371826e-01 3.81371826e-01 3.81371826e-01]\n",
            "   [2.52499133e-01 2.52499133e-01 2.52499133e-01]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.90588236 0.90588236 0.90588236]\n",
            "   [0.90457517 0.90457517 0.90457517]\n",
            "   [0.90544665 0.90544665 0.90544665]\n",
            "   ...\n",
            "   [0.5488016  0.5488016  0.5488016 ]\n",
            "   [0.5493464  0.5493464  0.5493464 ]\n",
            "   [0.5482568  0.5482568  0.5482568 ]]\n",
            "\n",
            "  [[0.904902   0.904902   0.904902  ]\n",
            "   [0.9078431  0.9078431  0.9078431 ]\n",
            "   [0.90915036 0.90915036 0.90915036]\n",
            "   ...\n",
            "   [0.44313702 0.44313702 0.44313702]\n",
            "   [0.43529412 0.43529412 0.43529412]\n",
            "   [0.44052303 0.44052303 0.44052303]]\n",
            "\n",
            "  [[0.90882355 0.90882355 0.90882355]\n",
            "   [0.9062091  0.9062091  0.9062091 ]\n",
            "   [0.90631807 0.90631807 0.90631807]\n",
            "   ...\n",
            "   [0.37777793 0.37777793 0.37777793]\n",
            "   [0.37843138 0.37843138 0.37843138]\n",
            "   [0.36056584 0.36056584 0.36056584]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04694989 0.04694989 0.04694989]\n",
            "   [0.04836601 0.04836601 0.04836601]\n",
            "   [0.04978213 0.04978213 0.04978213]\n",
            "   ...\n",
            "   [0.10457516 0.10457516 0.10457516]\n",
            "   [0.10098039 0.10098039 0.10098039]\n",
            "   [0.10283251 0.10283251 0.10283251]]\n",
            "\n",
            "  [[0.04281045 0.04281045 0.04281045]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04509804 0.04509804 0.04509804]\n",
            "   ...\n",
            "   [0.06503272 0.06503272 0.06503272]\n",
            "   [0.06764706 0.06764706 0.06764706]\n",
            "   [0.06535932 0.06535932 0.06535932]]\n",
            "\n",
            "  [[0.04248366 0.04248366 0.04248366]\n",
            "   [0.03954248 0.03954248 0.03954248]\n",
            "   [0.04531591 0.04531591 0.04531591]\n",
            "   ...\n",
            "   [0.05054461 0.05054461 0.05054461]\n",
            "   [0.05228758 0.05228758 0.05228758]\n",
            "   [0.05239633 0.05239633 0.05239633]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.06154686 0.06154686 0.06154686]\n",
            "   [0.05686275 0.05686275 0.05686275]\n",
            "   [0.05871458 0.05871458 0.05871458]\n",
            "   ...\n",
            "   [0.04259254 0.04259254 0.04259254]\n",
            "   [0.04150331 0.04150331 0.04150331]\n",
            "   [0.03986912 0.03986912 0.03986912]]\n",
            "\n",
            "  [[0.0620915  0.0620915  0.0620915 ]\n",
            "   [0.05588235 0.05588235 0.05588235]\n",
            "   [0.05784314 0.05784314 0.05784314]\n",
            "   ...\n",
            "   [0.04150331 0.04150331 0.04150331]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.03986912 0.03986912 0.03986912]]\n",
            "\n",
            "  [[0.05609993 0.05609993 0.05609993]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05806103 0.05806103 0.05806103]\n",
            "   ...\n",
            "   [0.03877985 0.03877985 0.03877985]\n",
            "   [0.03823505 0.03823505 0.03823505]\n",
            "   [0.03660099 0.03660099 0.03660099]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01633987 0.01633987 0.01633987]\n",
            "   [0.01764706 0.01764706 0.01764706]\n",
            "   [0.01895425 0.01895425 0.01895425]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01797386 0.01797386 0.01797386]\n",
            "   [0.01862745 0.01862745 0.01862745]\n",
            "   [0.02091503 0.02091503 0.02091503]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01688453 0.01688453 0.01688453]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.02287582 0.02287582 0.02287582]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.02407406 0.02407406 0.02407406]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02363836 0.02363836 0.02363836]\n",
            "   ...\n",
            "   [0.00337685 0.00337685 0.00337685]\n",
            "   [0.00228762 0.00228762 0.00228762]\n",
            "   [0.00065344 0.00065344 0.00065344]]\n",
            "\n",
            "  [[0.02189542 0.02189542 0.02189542]\n",
            "   [0.0245098  0.0245098  0.0245098 ]\n",
            "   [0.02385621 0.02385621 0.02385621]\n",
            "   ...\n",
            "   [0.00228762 0.00228762 0.00228762]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00065344 0.00065344 0.00065344]]\n",
            "\n",
            "  [[0.0169933  0.0169933  0.0169933 ]\n",
            "   [0.02189535 0.02189535 0.02189535]\n",
            "   [0.02080597 0.02080597 0.02080597]\n",
            "   ...\n",
            "   [0.00065367 0.00065367 0.00065367]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00337701 0.00337701 0.00337701]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00381262 0.00381262 0.00381262]\n",
            "   [0.00163399 0.00163399 0.00163399]\n",
            "   [0.00326813 0.00326813 0.00326813]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00163395 0.00163395 0.00163395]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.00163407 0.00163407 0.00163407]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.12167749 0.12167749 0.12167749]\n",
            "   [0.15490197 0.15490197 0.15490197]\n",
            "   [0.18322426 0.18322426 0.18322426]\n",
            "   ...\n",
            "   [0.34880167 0.34880167 0.34880167]\n",
            "   [0.3343136  0.3343136  0.3343136 ]\n",
            "   [0.31492323 0.31492323 0.31492323]]\n",
            "\n",
            "  [[0.11862745 0.11862745 0.11862745]\n",
            "   [0.15294118 0.15294118 0.15294118]\n",
            "   [0.175817   0.175817   0.175817  ]\n",
            "   ...\n",
            "   [0.3470586  0.3470586  0.3470586 ]\n",
            "   [0.327451   0.327451   0.327451  ]\n",
            "   [0.31928113 0.31928113 0.31928113]]\n",
            "\n",
            "  [[0.11448783 0.11448783 0.11448783]\n",
            "   [0.1460782  0.1460782  0.1460782 ]\n",
            "   [0.17875841 0.17875841 0.17875841]\n",
            "   ...\n",
            "   [0.3556648  0.3556648  0.3556648 ]\n",
            "   [0.33202645 0.33202645 0.33202645]\n",
            "   [0.32799602 0.32799602 0.32799602]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00272325 0.00272325 0.00272325]\n",
            "   [0.01470552 0.01470552 0.01470552]\n",
            "   [0.00762509 0.00762509 0.00762509]\n",
            "   ...\n",
            "   [0.03158911 0.03158911 0.03158911]\n",
            "   [0.00653579 0.00653579 0.00653579]\n",
            "   [0.00054452 0.00054452 0.00054452]]\n",
            "\n",
            "  [[0.01437909 0.01437909 0.01437909]\n",
            "   [0.10490196 0.10490196 0.10490196]\n",
            "   [0.10228758 0.10228758 0.10228758]\n",
            "   ...\n",
            "   [0.14248405 0.14248405 0.14248405]\n",
            "   [0.12058824 0.12058824 0.12058824]\n",
            "   [0.01372214 0.01372214 0.01372214]]\n",
            "\n",
            "  [[0.03420506 0.03420506 0.03420506]\n",
            "   [0.25228965 0.25228965 0.25228965]\n",
            "   [0.25414184 0.25414184 0.25414184]\n",
            "   ...\n",
            "   [0.34379452 0.34379452 0.34379452]\n",
            "   [0.29019848 0.29019848 0.29019848]\n",
            "   [0.03397895 0.03397895 0.03397895]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.4011909  0.4011909  0.4011909 ]\n",
            "   [0.05849674 0.05849674 0.05849674]\n",
            "   [0.00664438 0.00664438 0.00664438]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.1483743  0.1483743  0.1483743 ]\n",
            "   [0.37254903 0.37254903 0.37254903]\n",
            "   [0.04606814 0.04606814 0.04606814]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.03878349 0.03878349 0.03878349]\n",
            "   [0.30588233 0.30588233 0.30588233]\n",
            "   [0.0931209  0.0931209  0.0931209 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.02178604 0.02178604 0.02178604]\n",
            "   [0.01764706 0.01764706 0.01764706]\n",
            "   [0.02603485 0.02603485 0.02603485]\n",
            "   ...\n",
            "   [0.06928089 0.06928089 0.06928089]\n",
            "   [0.06111115 0.06111115 0.06111115]\n",
            "   [0.05893245 0.05893245 0.05893245]]\n",
            "\n",
            "  [[0.08594771 0.08594771 0.08594771]\n",
            "   [0.01764706 0.01764706 0.01764706]\n",
            "   [0.02614379 0.02614379 0.02614379]\n",
            "   ...\n",
            "   [0.06960772 0.06960772 0.06960772]\n",
            "   [0.06372549 0.06372549 0.06372549]\n",
            "   [0.06111103 0.06111103 0.06111103]]\n",
            "\n",
            "  [[0.41755027 0.41755027 0.41755027]\n",
            "   [0.01764706 0.01764706 0.01764706]\n",
            "   [0.02843145 0.02843145 0.02843145]\n",
            "   ...\n",
            "   [0.06721118 0.06721118 0.06721118]\n",
            "   [0.06470589 0.06470589 0.06470589]\n",
            "   [0.0627451  0.0627451  0.0627451 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00108932 0.00108932 0.00108932]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00653595 0.00653595 0.00653595]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.0174292  0.0174292  0.0174292 ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01993464 0.01993464 0.01993464]\n",
            "   [0.02156863 0.02156863 0.02156863]\n",
            "   [0.02320261 0.02320261 0.02320261]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.05675464 0.05675464 0.05675464]\n",
            "   [0.06274606 0.06274606 0.06274606]\n",
            "   [0.06601403 0.06601403 0.06601403]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01688453 0.01688453 0.01688453]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   ...\n",
            "   [0.00838779 0.00838779 0.00838779]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00838783 0.00838783 0.00838783]]\n",
            "\n",
            "  [[0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   ...\n",
            "   [0.01111103 0.01111103 0.01111103]\n",
            "   [0.00882353 0.00882353 0.00882353]\n",
            "   [0.01143799 0.01143799 0.01143799]]\n",
            "\n",
            "  [[0.01688453 0.01688453 0.01688453]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.01688453 0.01688453 0.01688453]\n",
            "   ...\n",
            "   [0.00838779 0.00838779 0.00838779]\n",
            "   [0.00816993 0.00816993 0.00816993]\n",
            "   [0.00849673 0.00849673 0.00849673]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00588235 0.00588235 0.00588235]\n",
            "   [0.00457516 0.00457516 0.00457516]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00359473 0.00359473 0.00359473]\n",
            "   [0.00381265 0.00381265 0.00381265]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00588235 0.00588235 0.00588235]\n",
            "   [0.00457516 0.00457516 0.00457516]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00294118 0.00294118 0.00294118]\n",
            "   [0.00359485 0.00359485 0.00359485]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00588235 0.00588235 0.00588235]\n",
            "   [0.00457516 0.00457516 0.00457516]\n",
            "   ...\n",
            "   [0.00119819 0.00119819 0.00119819]\n",
            "   [0.0022875  0.0022875  0.0022875 ]\n",
            "   [0.00337701 0.00337701 0.00337701]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.02690632 0.02690632 0.02690632]\n",
            "   [0.02385621 0.02385621 0.02385621]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.0245098  0.0245098  0.0245098 ]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03801736 0.03801736 0.03801736]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.004575   0.004575   0.004575  ]]\n",
            "\n",
            "  [[0.0372549  0.0372549  0.0372549 ]\n",
            "   [0.0372549  0.0372549  0.0372549 ]\n",
            "   [0.0372549  0.0372549  0.0372549 ]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.004575   0.004575   0.004575  ]]\n",
            "\n",
            "  [[0.0288666  0.0288666  0.0288666 ]\n",
            "   [0.02777722 0.02777722 0.02777722]\n",
            "   [0.02668784 0.02668784 0.02668784]\n",
            "   ...\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   [0.00403045 0.00403045 0.00403045]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04248366 0.04248366 0.04248366]\n",
            "   [0.04281046 0.04281046 0.04281046]\n",
            "   [0.04640523 0.04640523 0.04640523]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.04150327 0.04150327 0.04150327]\n",
            "   [0.04411765 0.04411765 0.04411765]\n",
            "   [0.04509804 0.04509804 0.04509804]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.04379085 0.04379085 0.04379085]\n",
            "   [0.04542483 0.04542483 0.04542483]\n",
            "   [0.04324619 0.04324619 0.04324619]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.0432462  0.0432462  0.0432462 ]\n",
            "   [0.04346409 0.04346409 0.04346409]\n",
            "   [0.04041401 0.04041401 0.04041401]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.04509804 0.04509804 0.04509804]\n",
            "   [0.04411765 0.04411765 0.04411765]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.04368179 0.04368179 0.04368179]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.33747184 0.33747184 0.33747184]\n",
            "   [0.35718957 0.35718957 0.35718957]\n",
            "   [0.22057875 0.22057875 0.22057875]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.7222201  0.7222201  0.7222201 ]\n",
            "   [0.7392157  0.7392157  0.7392157 ]\n",
            "   [0.46860927 0.46860927 0.46860927]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.714268   0.714268   0.714268  ]\n",
            "   [0.7127451  0.7127451  0.7127451 ]\n",
            "   [0.45303333 0.45303333 0.45303333]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.59324104 0.59324104 0.59324104]\n",
            "   [0.620913   0.620913   0.620913  ]\n",
            "   [0.44976816 0.44976816 0.44976816]]\n",
            "\n",
            "  [[0.00228758 0.00228758 0.00228758]\n",
            "   [0.01470588 0.01470588 0.01470588]\n",
            "   [0.01078431 0.01078431 0.01078431]\n",
            "   ...\n",
            "   [0.57940996 0.57940996 0.57940996]\n",
            "   [0.6480392  0.6480392  0.6480392 ]\n",
            "   [0.46338275 0.46338275 0.46338275]]\n",
            "\n",
            "  [[0.0078433  0.0078433  0.0078433 ]\n",
            "   [0.05392276 0.05392276 0.05392276]\n",
            "   [0.04008805 0.04008805 0.04008805]\n",
            "   ...\n",
            "   [0.4457395  0.4457395  0.4457395 ]\n",
            "   [0.44965822 0.44965822 0.44965822]\n",
            "   [0.21664192 0.21664192 0.21664192]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00849673 0.00849673 0.00849673]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00849673 0.00849673 0.00849673]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01013072 0.01013072 0.01013072]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00849673 0.00849673 0.00849673]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849673 0.00849673 0.00849673]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01405229 0.01405229 0.01405229]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  [[0.01296296 0.01296296 0.01296296]\n",
            "   [0.01405229 0.01405229 0.01405229]\n",
            "   [0.01459695 0.01459695 0.01459695]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00904146 0.00904146 0.00904146]\n",
            "   [0.01013076 0.01013076 0.01013076]\n",
            "   [0.00849681 0.00849681 0.00849681]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01013076 0.01013076 0.01013076]\n",
            "   [0.01122019 0.01122019 0.01122019]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.0708061  0.0708061  0.0708061 ]\n",
            "   [0.07156863 0.07156863 0.07156863]\n",
            "   [0.07015251 0.07015251 0.07015251]\n",
            "   ...\n",
            "   [0.02080617 0.02080617 0.02080617]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.01819127 0.01819127 0.01819127]]\n",
            "\n",
            "  [[0.07189542 0.07189542 0.07189542]\n",
            "   [0.07745098 0.07745098 0.07745098]\n",
            "   [0.0748366  0.0748366  0.0748366 ]\n",
            "   ...\n",
            "   [0.02320257 0.02320257 0.02320257]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02124143 0.02124143 0.02124143]]\n",
            "\n",
            "  [[0.08061003 0.08061003 0.08061003]\n",
            "   [0.08006535 0.08006535 0.08006535]\n",
            "   [0.07897604 0.07897604 0.07897604]\n",
            "   ...\n",
            "   [0.02614371 0.02614371 0.02614371]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.01830017 0.01830017 0.01830017]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.25610015 0.25610015 0.25610015]\n",
            "   [0.25620908 0.25620908 0.25620908]\n",
            "   [0.27429166 0.27429166 0.27429166]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.2526144  0.2526144  0.2526144 ]\n",
            "   [0.2529412  0.2529412  0.2529412 ]\n",
            "   [0.25980392 0.25980392 0.25980392]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.2469496  0.2469496  0.2469496 ]\n",
            "   [0.24803898 0.24803898 0.24803898]\n",
            "   [0.24967287 0.24967287 0.24967287]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   ...\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.06993192 0.06993192 0.06993192]]\n",
            "\n",
            "  [[0.12156863 0.12156863 0.12156863]\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   ...\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.1254902  0.1254902  0.1254902 ]\n",
            "   [0.07221943 0.07221943 0.07221943]]\n",
            "\n",
            "  [[0.07973633 0.07973633 0.07973633]\n",
            "   [0.07973633 0.07973633 0.07973633]\n",
            "   [0.07973633 0.07973633 0.07973633]\n",
            "   ...\n",
            "   [0.07973633 0.07973633 0.07973633]\n",
            "   [0.0836579  0.0836579  0.0836579 ]\n",
            "   [0.04781811 0.04781811 0.04781811]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.08246188 0.08246188 0.08246188]\n",
            "   [0.1356209  0.1356209  0.1356209 ]\n",
            "   [0.13050109 0.13050109 0.13050109]\n",
            "   ...\n",
            "   [0.1208064  0.1208064  0.1208064 ]\n",
            "   [0.12352941 0.12352941 0.12352941]\n",
            "   [0.11154674 0.11154674 0.11154674]]\n",
            "\n",
            "  [[0.08267974 0.08267974 0.08267974]\n",
            "   [0.13627452 0.13627452 0.13627452]\n",
            "   [0.13431373 0.13431373 0.13431373]\n",
            "   ...\n",
            "   [0.15686227 0.15686227 0.15686227]\n",
            "   [0.13529412 0.13529412 0.13529412]\n",
            "   [0.1202608  0.1202608  0.1202608 ]]\n",
            "\n",
            "  [[0.0828976  0.0828976  0.0828976 ]\n",
            "   [0.13856208 0.13856208 0.13856208]\n",
            "   [0.1332244  0.1332244  0.1332244 ]\n",
            "   ...\n",
            "   [0.13627471 0.13627471 0.13627471]\n",
            "   [0.14542483 0.14542483 0.14542483]\n",
            "   [0.12516236 0.12516236 0.12516236]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09738562 0.09738562 0.09738562]\n",
            "   [0.16633983 0.16633983 0.16633983]\n",
            "   [0.15740739 0.15740739 0.15740739]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]]\n",
            "\n",
            "  [[0.09705883 0.09705883 0.09705883]\n",
            "   [0.1627451  0.1627451  0.1627451 ]\n",
            "   [0.15653594 0.15653594 0.15653594]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09901961 0.09901961 0.09901961]\n",
            "   [0.1        0.1        0.1       ]]\n",
            "\n",
            "  [[0.09618734 0.09618734 0.09618734]\n",
            "   [0.15915024 0.15915024 0.15915024]\n",
            "   [0.1534857  0.1534857  0.1534857 ]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09836593 0.09836593 0.09836593]\n",
            "   [0.09869265 0.09869265 0.09869265]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]]\n",
            "\n",
            "  [[0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]]\n",
            "\n",
            "  [[0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   ...\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   [0.09803922 0.09803922 0.09803922]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.76132894 0.76132894 0.76132894]\n",
            "   [0.7640522  0.7640522  0.7640522 ]\n",
            "   [0.76459694 0.76459694 0.76459694]\n",
            "   ...\n",
            "   [0.55185175 0.55185175 0.55185175]\n",
            "   [0.5477125  0.5477125  0.5477125 ]\n",
            "   [0.54248357 0.54248357 0.54248357]]\n",
            "\n",
            "  [[0.7607843  0.7607843  0.7607843 ]\n",
            "   [0.7617647  0.7617647  0.7617647 ]\n",
            "   [0.766013   0.766013   0.766013  ]\n",
            "   ...\n",
            "   [0.54411775 0.54411775 0.54411775]\n",
            "   [0.5480392  0.5480392  0.5480392 ]\n",
            "   [0.54215664 0.54215664 0.54215664]]\n",
            "\n",
            "  [[0.7607843  0.7607843  0.7607843 ]\n",
            "   [0.76437914 0.76437914 0.76437914]\n",
            "   [0.77124196 0.77124196 0.77124196]\n",
            "   ...\n",
            "   [0.54128563 0.54128563 0.54128563]\n",
            "   [0.54509807 0.54509807 0.54509807]\n",
            "   [0.53856176 0.53856176 0.53856176]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05250544 0.05250544 0.05250544]\n",
            "   [0.04346405 0.04346405 0.04346405]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.03638358 0.03638358 0.03638358]\n",
            "   [0.04248366 0.04248366 0.04248366]\n",
            "   [0.03932443 0.03932443 0.03932443]]\n",
            "\n",
            "  [[0.04673202 0.04673202 0.04673202]\n",
            "   [0.04411765 0.04411765 0.04411765]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.0372549  0.0372549  0.0372549 ]\n",
            "   [0.03758162 0.03758162 0.03758162]]\n",
            "\n",
            "  [[0.04586057 0.04586057 0.04586057]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.03583885 0.03583885 0.03583885]\n",
            "   [0.03856209 0.03856209 0.03856209]\n",
            "   [0.03365989 0.03365989 0.03365989]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.3148146  0.3148146  0.3148146 ]\n",
            "   [0.304575   0.304575   0.304575  ]\n",
            "   [0.30958658 0.30958658 0.30958658]\n",
            "   ...\n",
            "   [0.00065367 0.00065367 0.00065367]\n",
            "   [0.00196078 0.00196078 0.00196078]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.30849674 0.30849674 0.30849674]\n",
            "   [0.30882353 0.30882353 0.30882353]\n",
            "   [0.32875815 0.32875815 0.32875815]\n",
            "   ...\n",
            "   [0.00065367 0.00065367 0.00065367]\n",
            "   [0.00196078 0.00196078 0.00196078]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.33812773 0.33812773 0.33812773]\n",
            "   [0.3310463  0.3310463  0.3310463 ]\n",
            "   [0.33159068 0.33159068 0.33159068]\n",
            "   ...\n",
            "   [0.00065367 0.00065367 0.00065367]\n",
            "   [0.00196078 0.00196078 0.00196078]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.02625272 0.02625272 0.02625272]\n",
            "   [0.0251634  0.0251634  0.0251634 ]\n",
            "   [0.02407407 0.02407407 0.02407407]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01307158 0.01307158 0.01307158]\n",
            "   [0.01470564 0.01470564 0.01470564]\n",
            "   [0.01361626 0.01361626 0.01361626]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.12396514 0.12396514 0.12396514]\n",
            "   [0.1261438  0.1261438  0.1261438 ]\n",
            "   [0.1261438  0.1261438  0.1261438 ]\n",
            "   ...\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]]\n",
            "\n",
            "  [[0.13431373 0.13431373 0.13431373]\n",
            "   [0.13039216 0.13039216 0.13039216]\n",
            "   [0.13137256 0.13137256 0.13137256]\n",
            "   ...\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]]\n",
            "\n",
            "  [[0.13703704 0.13703704 0.13703704]\n",
            "   [0.13464051 0.13464051 0.13464051]\n",
            "   [0.13061003 0.13061003 0.13061003]\n",
            "   ...\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.7432462  0.7432462  0.7432462 ]\n",
            "   [0.7379086  0.7379086  0.7379086 ]\n",
            "   [0.7499999  0.7499999  0.7499999 ]\n",
            "   ...\n",
            "   [0.04259254 0.04259254 0.04259254]\n",
            "   [0.04150331 0.04150331 0.04150331]\n",
            "   [0.04313726 0.04313726 0.04313726]]\n",
            "\n",
            "  [[0.74607843 0.74607843 0.74607843]\n",
            "   [0.7411765  0.7411765  0.7411765 ]\n",
            "   [0.7411765  0.7411765  0.7411765 ]\n",
            "   ...\n",
            "   [0.04150331 0.04150331 0.04150331]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]]\n",
            "\n",
            "  [[0.748366   0.748366   0.748366  ]\n",
            "   [0.74607867 0.74607867 0.74607867]\n",
            "   [0.7443359  0.7443359  0.7443359 ]\n",
            "   ...\n",
            "   [0.04259274 0.04259274 0.04259274]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00620915 0.00620915 0.00620915]\n",
            "   [0.00729848 0.00729848 0.00729848]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.42080575 0.42080575 0.42080575]\n",
            "   [0.4205881  0.4205881  0.4205881 ]\n",
            "   [0.2389885  0.2389885  0.2389885 ]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.43529388 0.43529388 0.43529388]\n",
            "   [0.43823528 0.43823528 0.43823528]\n",
            "   [0.25325832 0.25325832 0.25325832]]\n",
            "\n",
            "  [[0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   ...\n",
            "   [0.29400083 0.29400083 0.29400083]\n",
            "   [0.30064577 0.30064577 0.30064577]\n",
            "   [0.17275561 0.17275561 0.17275561]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03071895 0.03071895 0.03071895]\n",
            "   [0.03267974 0.03267974 0.03267974]\n",
            "   [0.03464052 0.03464052 0.03464052]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02745098 0.02745098 0.02745098]\n",
            "   [0.02843137 0.02843137 0.02843137]\n",
            "   [0.02941176 0.02941176 0.02941176]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.03017429 0.03017429 0.03017429]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.49335513 0.49335513 0.49335513]\n",
            "   [0.48986924 0.48986924 0.48986924]\n",
            "   [0.4961877  0.4961877  0.4961877 ]\n",
            "   ...\n",
            "   [0.31546858 0.31546858 0.31546858]\n",
            "   [0.3205886  0.3205886  0.3205886 ]\n",
            "   [0.19171433 0.19171433 0.19171433]]\n",
            "\n",
            "  [[0.5192811  0.5192811  0.5192811 ]\n",
            "   [0.5205882  0.5205882  0.5205882 ]\n",
            "   [0.5415033  0.5415033  0.5415033 ]\n",
            "   ...\n",
            "   [0.370588   0.370588   0.370588  ]\n",
            "   [0.38039216 0.38039216 0.38039216]\n",
            "   [0.228423   0.228423   0.228423  ]]\n",
            "\n",
            "  [[0.36110207 0.36110207 0.36110207]\n",
            "   [0.37319383 0.37319383 0.37319383]\n",
            "   [0.37656993 0.37656993 0.37656993]\n",
            "   ...\n",
            "   [0.27374077 0.27374077 0.27374077]\n",
            "   [0.2882286  0.2882286  0.2882286 ]\n",
            "   [0.17580695 0.17580695 0.17580695]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01601307 0.01601307 0.01601307]\n",
            "   [0.01764706 0.01764706 0.01764706]\n",
            "   [0.01601307 0.01601307 0.01601307]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01252705 0.01252705 0.01252705]\n",
            "   [0.01307158 0.01307158 0.01307158]\n",
            "   [0.0098036  0.0098036  0.0098036 ]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.35283214 0.35283214 0.35283214]\n",
            "   [0.35620907 0.35620907 0.35620907]\n",
            "   [0.37429205 0.37429205 0.37429205]\n",
            "   ...\n",
            "   [0.27276623 0.27276623 0.27276623]\n",
            "   [0.23202622 0.23202622 0.23202622]\n",
            "   [0.19890977 0.19890977 0.19890977]]\n",
            "\n",
            "  [[0.34542483 0.34542483 0.34542483]\n",
            "   [0.3509804  0.3509804  0.3509804 ]\n",
            "   [0.37777779 0.37777779 0.37777779]\n",
            "   ...\n",
            "   [0.2647054  0.2647054  0.2647054 ]\n",
            "   [0.23137255 0.23137255 0.23137255]\n",
            "   [0.19477013 0.19477013 0.19477013]]\n",
            "\n",
            "  [[0.3347491  0.3347491  0.3347491 ]\n",
            "   [0.34248334 0.34248334 0.34248334]\n",
            "   [0.36710197 0.36710197 0.36710197]\n",
            "   ...\n",
            "   [0.25283155 0.25283155 0.25283155]\n",
            "   [0.22254878 0.22254878 0.22254878]\n",
            "   [0.19172022 0.19172022 0.19172022]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.208061   0.208061   0.208061  ]\n",
            "   [0.20947713 0.20947713 0.20947713]\n",
            "   [0.21034859 0.21034859 0.21034859]\n",
            "   ...\n",
            "   [0.2850762  0.2850762  0.2850762 ]\n",
            "   [0.28235295 0.28235295 0.28235295]\n",
            "   [0.28398702 0.28398702 0.28398702]]\n",
            "\n",
            "  [[0.2127451  0.2127451  0.2127451 ]\n",
            "   [0.21960784 0.21960784 0.21960784]\n",
            "   [0.22156863 0.22156863 0.22156863]\n",
            "   ...\n",
            "   [0.30294082 0.30294082 0.30294082]\n",
            "   [0.2882353  0.2882353  0.2882353 ]\n",
            "   [0.2931375  0.2931375  0.2931375 ]]\n",
            "\n",
            "  [[0.2157952  0.2157952  0.2157952 ]\n",
            "   [0.21830066 0.21830066 0.21830066]\n",
            "   [0.21699347 0.21699347 0.21699347]\n",
            "   ...\n",
            "   [0.3088234  0.3088234  0.3088234 ]\n",
            "   [0.30392158 0.30392158 0.30392158]\n",
            "   [0.30119812 0.30119812 0.30119812]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.7372549  0.7372549  0.7372549 ]\n",
            "   [0.746732   0.746732   0.746732  ]\n",
            "   [0.76819146 0.76819146 0.76819146]\n",
            "   ...\n",
            "   [0.90904176 0.90904176 0.90904176]\n",
            "   [0.9248365  0.9248365  0.9248365 ]\n",
            "   [0.9166664  0.9166664  0.9166664 ]]\n",
            "\n",
            "  [[0.7362745  0.7362745  0.7362745 ]\n",
            "   [0.7470588  0.7470588  0.7470588 ]\n",
            "   [0.75784314 0.75784314 0.75784314]\n",
            "   ...\n",
            "   [0.90980417 0.90980417 0.90980417]\n",
            "   [0.92058825 0.92058825 0.92058825]\n",
            "   [0.9199346  0.9199346  0.9199346 ]]\n",
            "\n",
            "  [[0.73801756 0.73801756 0.73801756]\n",
            "   [0.75228775 0.75228775 0.75228775]\n",
            "   [0.760022   0.760022   0.760022  ]\n",
            "   ...\n",
            "   [0.9296305  0.9296305  0.9296305 ]\n",
            "   [0.9261441  0.9261441  0.9261441 ]\n",
            "   [0.9155769  0.9155769  0.9155769 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03137255 0.03137255 0.03137255]\n",
            "   [0.04901961 0.04901961 0.04901961]\n",
            "   [0.0503268  0.0503268  0.0503268 ]\n",
            "   ...\n",
            "   [0.11132964 0.11132964 0.11132964]\n",
            "   [0.12516339 0.12516339 0.12516339]\n",
            "   [0.10468375 0.10468375 0.10468375]]\n",
            "\n",
            "  [[0.03169935 0.03169935 0.03169935]\n",
            "   [0.05       0.05       0.05      ]\n",
            "   [0.04869281 0.04869281 0.04869281]\n",
            "   ...\n",
            "   [0.1362744  0.1362744  0.1362744 ]\n",
            "   [0.13039216 0.13039216 0.13039216]\n",
            "   [0.11470517 0.11470517 0.11470517]]\n",
            "\n",
            "  [[0.03148148 0.03148148 0.03148148]\n",
            "   [0.0493464  0.0493464  0.0493464 ]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   ...\n",
            "   [0.1247275  0.1247275  0.1247275 ]\n",
            "   [0.13235295 0.13235295 0.13235295]\n",
            "   [0.11927969 0.11927969 0.11927969]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03398693 0.03398693 0.03398693]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.03921569 0.03921569 0.03921569]\n",
            "   ...\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.05261434 0.05261434 0.05261434]\n",
            "   [0.06459744 0.06459744 0.06459744]]\n",
            "\n",
            "  [[0.03398693 0.03398693 0.03398693]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.03921569 0.03921569 0.03921569]\n",
            "   ...\n",
            "   [0.05294118 0.05294118 0.05294118]\n",
            "   [0.05196078 0.05196078 0.05196078]\n",
            "   [0.06568699 0.06568699 0.06568699]]\n",
            "\n",
            "  [[0.03616568 0.03616568 0.03616568]\n",
            "   [0.05620979 0.05620979 0.05620979]\n",
            "   [0.05501167 0.05501167 0.05501167]\n",
            "   ...\n",
            "   [0.07451076 0.07451076 0.07451076]\n",
            "   [0.07254998 0.07254998 0.07254998]\n",
            "   [0.07603555 0.07603555 0.07603555]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.07788671 0.07788671 0.07788671]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.08115468 0.08115468 0.08115468]\n",
            "   ...\n",
            "   [0.07396515 0.07396515 0.07396515]\n",
            "   [0.0748366  0.0748366  0.0748366 ]\n",
            "   [0.07461871 0.07461871 0.07461871]]\n",
            "\n",
            "  [[0.07516339 0.07516339 0.07516339]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.07679738 0.07679738 0.07679738]\n",
            "   ...\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   [0.0754902  0.0754902  0.0754902 ]\n",
            "   [0.07483652 0.07483652 0.07483652]]\n",
            "\n",
            "  [[0.07788671 0.07788671 0.07788671]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.07788671 0.07788671 0.07788671]\n",
            "   ...\n",
            "   [0.07450972 0.07450972 0.07450972]\n",
            "   [0.07124183 0.07124183 0.07124183]\n",
            "   [0.07396527 0.07396527 0.07396527]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03453157 0.03453157 0.03453157]\n",
            "   [0.03071887 0.03071887 0.03071887]\n",
            "   [0.0312636  0.0312636  0.0312636 ]\n",
            "   ...\n",
            "   [0.0279957  0.0279957  0.0279957 ]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.0296296  0.0296296  0.0296296 ]]\n",
            "\n",
            "  [[0.03398693 0.03398693 0.03398693]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02908497 0.02908497 0.02908497]\n",
            "   ...\n",
            "   [0.02712414 0.02712414 0.02712414]\n",
            "   [0.02647059 0.02647059 0.02647059]\n",
            "   [0.02581691 0.02581691 0.02581691]]\n",
            "\n",
            "  [[0.03126349 0.03126349 0.03126349]\n",
            "   [0.02581691 0.02581691 0.02581691]\n",
            "   [0.02418285 0.02418285 0.02418285]\n",
            "   ...\n",
            "   [0.02679755 0.02679755 0.02679755]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02418285 0.02418285 0.02418285]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00228758 0.00228758 0.00228758]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00337691 0.00337691 0.00337691]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   [0.004575   0.004575   0.004575  ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.00980392 0.00980392 0.00980392]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01078431 0.01078431 0.01078431]\n",
            "   [0.00816993 0.00816993 0.00816993]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   [0.0052286  0.0052286  0.0052286 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.17777786 0.17777786 0.17777786]\n",
            "   [0.1820261  0.1820261  0.1820261 ]\n",
            "   [0.19335502 0.19335502 0.19335502]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.17941177 0.17941177 0.17941177]\n",
            "   [0.18235295 0.18235295 0.18235295]\n",
            "   [0.1885621  0.1885621  0.1885621 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.17450964 0.17450964 0.17450964]\n",
            "   [0.17941153 0.17941153 0.17941153]\n",
            "   [0.18921578 0.18921578 0.18921578]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.0150326  0.0150326  0.0150326 ]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.01535944 0.01535944 0.01535944]\n",
            "   [0.0127451  0.0127451  0.0127451 ]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.00969476 0.00969476 0.00969476]\n",
            "   [0.01045736 0.01045736 0.01045736]\n",
            "   [0.00522844 0.00522844 0.00522844]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04716776 0.04716776 0.04716776]\n",
            "   [0.0493464  0.0493464  0.0493464 ]\n",
            "   [0.04771242 0.04771242 0.04771242]\n",
            "   ...\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05490196 0.05490196 0.05490196]]\n",
            "\n",
            "  [[0.04934641 0.04934641 0.04934641]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.0493464  0.0493464  0.0493464 ]\n",
            "   ...\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05588235 0.05588235 0.05588235]\n",
            "   [0.05522868 0.05522868 0.05522868]]\n",
            "\n",
            "  [[0.05424837 0.05424837 0.05424837]\n",
            "   [0.05261438 0.05261438 0.05261438]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   ...\n",
            "   [0.0576252  0.0576252  0.0576252 ]\n",
            "   [0.05522876 0.05522876 0.05522876]\n",
            "   [0.05501087 0.05501087 0.05501087]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03137255 0.03137255 0.03137255]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.02810458 0.02810458 0.02810458]\n",
            "   ...\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.05130723 0.05130723 0.05130723]\n",
            "   [0.05435745 0.05435745 0.05435745]]\n",
            "\n",
            "  [[0.03137255 0.03137255 0.03137255]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.02810458 0.02810458 0.02810458]\n",
            "   ...\n",
            "   [0.05130723 0.05130723 0.05130723]\n",
            "   [0.05392157 0.05392157 0.05392157]\n",
            "   [0.05490196 0.05490196 0.05490196]]\n",
            "\n",
            "  [[0.03137255 0.03137255 0.03137255]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.03082802 0.03082802 0.03082802]\n",
            "   ...\n",
            "   [0.05108931 0.05108931 0.05108931]\n",
            "   [0.05326789 0.05326789 0.05326789]\n",
            "   [0.05490196 0.05490196 0.05490196]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01895417 0.01895417 0.01895417]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01840972 0.01840972 0.01840972]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01895417 0.01895417 0.01895417]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01732034 0.01732034 0.01732034]]\n",
            "\n",
            "  [[0.01056645 0.01056645 0.01056645]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01895417 0.01895417 0.01895417]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01623096 0.01623096 0.01623096]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.02755994 0.02755994 0.02755994]\n",
            "   [0.02581703 0.02581703 0.02581703]\n",
            "   [0.02026128 0.02026128 0.02026128]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.02614387 0.02614387 0.02614387]\n",
            "   [0.02647059 0.02647059 0.02647059]\n",
            "   [0.02189535 0.02189535 0.02189535]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01013064 0.01013064 0.01013064]\n",
            "   [0.01122002 0.01122002 0.01122002]\n",
            "   ...\n",
            "   [0.02690646 0.02690646 0.02690646]\n",
            "   [0.02712426 0.02712426 0.02712426]\n",
            "   [0.02407397 0.02407397 0.02407397]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.06732026 0.06732026 0.06732026]\n",
            "   [0.06699347 0.06699347 0.06699347]\n",
            "   [0.06938998 0.06938998 0.06938998]\n",
            "   ...\n",
            "   [0.12080608 0.12080608 0.12080608]\n",
            "   [0.12026144 0.12026144 0.12026144]\n",
            "   [0.12026144 0.12026144 0.12026144]]\n",
            "\n",
            "  [[0.06862745 0.06862745 0.06862745]\n",
            "   [0.06764706 0.06764706 0.06764706]\n",
            "   [0.06503268 0.06503268 0.06503268]\n",
            "   ...\n",
            "   [0.11339866 0.11339866 0.11339866]\n",
            "   [0.11176471 0.11176471 0.11176471]\n",
            "   [0.11339878 0.11339878 0.11339878]]\n",
            "\n",
            "  [[0.06938998 0.06938998 0.06938998]\n",
            "   [0.06503268 0.06503268 0.06503268]\n",
            "   [0.06557734 0.06557734 0.06557734]\n",
            "   ...\n",
            "   [0.1130719  0.1130719  0.1130719 ]\n",
            "   [0.1130719  0.1130719  0.1130719 ]\n",
            "   [0.11634003 0.11634003 0.11634003]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01514163 0.01514163 0.01514163]\n",
            "   [0.01241838 0.01241838 0.01241838]\n",
            "   [0.01187365 0.01187365 0.01187365]\n",
            "   ...\n",
            "   [0.07233134 0.07233134 0.07233134]\n",
            "   [0.07483664 0.07483664 0.07483664]\n",
            "   [0.07461873 0.07461873 0.07461873]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01405229 0.01405229 0.01405229]\n",
            "   ...\n",
            "   [0.0777777  0.0777777  0.0777777 ]\n",
            "   [0.0754902  0.0754902  0.0754902 ]\n",
            "   [0.07647059 0.07647059 0.07647059]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.07723294 0.07723294 0.07723294]\n",
            "   [0.07124167 0.07124167 0.07124167]\n",
            "   [0.07450981 0.07450981 0.07450981]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.06459694 0.06459694 0.06459694]\n",
            "   [0.10359477 0.10359477 0.10359477]\n",
            "   [0.09738562 0.09738562 0.09738562]\n",
            "   ...\n",
            "   [0.10544617 0.10544617 0.10544617]\n",
            "   [0.13986929 0.13986929 0.13986929]\n",
            "   [0.5049172  0.5049172  0.5049172 ]]\n",
            "\n",
            "  [[0.06209151 0.06209151 0.06209151]\n",
            "   [0.10098039 0.10098039 0.10098039]\n",
            "   [0.09575164 0.09575164 0.09575164]\n",
            "   ...\n",
            "   [0.09575159 0.09575159 0.09575159]\n",
            "   [0.11862745 0.11862745 0.11862745]\n",
            "   [0.21830432 0.21830432 0.21830432]]\n",
            "\n",
            "  [[0.06013072 0.06013072 0.06013072]\n",
            "   [0.10163398 0.10163398 0.10163398]\n",
            "   [0.09738562 0.09738562 0.09738562]\n",
            "   ...\n",
            "   [0.0838781  0.0838781  0.0838781 ]\n",
            "   [0.11699346 0.11699346 0.11699346]\n",
            "   [0.16917327 0.16917327 0.16917327]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10958579 0.10958579 0.10958579]\n",
            "   [0.27124238 0.27124238 0.27124238]\n",
            "   [0.13714673 0.13714673 0.13714673]\n",
            "   ...\n",
            "   [0.06623083 0.06623083 0.06623083]\n",
            "   [0.09379129 0.09379129 0.09379129]\n",
            "   [0.23846617 0.23846617 0.23846617]]\n",
            "\n",
            "  [[0.09738562 0.09738562 0.09738562]\n",
            "   [0.29117647 0.29117647 0.29117647]\n",
            "   [0.22352938 0.22352938 0.22352938]\n",
            "   ...\n",
            "   [0.06666595 0.06666595 0.06666595]\n",
            "   [0.16764706 0.16764706 0.16764706]\n",
            "   [0.7212625  0.7212625  0.7212625 ]]\n",
            "\n",
            "  [[0.0928103  0.0928103  0.0928103 ]\n",
            "   [0.1901913  0.1901913  0.1901913 ]\n",
            "   [0.21568325 0.21568325 0.21568325]\n",
            "   ...\n",
            "   [0.06601203 0.06601203 0.06601203]\n",
            "   [0.2774536  0.2774536  0.2774536 ]\n",
            "   [0.90666384 0.90666384 0.90666384]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01372549 0.01372549 0.01372549]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01372549 0.01372549 0.01372549]\n",
            "   [0.01732026 0.01732026 0.01732026]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00849657 0.00849657 0.00849657]\n",
            "   [0.00882329 0.00882329 0.00882329]\n",
            "   [0.01241798 0.01241798 0.01241798]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02581699 0.02581699 0.02581699]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.02363834 0.02363834 0.02363834]\n",
            "   [0.02418301 0.02418301 0.02418301]\n",
            "   [0.02418301 0.02418301 0.02418301]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.02734203 0.02734203 0.02734203]\n",
            "   [0.02712414 0.02712414 0.02712414]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.02712419 0.02712419 0.02712419]\n",
            "   [0.02647059 0.02647059 0.02647059]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.01764658 0.01764658 0.01764658]\n",
            "   [0.01928065 0.01928065 0.01928065]\n",
            "   [0.02091471 0.02091471 0.02091471]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.07450981 0.07450981 0.07450981]\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   ...\n",
            "   [0.08180821 0.08180821 0.08180821]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08616561 0.08616561 0.08616561]]\n",
            "\n",
            "  [[0.07254902 0.07254902 0.07254902]\n",
            "   [0.07254902 0.07254902 0.07254902]\n",
            "   [0.07254902 0.07254902 0.07254902]\n",
            "   ...\n",
            "   [0.08267978 0.08267978 0.08267978]\n",
            "   [0.08333334 0.08333334 0.08333334]\n",
            "   [0.08725514 0.08725514 0.08725514]]\n",
            "\n",
            "  [[0.07058824 0.07058824 0.07058824]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   ...\n",
            "   [0.08300661 0.08300661 0.08300661]\n",
            "   [0.08594771 0.08594771 0.08594771]\n",
            "   [0.08943374 0.08943374 0.08943374]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.07734216 0.07734216 0.07734216]\n",
            "   [0.07189558 0.07189558 0.07189558]\n",
            "   [0.077342   0.077342   0.077342  ]\n",
            "   ...\n",
            "   [0.06263614 0.06263614 0.06263614]\n",
            "   [0.06764694 0.06764694 0.06764694]\n",
            "   [0.07156859 0.07156859 0.07156859]]\n",
            "\n",
            "  [[0.07973856 0.07973856 0.07973856]\n",
            "   [0.07745098 0.07745098 0.07745098]\n",
            "   [0.07352941 0.07352941 0.07352941]\n",
            "   ...\n",
            "   [0.06568615 0.06568615 0.06568615]\n",
            "   [0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.07124215 0.07124215 0.07124215]]\n",
            "\n",
            "  [[0.0766884  0.0766884  0.0766884 ]\n",
            "   [0.07156838 0.07156838 0.07156838]\n",
            "   [0.07407418 0.07407418 0.07407418]\n",
            "   ...\n",
            "   [0.06437889 0.06437889 0.06437889]\n",
            "   [0.0676473  0.0676473  0.0676473 ]\n",
            "   [0.07309406 0.07309406 0.07309406]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[6.5359485e-04 6.5359485e-04 6.5359485e-04]\n",
            "   [3.9215689e-03 3.9215689e-03 3.9215689e-03]\n",
            "   [3.3769060e-03 3.3769060e-03 3.3769060e-03]\n",
            "   ...\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   [1.9607844e-03 1.9607844e-03 1.9607844e-03]\n",
            "   [3.3768797e-03 3.3768797e-03 3.3768797e-03]]\n",
            "\n",
            "  [[6.5359485e-04 6.5359485e-04 6.5359485e-04]\n",
            "   [3.9215689e-03 3.9215689e-03 3.9215689e-03]\n",
            "   [2.2875813e-03 2.2875813e-03 2.2875813e-03]\n",
            "   ...\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   [9.8039221e-04 9.8039221e-04 9.8039221e-04]\n",
            "   [3.2671759e-04 3.2671759e-04 3.2671759e-04]]\n",
            "\n",
            "  [[6.5359485e-04 6.5359485e-04 6.5359485e-04]\n",
            "   [3.9215689e-03 3.9215689e-03 3.9215689e-03]\n",
            "   [3.9215689e-03 3.9215689e-03 3.9215689e-03]\n",
            "   ...\n",
            "   [5.4472889e-04 5.4472889e-04 5.4472889e-04]\n",
            "   [1.6339873e-03 1.6339873e-03 1.6339873e-03]\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.1601304e-01 2.1601304e-01 2.1601304e-01]\n",
            "   [3.7189510e-01 3.7189510e-01 3.7189510e-01]\n",
            "   [3.5294119e-01 3.5294119e-01 3.5294119e-01]\n",
            "   ...\n",
            "   [4.0969473e-01 4.0969473e-01 4.0969473e-01]\n",
            "   [4.1568604e-01 4.1568604e-01 4.1568604e-01]\n",
            "   [2.5282365e-01 2.5282365e-01 2.5282365e-01]]\n",
            "\n",
            "  [[2.1862745e-01 2.1862745e-01 2.1862745e-01]\n",
            "   [3.6568627e-01 3.6568627e-01 3.6568627e-01]\n",
            "   [3.6895424e-01 3.6895424e-01 3.6895424e-01]\n",
            "   ...\n",
            "   [4.1372526e-01 4.1372526e-01 4.1372526e-01]\n",
            "   [4.1764706e-01 4.1764706e-01 4.1764706e-01]\n",
            "   [2.5489333e-01 2.5489333e-01 2.5489333e-01]]\n",
            "\n",
            "  [[1.5370034e-01 1.5370034e-01 1.5370034e-01]\n",
            "   [2.4999401e-01 2.4999401e-01 2.4999401e-01]\n",
            "   [2.4716103e-01 2.4716103e-01 2.4716103e-01]\n",
            "   ...\n",
            "   [2.8485131e-01 2.8485131e-01 2.8485131e-01]\n",
            "   [2.9215017e-01 2.9215017e-01 2.9215017e-01]\n",
            "   [1.8397686e-01 1.8397686e-01 1.8397686e-01]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01056645 0.01056645 0.01056645]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00849681 0.00849681 0.00849681]\n",
            "   [0.00816997 0.00816997 0.00816997]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.00980392 0.00980392 0.00980392]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00849657 0.00849657 0.00849657]\n",
            "   [0.00816985 0.00816985 0.00816985]\n",
            "   [0.00511969 0.00511969 0.00511969]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.6389981  0.6389981  0.6389981 ]\n",
            "   [0.65392166 0.65392166 0.65392166]\n",
            "   [0.65904135 0.65904135 0.65904135]\n",
            "   ...\n",
            "   [0.6006537  0.6006537  0.6006537 ]\n",
            "   [0.60653627 0.60653627 0.60653627]\n",
            "   [0.61840975 0.61840975 0.61840975]]\n",
            "\n",
            "  [[0.64967316 0.64967316 0.64967316]\n",
            "   [0.6598039  0.6598039  0.6598039 ]\n",
            "   [0.66013074 0.66013074 0.66013074]\n",
            "   ...\n",
            "   [0.60882366 0.60882366 0.60882366]\n",
            "   [0.6137255  0.6137255  0.6137255 ]\n",
            "   [0.6120914  0.6120914  0.6120914 ]]\n",
            "\n",
            "  [[0.62766784 0.62766784 0.62766784]\n",
            "   [0.63463926 0.63463926 0.63463926]\n",
            "   [0.6617646  0.6617646  0.6617646 ]\n",
            "   ...\n",
            "   [0.6104571  0.6104571  0.6104571 ]\n",
            "   [0.6111113  0.6111113  0.6111113 ]\n",
            "   [0.6172111  0.6172111  0.6172111 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.52298445 0.52298445 0.52298445]\n",
            "   [0.53104573 0.53104573 0.53104573]\n",
            "   [0.30597928 0.30597928 0.30597928]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.54673177 0.54673177 0.54673177]\n",
            "   [0.54901963 0.54901963 0.54901963]\n",
            "   [0.30946475 0.30946475 0.30946475]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.3749356  0.3749356  0.3749356 ]\n",
            "   [0.37090537 0.37090537 0.37090537]\n",
            "   [0.21164243 0.21164243 0.21164243]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.15479293 0.15479293 0.15479293]\n",
            "   [0.17189534 0.17189534 0.17189534]\n",
            "   [0.18627451 0.18627451 0.18627451]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.16111112 0.16111112 0.16111112]\n",
            "   [0.18137255 0.18137255 0.18137255]\n",
            "   [0.19673201 0.19673201 0.19673201]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.11513887 0.11513887 0.11513887]\n",
            "   [0.12875497 0.12875497 0.12875497]\n",
            "   [0.13529062 0.13529062 0.13529062]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03148148 0.03148148 0.03148148]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.05087146 0.05087146 0.05087146]\n",
            "   ...\n",
            "   [0.12505457 0.12505457 0.12505457]\n",
            "   [0.12124183 0.12124183 0.12124183]\n",
            "   [0.107625   0.107625   0.107625  ]]\n",
            "\n",
            "  [[0.03235294 0.03235294 0.03235294]\n",
            "   [0.05196078 0.05196078 0.05196078]\n",
            "   [0.0503268  0.0503268  0.0503268 ]\n",
            "   ...\n",
            "   [0.14673199 0.14673199 0.14673199]\n",
            "   [0.14019608 0.14019608 0.14019608]\n",
            "   [0.11568531 0.11568531 0.11568531]]\n",
            "\n",
            "  [[0.03213508 0.03213508 0.03213508]\n",
            "   [0.05130719 0.05130719 0.05130719]\n",
            "   [0.04760349 0.04760349 0.04760349]\n",
            "   ...\n",
            "   [0.13191696 0.13191696 0.13191696]\n",
            "   [0.1264706  0.1264706  0.1264706 ]\n",
            "   [0.11938939 0.11938939 0.11938939]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05555556 0.05555556 0.05555556]\n",
            "   [0.07254902 0.07254902 0.07254902]\n",
            "   [0.06993464 0.06993464 0.06993464]\n",
            "   ...\n",
            "   [0.03986936 0.03986936 0.03986936]\n",
            "   [0.03758174 0.03758174 0.03758174]\n",
            "   [0.05871581 0.05871581 0.05871581]]\n",
            "\n",
            "  [[0.05555556 0.05555556 0.05555556]\n",
            "   [0.07156863 0.07156863 0.07156863]\n",
            "   [0.06960785 0.06960785 0.06960785]\n",
            "   ...\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04019608 0.04019608 0.04019608]\n",
            "   [0.0617659  0.0617659  0.0617659 ]]\n",
            "\n",
            "  [[0.05882369 0.05882369 0.05882369]\n",
            "   [0.09346517 0.09346517 0.09346517]\n",
            "   [0.08997922 0.08997922 0.08997922]\n",
            "   ...\n",
            "   [0.07309521 0.07309521 0.07309521]\n",
            "   [0.07549187 0.07549187 0.07549187]\n",
            "   [0.08170062 0.08170062 0.08170062]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.08616558 0.08616558 0.08616558]\n",
            "   [0.08398692 0.08398692 0.08398692]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   ...\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.12102394 0.12102394 0.12102394]]\n",
            "\n",
            "  [[0.08562092 0.08562092 0.08562092]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   ...\n",
            "   [0.11797389 0.11797389 0.11797389]\n",
            "   [0.11960784 0.11960784 0.11960784]\n",
            "   [0.11797377 0.11797377 0.11797377]]\n",
            "\n",
            "  [[0.08562092 0.08562092 0.08562092]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   ...\n",
            "   [0.11710241 0.11710241 0.11710241]\n",
            "   [0.11764706 0.11764706 0.11764706]\n",
            "   [0.11764706 0.11764706 0.11764706]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.082244   0.082244   0.082244  ]\n",
            "   [0.0820261  0.0820261  0.0820261 ]\n",
            "   [0.07908496 0.07908496 0.07908496]\n",
            "   ...\n",
            "   [0.00631795 0.00631795 0.00631795]\n",
            "   [0.00098051 0.00098051 0.00098051]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.08006536 0.08006536 0.08006536]\n",
            "   [0.07941177 0.07941177 0.07941177]\n",
            "   [0.07875817 0.07875817 0.07875817]\n",
            "   ...\n",
            "   [0.00457524 0.00457524 0.00457524]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.07843138 0.07843138 0.07843138]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   ...\n",
            "   [0.00065344 0.00065344 0.00065344]\n",
            "   [0.00032672 0.00032672 0.00032672]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.0587146  0.0587146  0.0587146 ]\n",
            "   [0.05620915 0.05620915 0.05620915]\n",
            "   [0.05969499 0.05969499 0.05969499]\n",
            "   ...\n",
            "   [0.07962978 0.07962978 0.07962978]\n",
            "   [0.08529412 0.08529412 0.08529412]\n",
            "   [0.08551201 0.08551201 0.08551201]]\n",
            "\n",
            "  [[0.05653594 0.05653594 0.05653594]\n",
            "   [0.05294118 0.05294118 0.05294118]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   ...\n",
            "   [0.04738566 0.04738566 0.04738566]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.05000024 0.05000024 0.05000024]]\n",
            "\n",
            "  [[0.04945534 0.04945534 0.04945534]\n",
            "   [0.05130719 0.05130719 0.05130719]\n",
            "   [0.05043573 0.05043573 0.05043573]\n",
            "   ...\n",
            "   [0.03202614 0.03202614 0.03202614]\n",
            "   [0.03169934 0.03169934 0.03169934]\n",
            "   [0.03246193 0.03246193 0.03246193]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.82004505 0.82004505 0.82004505]\n",
            "   [0.82353085 0.82353085 0.82353085]\n",
            "   [0.8172127  0.8172127  0.8172127 ]\n",
            "   ...\n",
            "   [0.30272296 0.30272296 0.30272296]\n",
            "   [0.2990195  0.2990195  0.2990195 ]\n",
            "   [0.28714556 0.28714556 0.28714556]]\n",
            "\n",
            "  [[0.87222224 0.87222224 0.87222224]\n",
            "   [0.8784314  0.8784314  0.8784314 ]\n",
            "   [0.8699346  0.8699346  0.8699346 ]\n",
            "   ...\n",
            "   [0.28692818 0.28692818 0.28692818]\n",
            "   [0.29313725 0.29313725 0.29313725]\n",
            "   [0.2830059  0.2830059  0.2830059 ]]\n",
            "\n",
            "  [[0.8650328  0.8650328  0.8650328 ]\n",
            "   [0.8696076  0.8696076  0.8696076 ]\n",
            "   [0.84640425 0.84640425 0.84640425]\n",
            "   ...\n",
            "   [0.2880173  0.2880173  0.2880173 ]\n",
            "   [0.27745026 0.27745026 0.27745026]\n",
            "   [0.26960704 0.26960704 0.26960704]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05119827 0.05119827 0.05119827]\n",
            "   [0.38398695 0.38398695 0.38398695]\n",
            "   [0.458061   0.458061   0.458061  ]\n",
            "   ...\n",
            "   [0.43573046 0.43573046 0.43573046]\n",
            "   [0.38039216 0.38039216 0.38039216]\n",
            "   [0.04998779 0.04998779 0.04998779]]\n",
            "\n",
            "  [[0.11111112 0.11111112 0.11111112]\n",
            "   [0.8303922  0.8303922  0.8303922 ]\n",
            "   [0.98758173 0.98758173 0.98758173]\n",
            "   ...\n",
            "   [0.95817083 0.95817083 0.95817083]\n",
            "   [0.83137256 0.83137256 0.83137256]\n",
            "   [0.1114107  0.1114107  0.1114107 ]]\n",
            "\n",
            "  [[0.10893247 0.10893247 0.10893247]\n",
            "   [0.825817   0.825817   0.825817  ]\n",
            "   [0.98496735 0.98496735 0.98496735]\n",
            "   ...\n",
            "   [0.9321367  0.9321367  0.9321367 ]\n",
            "   [0.8281046  0.8281046  0.8281046 ]\n",
            "   [0.10966821 0.10966821 0.10966821]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.11165562 0.11165562 0.11165562]\n",
            "   [0.8258166  0.8258166  0.8258166 ]\n",
            "   [0.98551095 0.98551095 0.98551095]\n",
            "   ...\n",
            "   [0.96840703 0.96840703 0.96840703]\n",
            "   [0.91078275 0.91078275 0.91078275]\n",
            "   [0.23493752 0.23493752 0.23493752]]\n",
            "\n",
            "  [[0.17124185 0.17124185 0.17124185]\n",
            "   [0.8539216  0.8539216  0.8539216 ]\n",
            "   [0.9663398  0.9663398  0.9663398 ]\n",
            "   ...\n",
            "   [0.88366175 0.88366175 0.88366175]\n",
            "   [0.8715686  0.8715686  0.8715686 ]\n",
            "   [0.21075583 0.21075583 0.21075583]]\n",
            "\n",
            "  [[0.22647004 0.22647004 0.22647004]\n",
            "   [0.4489976  0.4489976  0.4489976 ]\n",
            "   [0.4667502  0.4667502  0.4667502 ]\n",
            "   ...\n",
            "   [0.4666444  0.4666444  0.4666444 ]\n",
            "   [0.44344196 0.44344196 0.44344196]\n",
            "   [0.11414186 0.11414186 0.11414186]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.46992576 0.46992576 0.46992576]\n",
            "   [0.06437909 0.06437909 0.06437909]\n",
            "   [0.01067485 0.01067485 0.01067485]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.12941918 0.12941918 0.12941918]\n",
            "   [0.36862746 0.36862746 0.36862746]\n",
            "   [0.05554343 0.05554343 0.05554343]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.02854299 0.02854299 0.02854299]\n",
            "   [0.29052284 0.29052284 0.29052284]\n",
            "   [0.10096372 0.10096372 0.10096372]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01557701 0.01557701 0.01557701]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.03071887 0.03071887 0.03071887]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  [[0.0882353  0.0882353  0.0882353 ]\n",
            "   [0.0127451  0.0127451  0.0127451 ]\n",
            "   [0.0124183  0.0124183  0.0124183 ]\n",
            "   ...\n",
            "   [0.03071887 0.03071887 0.03071887]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  [[0.39401942 0.39401942 0.39401942]\n",
            "   [0.01372549 0.01372549 0.01372549]\n",
            "   [0.01416127 0.01416127 0.01416127]\n",
            "   ...\n",
            "   [0.03071887 0.03071887 0.03071887]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10337692 0.10337692 0.10337692]\n",
            "   [0.11601311 0.11601311 0.11601311]\n",
            "   [0.12538134 0.12538134 0.12538134]\n",
            "   ...\n",
            "   [0.3744006  0.3744006  0.3744006 ]\n",
            "   [0.37483642 0.37483642 0.37483642]\n",
            "   [0.21731192 0.21731192 0.21731192]]\n",
            "\n",
            "  [[0.11470588 0.11470588 0.11470588]\n",
            "   [0.1254902  0.1254902  0.1254902 ]\n",
            "   [0.13464053 0.13464053 0.13464053]\n",
            "   ...\n",
            "   [0.39150295 0.39150295 0.39150295]\n",
            "   [0.38431373 0.38431373 0.38431373]\n",
            "   [0.2218872  0.2218872  0.2218872 ]]\n",
            "\n",
            "  [[0.08300446 0.08300446 0.08300446]\n",
            "   [0.08921354 0.08921354 0.08921354]\n",
            "   [0.0954226  0.0954226  0.0954226 ]\n",
            "   ...\n",
            "   [0.26916504 0.26916504 0.26916504]\n",
            "   [0.26633325 0.26633325 0.26633325]\n",
            "   [0.15456557 0.15456557 0.15456557]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   [0.00849657 0.00849657 0.00849657]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01176471 0.01176471 0.01176471]\n",
            "   [0.01143791 0.01143791 0.01143791]\n",
            "   [0.01165577 0.01165577 0.01165577]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00980392 0.00980392 0.00980392]\n",
            "   [0.00882353 0.00882353 0.00882353]\n",
            "   [0.00947712 0.00947712 0.00947712]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.11285408 0.11285408 0.11285408]\n",
            "   [0.12712415 0.12712415 0.12712415]\n",
            "   [0.15010868 0.15010868 0.15010868]\n",
            "   ...\n",
            "   [0.26416045 0.26416045 0.26416045]\n",
            "   [0.21960784 0.21960784 0.21960784]\n",
            "   [0.21372525 0.21372525 0.21372525]]\n",
            "\n",
            "  [[0.11928105 0.11928105 0.11928105]\n",
            "   [0.12941177 0.12941177 0.12941177]\n",
            "   [0.13790849 0.13790849 0.13790849]\n",
            "   ...\n",
            "   [0.26470515 0.26470515 0.26470515]\n",
            "   [0.22352941 0.22352941 0.22352941]\n",
            "   [0.20686251 0.20686251 0.20686251]]\n",
            "\n",
            "  [[0.12843162 0.12843162 0.12843162]\n",
            "   [0.13169926 0.13169926 0.13169926]\n",
            "   [0.13932475 0.13932475 0.13932475]\n",
            "   ...\n",
            "   [0.25980324 0.25980324 0.25980324]\n",
            "   [0.22908504 0.22908504 0.22908504]\n",
            "   [0.22233142 0.22233142 0.22233142]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.1774511  0.1774511  0.1774511 ]\n",
            "   [0.18071875 0.18071875 0.18071875]\n",
            "   [0.18235302 0.18235302 0.18235302]\n",
            "   ...\n",
            "   [0.05152511 0.05152511 0.05152511]\n",
            "   [0.04934644 0.04934644 0.04934644]\n",
            "   [0.04716774 0.04716774 0.04716774]]\n",
            "\n",
            "  [[0.17941177 0.17941177 0.17941177]\n",
            "   [0.17450981 0.17450981 0.17450981]\n",
            "   [0.18431373 0.18431373 0.18431373]\n",
            "   ...\n",
            "   [0.05784302 0.05784302 0.05784302]\n",
            "   [0.05196078 0.05196078 0.05196078]\n",
            "   [0.04771226 0.04771226 0.04771226]]\n",
            "\n",
            "  [[0.1808281  0.1808281  0.1808281 ]\n",
            "   [0.18627499 0.18627499 0.18627499]\n",
            "   [0.18736404 0.18736404 0.18736404]\n",
            "   ...\n",
            "   [0.06525064 0.06525064 0.06525064]\n",
            "   [0.05620931 0.05620931 0.05620931]\n",
            "   [0.05043584 0.05043584 0.05043584]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03660131 0.03660131 0.03660131]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05544662 0.05544662 0.05544662]\n",
            "   ...\n",
            "   [0.07189558 0.07189558 0.07189558]\n",
            "   [0.08039216 0.08039216 0.08039216]\n",
            "   [0.11775772 0.11775772 0.11775772]]\n",
            "\n",
            "  [[0.03464052 0.03464052 0.03464052]\n",
            "   [0.05784314 0.05784314 0.05784314]\n",
            "   [0.05653595 0.05653595 0.05653595]\n",
            "   ...\n",
            "   [0.07189558 0.07189558 0.07189558]\n",
            "   [0.08137255 0.08137255 0.08137255]\n",
            "   [0.09085    0.09085    0.09085   ]]\n",
            "\n",
            "  [[0.03267974 0.03267974 0.03267974]\n",
            "   [0.05849673 0.05849673 0.05849673]\n",
            "   [0.05816994 0.05816994 0.05816994]\n",
            "   ...\n",
            "   [0.07080613 0.07080613 0.07080613]\n",
            "   [0.07908496 0.07908496 0.07908496]\n",
            "   [0.10207049 0.10207049 0.10207049]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.04182991 0.04182991 0.04182991]\n",
            "   [0.0330065  0.0330065  0.0330065 ]\n",
            "   [0.02145923 0.02145923 0.02145923]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.04215674 0.04215674 0.04215674]\n",
            "   [0.03235294 0.03235294 0.03235294]\n",
            "   [0.01928065 0.01928065 0.01928065]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.04248358 0.04248358 0.04248358]\n",
            "   [0.03333334 0.03333334 0.03333334]\n",
            "   [0.01764658 0.01764658 0.01764658]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.00490196 0.00490196 0.00490196]\n",
            "   [0.01078431 0.01078431 0.01078431]\n",
            "   [0.01013072 0.01013072 0.01013072]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01797426 0.01797426 0.01797426]\n",
            "   [0.03954336 0.03954336 0.03954336]\n",
            "   [0.03987024 0.03987024 0.03987024]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01230937 0.01230937 0.01230937]\n",
            "   [0.0127451  0.0127451  0.0127451 ]\n",
            "   [0.01100218 0.01100218 0.01100218]\n",
            "   ...\n",
            "   [0.0312636  0.0312636  0.0312636 ]\n",
            "   [0.03071895 0.03071895 0.03071895]\n",
            "   [0.03671053 0.03671053 0.03671053]]\n",
            "\n",
            "  [[0.01143791 0.01143791 0.01143791]\n",
            "   [0.00686275 0.00686275 0.00686275]\n",
            "   [0.00555556 0.00555556 0.00555556]\n",
            "   ...\n",
            "   [0.02875809 0.02875809 0.02875809]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02712426 0.02712426 0.02712426]]\n",
            "\n",
            "  [[0.00566449 0.00566449 0.00566449]\n",
            "   [0.00588235 0.00588235 0.00588235]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   ...\n",
            "   [0.02135082 0.02135082 0.02135082]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02080597 0.02080597 0.02080597]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.3842049  0.3842049  0.3842049 ]\n",
            "   [0.41830075 0.41830075 0.41830075]\n",
            "   [0.44368175 0.44368175 0.44368175]\n",
            "   ...\n",
            "   [0.03050008 0.03050008 0.03050008]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.39934638 0.39934638 0.39934638]\n",
            "   [0.41862744 0.41862744 0.41862744]\n",
            "   [0.43300655 0.43300655 0.43300655]\n",
            "   ...\n",
            "   [0.01143763 0.01143763 0.01143763]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.40250498 0.40250498 0.40250498]\n",
            "   [0.41732034 0.41732034 0.41732034]\n",
            "   [0.41470516 0.41470516 0.41470516]\n",
            "   ...\n",
            "   [0.00054452 0.00054452 0.00054452]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.16318083 0.16318083 0.16318083]\n",
            "   [0.15947713 0.15947713 0.15947713]\n",
            "   [0.14705883 0.14705883 0.14705883]\n",
            "   ...\n",
            "   [0.00272324 0.00272324 0.00272324]\n",
            "   [0.00359477 0.00359477 0.00359477]\n",
            "   [0.01535988 0.01535988 0.01535988]]\n",
            "\n",
            "  [[0.17124182 0.17124182 0.17124182]\n",
            "   [0.17156863 0.17156863 0.17156863]\n",
            "   [0.15882353 0.15882353 0.15882353]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.00098039 0.00098039 0.00098039]\n",
            "   [0.00196078 0.00196078 0.00196078]]\n",
            "\n",
            "  [[0.15806101 0.15806101 0.15806101]\n",
            "   [0.17058824 0.17058824 0.17058824]\n",
            "   [0.16023965 0.16023965 0.16023965]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.02418301 0.02418301 0.02418301]\n",
            "   [0.02908493 0.02908493 0.02908493]\n",
            "   [0.02418293 0.02418293 0.02418293]\n",
            "   ...\n",
            "   [0.0096952  0.0096952  0.0096952 ]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]]\n",
            "\n",
            "  [[0.02222222 0.02222222 0.02222222]\n",
            "   [0.0254902  0.0254902  0.0254902 ]\n",
            "   [0.02222222 0.02222222 0.02222222]\n",
            "   ...\n",
            "   [0.01241838 0.01241838 0.01241838]\n",
            "   [0.01372549 0.01372549 0.01372549]\n",
            "   [0.01339877 0.01339877 0.01339877]]\n",
            "\n",
            "  [[0.02026144 0.02026144 0.02026144]\n",
            "   [0.02516348 0.02516348 0.02516348]\n",
            "   [0.0240741  0.0240741  0.0240741 ]\n",
            "   ...\n",
            "   [0.00915025 0.00915025 0.00915025]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.0143794  0.0143794  0.0143794 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05490196 0.05490196 0.05490196]\n",
            "   [0.05816993 0.05816993 0.05816993]\n",
            "   [0.05544662 0.05544662 0.05544662]\n",
            "   ...\n",
            "   [0.03082782 0.03082782 0.03082782]\n",
            "   [0.02810458 0.02810458 0.02810458]\n",
            "   [0.03082802 0.03082802 0.03082802]]\n",
            "\n",
            "  [[0.05163399 0.05163399 0.05163399]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   ...\n",
            "   [0.03104571 0.03104571 0.03104571]\n",
            "   [0.02941176 0.02941176 0.02941176]\n",
            "   [0.02941176 0.02941176 0.02941176]]\n",
            "\n",
            "  [[0.05163399 0.05163399 0.05163399]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   ...\n",
            "   [0.03071887 0.03071887 0.03071887]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02080617 0.02080617 0.02080617]\n",
            "   ...\n",
            "   [0.0150326  0.0150326  0.0150326 ]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01503284 0.01503284 0.01503284]]\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.0150326  0.0150326  0.0150326 ]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01339877 0.01339877 0.01339877]]\n",
            "\n",
            "  [[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01230922 0.01230922 0.01230922]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  [[0.02320261 0.02320261 0.02320261]\n",
            "   [0.02254902 0.02254902 0.02254902]\n",
            "   [0.02189542 0.02189542 0.02189542]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  [[0.02342048 0.02342048 0.02342048]\n",
            "   [0.02320261 0.02320261 0.02320261]\n",
            "   [0.02298475 0.02298475 0.02298475]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00729841 0.00729841 0.00729841]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00228762 0.00228762 0.00228762]\n",
            "   [0.00337705 0.00337705 0.00337705]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00620915 0.00620915 0.00620915]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.0022875  0.0022875  0.0022875 ]\n",
            "   [0.00337701 0.00337701 0.00337701]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1.2287582e-01 1.2287582e-01 1.2287582e-01]\n",
            "   [1.2287582e-01 1.2287582e-01 1.2287582e-01]\n",
            "   [1.2505446e-01 1.2505446e-01 1.2505446e-01]\n",
            "   ...\n",
            "   [4.6710292e-01 4.6710292e-01 4.6710292e-01]\n",
            "   [5.0686276e-01 5.0686276e-01 5.0686276e-01]\n",
            "   [5.5207109e-01 5.5207109e-01 5.5207109e-01]]\n",
            "\n",
            "  [[1.3529412e-01 1.3529412e-01 1.3529412e-01]\n",
            "   [1.3529412e-01 1.3529412e-01 1.3529412e-01]\n",
            "   [1.3529412e-01 1.3529412e-01 1.3529412e-01]\n",
            "   ...\n",
            "   [4.8627523e-01 4.8627523e-01 4.8627523e-01]\n",
            "   [5.2058822e-01 5.2058822e-01 5.2058822e-01]\n",
            "   [5.3202647e-01 5.3202647e-01 5.3202647e-01]]\n",
            "\n",
            "  [[1.5424837e-01 1.5424837e-01 1.5424837e-01]\n",
            "   [1.5261438e-01 1.5261438e-01 1.5261438e-01]\n",
            "   [1.5152505e-01 1.5152505e-01 1.5152505e-01]\n",
            "   ...\n",
            "   [5.2614403e-01 5.2614403e-01 5.2614403e-01]\n",
            "   [5.3267974e-01 5.3267974e-01 5.3267974e-01]\n",
            "   [5.3431398e-01 5.3431398e-01 5.3431398e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[3.2678940e-03 3.2678940e-03 3.2678940e-03]\n",
            "   [1.6339470e-03 1.6339470e-03 1.6339470e-03]\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   ...\n",
            "   [7.9085045e-02 7.9085045e-02 7.9085045e-02]\n",
            "   [8.1045829e-02 8.1045829e-02 8.1045829e-02]\n",
            "   [8.5185245e-02 8.5185245e-02 8.5185245e-02]]\n",
            "\n",
            "  [[3.2679742e-04 3.2679742e-04 3.2679742e-04]\n",
            "   [9.8039221e-04 9.8039221e-04 9.8039221e-04]\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   ...\n",
            "   [8.2679778e-02 8.2679778e-02 8.2679778e-02]\n",
            "   [8.5294120e-02 8.5294120e-02 8.5294120e-02]\n",
            "   [8.4640443e-02 8.4640443e-02 8.4640443e-02]]\n",
            "\n",
            "  [[3.3770392e-03 3.3770392e-03 3.3770392e-03]\n",
            "   [1.9607844e-03 1.9607844e-03 1.9607844e-03]\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   ...\n",
            "   [8.1917107e-02 8.1917107e-02 8.1917107e-02]\n",
            "   [8.4640443e-02 8.4640443e-02 8.4640443e-02]\n",
            "   [8.9542642e-02 8.9542642e-02 8.9542642e-02]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.01503268 0.01503268 0.01503268]\n",
            "   [0.0124183  0.0124183  0.0124183 ]\n",
            "   [0.01579521 0.01579521 0.01579521]\n",
            "   ...\n",
            "   [0.02342047 0.02342047 0.02342047]\n",
            "   [0.02581699 0.02581699 0.02581699]\n",
            "   [0.02984755 0.02984755 0.02984755]]\n",
            "\n",
            "  [[0.01764706 0.01764706 0.01764706]\n",
            "   [0.02058824 0.02058824 0.02058824]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.02810442 0.02810442 0.02810442]\n",
            "   [0.02156863 0.02156863 0.02156863]\n",
            "   [0.02483676 0.02483676 0.02483676]]\n",
            "\n",
            "  [[0.02298475 0.02298475 0.02298475]\n",
            "   [0.02712419 0.02712419 0.02712419]\n",
            "   [0.03071895 0.03071895 0.03071895]\n",
            "   ...\n",
            "   [0.03605674 0.03605674 0.03605674]\n",
            "   [0.03856209 0.03856209 0.03856209]\n",
            "   [0.03997835 0.03997835 0.03997835]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.16024    0.16024    0.16024   ]\n",
            "   [0.19738603 0.19738603 0.19738603]\n",
            "   [0.22854045 0.22854045 0.22854045]\n",
            "   ...\n",
            "   [0.05054463 0.05054463 0.05054463]\n",
            "   [0.04967328 0.04967328 0.04967328]\n",
            "   [0.05043588 0.05043588 0.05043588]]\n",
            "\n",
            "  [[0.17810456 0.17810456 0.17810456]\n",
            "   [0.21764706 0.21764706 0.21764706]\n",
            "   [0.23104575 0.23104575 0.23104575]\n",
            "   ...\n",
            "   [0.04640539 0.04640539 0.04640539]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.04901961 0.04901961 0.04901961]]\n",
            "\n",
            "  [[0.18071887 0.18071887 0.18071887]\n",
            "   [0.22156863 0.22156863 0.22156863]\n",
            "   [0.2270152  0.2270152  0.2270152 ]\n",
            "   ...\n",
            "   [0.04716798 0.04716798 0.04716798]\n",
            "   [0.04901961 0.04901961 0.04901961]\n",
            "   [0.0497824  0.0497824  0.0497824 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05958606 0.05958606 0.05958606]\n",
            "   [0.10065359 0.10065359 0.10065359]\n",
            "   [0.09814815 0.09814815 0.09814815]\n",
            "   ...\n",
            "   [0.14324604 0.14324604 0.14324604]\n",
            "   [0.14150326 0.14150326 0.14150326]\n",
            "   [0.15501134 0.15501134 0.15501134]]\n",
            "\n",
            "  [[0.05980392 0.05980392 0.05980392]\n",
            "   [0.10098039 0.10098039 0.10098039]\n",
            "   [0.09803922 0.09803922 0.09803922]\n",
            "   ...\n",
            "   [0.13856201 0.13856201 0.13856201]\n",
            "   [0.14019608 0.14019608 0.14019608]\n",
            "   [0.1516343  0.1516343  0.1516343 ]]\n",
            "\n",
            "  [[0.06274511 0.06274511 0.06274511]\n",
            "   [0.0996732  0.0996732  0.0996732 ]\n",
            "   [0.09738562 0.09738562 0.09738562]\n",
            "   ...\n",
            "   [0.14259245 0.14259245 0.14259245]\n",
            "   [0.1388889  0.1388889  0.1388889 ]\n",
            "   [0.14226584 0.14226584 0.14226584]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.06590413 0.06590413 0.06590413]\n",
            "   [0.11568628 0.11568628 0.11568628]\n",
            "   [0.10936814 0.10936814 0.10936814]\n",
            "   ...\n",
            "   [0.1092592  0.1092592  0.1092592 ]\n",
            "   [0.10915048 0.10915048 0.10915048]\n",
            "   [0.11122019 0.11122019 0.11122019]]\n",
            "\n",
            "  [[0.06503268 0.06503268 0.06503268]\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10849673 0.10849673 0.10849673]\n",
            "   ...\n",
            "   [0.11013076 0.11013076 0.11013076]\n",
            "   [0.11568628 0.11568628 0.11568628]\n",
            "   [0.11633971 0.11633971 0.11633971]]\n",
            "\n",
            "  [[0.06525058 0.06525058 0.06525058]\n",
            "   [0.11339878 0.11339878 0.11339878]\n",
            "   [0.10980392 0.10980392 0.10980392]\n",
            "   ...\n",
            "   [0.10718946 0.10718946 0.10718946]\n",
            "   [0.11241814 0.11241814 0.11241814]\n",
            "   [0.11383437 0.11383437 0.11383437]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00457516 0.00457516 0.00457516]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00620915 0.00620915 0.00620915]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.05185186 0.05185186 0.05185186]\n",
            "   [0.38594773 0.38594773 0.38594773]\n",
            "   [0.4275599  0.4275599  0.4275599 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.11176472 0.11176472 0.11176472]\n",
            "   [0.83235294 0.83235294 0.83235294]\n",
            "   [0.95980394 0.95980394 0.95980394]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.10904141 0.10904141 0.10904141]\n",
            "   [0.8261438  0.8261438  0.8261438 ]\n",
            "   [0.9735294  0.9735294  0.9735294 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10980386 0.10980386 0.10980386]\n",
            "   [0.828431   0.828431   0.828431  ]\n",
            "   [0.9255976  0.9255976  0.9255976 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.12941179 0.12941179 0.12941179]\n",
            "   [0.84607846 0.84607846 0.84607846]\n",
            "   [0.8993464  0.8993464  0.8993464 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.11960626 0.11960626 0.11960626]\n",
            "   [0.43069708 0.43069708 0.43069708]\n",
            "   [0.46130586 0.46130586 0.46130586]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   ...\n",
            "   [3.2679739e-03 3.2679739e-03 3.2679739e-03]\n",
            "   [3.2679739e-03 3.2679739e-03 3.2679739e-03]\n",
            "   [3.8126628e-03 3.8126628e-03 3.8126628e-03]]\n",
            "\n",
            "  [[1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   ...\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "   [1.6340667e-03 1.6340667e-03 1.6340667e-03]]\n",
            "\n",
            "  [[1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
            "   ...\n",
            "   [5.4472889e-04 5.4472889e-04 5.4472889e-04]\n",
            "   [3.2679746e-03 3.2679746e-03 3.2679746e-03]\n",
            "   [5.4452947e-04 5.4452947e-04 5.4452947e-04]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.8551165e-01 1.8551165e-01 1.8551165e-01]\n",
            "   [2.0849657e-01 2.0849657e-01 2.0849657e-01]\n",
            "   [2.1514162e-01 2.1514162e-01 2.1514162e-01]\n",
            "   ...\n",
            "   [2.5871456e-01 2.5871456e-01 2.5871456e-01]\n",
            "   [2.4738567e-01 2.4738567e-01 2.4738567e-01]\n",
            "   [2.3387761e-01 2.3387761e-01 2.3387761e-01]]\n",
            "\n",
            "  [[1.7058824e-01 1.7058824e-01 1.7058824e-01]\n",
            "   [2.0098040e-01 2.0098040e-01 2.0098040e-01]\n",
            "   [2.1176471e-01 2.1176471e-01 2.1176471e-01]\n",
            "   ...\n",
            "   [2.6078406e-01 2.6078406e-01 2.6078406e-01]\n",
            "   [2.4705882e-01 2.4705882e-01 2.4705882e-01]\n",
            "   [2.3333286e-01 2.3333286e-01 2.3333286e-01]]\n",
            "\n",
            "  [[1.7037043e-01 1.7037043e-01 1.7037043e-01]\n",
            "   [1.9019561e-01 1.9019561e-01 1.9019561e-01]\n",
            "   [2.0348564e-01 2.0348564e-01 2.0348564e-01]\n",
            "   ...\n",
            "   [2.5958586e-01 2.5958586e-01 2.5958586e-01]\n",
            "   [2.4182990e-01 2.4182990e-01 2.4182990e-01]\n",
            "   [2.2625203e-01 2.2625203e-01 2.2625203e-01]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   [1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   ...\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.17712419 0.17712419 0.17712419]\n",
            "   [0.2784314  0.2784314  0.2784314 ]\n",
            "   [0.29477125 0.29477125 0.29477125]\n",
            "   ...\n",
            "   [0.37788647 0.37788647 0.37788647]\n",
            "   [0.3764706  0.3764706  0.3764706 ]\n",
            "   [0.3565346  0.3565346  0.3565346 ]]\n",
            "\n",
            "  [[0.16862746 0.16862746 0.16862746]\n",
            "   [0.27254903 0.27254903 0.27254903]\n",
            "   [0.29150328 0.29150328 0.29150328]\n",
            "   ...\n",
            "   [0.38169926 0.38169926 0.38169926]\n",
            "   [0.3882353  0.3882353  0.3882353 ]\n",
            "   [0.3604557  0.3604557  0.3604557 ]]\n",
            "\n",
            "  [[0.16612202 0.16612202 0.16612202]\n",
            "   [0.2617647  0.2617647  0.2617647 ]\n",
            "   [0.2751634  0.2751634  0.2751634 ]\n",
            "   ...\n",
            "   [0.3561003  0.3561003  0.3561003 ]\n",
            "   [0.3640523  0.3640523  0.3640523 ]\n",
            "   [0.33551034 0.33551034 0.33551034]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.16601308 0.16601308 0.16601308]\n",
            "   [0.22352941 0.22352941 0.22352941]\n",
            "   [0.20261438 0.20261438 0.20261438]\n",
            "   ...\n",
            "   [0.10119815 0.10119815 0.10119815]\n",
            "   [0.09150319 0.09150319 0.09150319]\n",
            "   [0.09923812 0.09923812 0.09923812]]\n",
            "\n",
            "  [[0.16633987 0.16633987 0.16633987]\n",
            "   [0.23333333 0.23333333 0.23333333]\n",
            "   [0.22026144 0.22026144 0.22026144]\n",
            "   ...\n",
            "   [0.1183005  0.1183005  0.1183005 ]\n",
            "   [0.10784314 0.10784314 0.10784314]\n",
            "   [0.11372597 0.11372597 0.11372597]]\n",
            "\n",
            "  [[0.1699348  0.1699348  0.1699348 ]\n",
            "   [0.25130758 0.25130758 0.25130758]\n",
            "   [0.24825758 0.24825758 0.24825758]\n",
            "   ...\n",
            "   [0.14956485 0.14956485 0.14956485]\n",
            "   [0.14379165 0.14379165 0.14379165]\n",
            "   [0.13965185 0.13965185 0.13965185]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.03409586 0.03409586 0.03409586]\n",
            "   [0.03366013 0.03366013 0.03366013]\n",
            "   [0.03867103 0.03867103 0.03867103]\n",
            "   ...\n",
            "   [0.07570813 0.07570813 0.07570813]\n",
            "   [0.07908496 0.07908496 0.07908496]\n",
            "   [0.07973856 0.07973856 0.07973856]]\n",
            "\n",
            "  [[0.03169935 0.03169935 0.03169935]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.0372549  0.0372549  0.0372549 ]\n",
            "   ...\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.08137255 0.08137255 0.08137255]\n",
            "   [0.08431373 0.08431373 0.08431373]]\n",
            "\n",
            "  [[0.03420479 0.03420479 0.03420479]\n",
            "   [0.03039216 0.03039216 0.03039216]\n",
            "   [0.03420479 0.03420479 0.03420479]\n",
            "   ...\n",
            "   [0.08115461 0.08115461 0.08115461]\n",
            "   [0.07712418 0.07712418 0.07712418]\n",
            "   [0.07581699 0.07581699 0.07581699]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.50904125 0.50904125 0.50904125]\n",
            "   [0.5081697  0.5081697  0.5081697 ]\n",
            "   [0.49422672 0.49422672 0.49422672]\n",
            "   ...\n",
            "   [0.59313744 0.59313744 0.59313744]\n",
            "   [0.5869284  0.5869284  0.5869284 ]\n",
            "   [0.58180815 0.58180815 0.58180815]]\n",
            "\n",
            "  [[0.5022876  0.5022876  0.5022876 ]\n",
            "   [0.5029412  0.5029412  0.5029412 ]\n",
            "   [0.5035948  0.5035948  0.5035948 ]\n",
            "   ...\n",
            "   [0.6049021  0.6049021  0.6049021 ]\n",
            "   [0.6039216  0.6039216  0.6039216 ]\n",
            "   [0.59150296 0.59150296 0.59150296]]\n",
            "\n",
            "  [[0.5118741  0.5118741  0.5118741 ]\n",
            "   [0.51078457 0.51078457 0.51078457]\n",
            "   [0.50642705 0.50642705 0.50642705]\n",
            "   ...\n",
            "   [0.6150333  0.6150333  0.6150333 ]\n",
            "   [0.62091565 0.62091565 0.62091565]\n",
            "   [0.6110024  0.6110024  0.6110024 ]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.0711329  0.0711329  0.0711329 ]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   [0.07331154 0.07331154 0.07331154]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.07385621 0.07385621 0.07385621]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.0711329  0.0711329  0.0711329 ]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.07385621 0.07385621 0.07385621]\n",
            "   [0.07222218 0.07222218 0.07222218]\n",
            "   [0.07167761 0.07167761 0.07167761]\n",
            "   ...\n",
            "   [0.07058824 0.07058824 0.07058824]\n",
            "   [0.07254902 0.07254902 0.07254902]\n",
            "   [0.04182847 0.04182847 0.04182847]]\n",
            "\n",
            "  [[0.07941177 0.07941177 0.07941177]\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   [0.07614379 0.07614379 0.07614379]\n",
            "   ...\n",
            "   [0.07254902 0.07254902 0.07254902]\n",
            "   [0.07450981 0.07450981 0.07450981]\n",
            "   [0.04378925 0.04378925 0.04378925]]\n",
            "\n",
            "  [[0.05609881 0.05609881 0.05609881]\n",
            "   [0.0522863  0.0522863  0.0522863 ]\n",
            "   [0.0522863  0.0522863  0.0522863 ]\n",
            "   ...\n",
            "   [0.04836474 0.04836474 0.04836474]\n",
            "   [0.05032552 0.05032552 0.05032552]\n",
            "   [0.03049928 0.03049928 0.03049928]]]], shape=(1, 768, 768, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0.04248366 0.04248366 0.04248366]\n",
            "   [0.04052287 0.04052287 0.04052287]\n",
            "   [0.03910675 0.03910675 0.03910675]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.0375817  0.0375817  0.0375817 ]\n",
            "   [0.0382353  0.0382353  0.0382353 ]\n",
            "   [0.03888889 0.03888889 0.03888889]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  [[0.03540305 0.03540305 0.03540305]\n",
            "   [0.03594771 0.03594771 0.03594771]\n",
            "   [0.03594771 0.03594771 0.03594771]\n",
            "   ...\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.01176471 0.01176471 0.01176471]\n",
            "   [0.00849657 0.00849657 0.00849657]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03583877 0.03583877 0.03583877]\n",
            "   [0.03888885 0.03888885 0.03888885]\n",
            "   [0.03921569 0.03921569 0.03921569]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.03921569 0.03921569 0.03921569]\n",
            "   [0.04019608 0.04019608 0.04019608]\n",
            "   [0.03954248 0.03954248 0.03954248]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]\n",
            "\n",
            "  [[0.02952003 0.02952003 0.02952003]\n",
            "   [0.02679659 0.02679659 0.02679659]\n",
            "   [0.02625206 0.02625206 0.02625206]\n",
            "   ...\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00392157 0.00392157 0.00392157]]]], shape=(1, 768, 768, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-502ddb59fee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m     return \"tf.Tensor(%s, shape=%s, dtype=%s)\" % (numpy_text(self), self.shape,\n\u001b[0m\u001b[1;32m   1013\u001b[0m                                                   self.dtype.name)\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy_text\u001b[0;34m(tensor, is_repr)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_numpy_compatible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_repr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaX722tJhYXh",
        "outputId": "e822843b-c154-4cd5-ef92-308c2095089c"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['002a34c58c5b758217ed1f584ccbcfe9',\n",
              "       '004f33259ee4aef671c2b95d54e4be68',\n",
              "       '008bdde2af2462e86fd373a445d0f4cd', ...,\n",
              "       'ffaa288c8abca300974f043b57d81521',\n",
              "       'ffc441e0c8b7153844047483a577e7c3',\n",
              "       'ffccf1709d0081d122a1d1f9edbefdf1'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMFk-cMhmly"
      },
      "source": [
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6LOiSoo6hnfA",
        "outputId": "cb4d6f24-3fb7-4227-85da-d02609af2cce"
      },
      "source": [
        "df_total_sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9\n",
              "1     004f33259ee4aef671c2b95d54e4be68\n",
              "2     008bdde2af2462e86fd373a445d0f4cd\n",
              "3     009bc039326338823ca3aa84381f17f1\n",
              "4     00a2145de1886cb9eb88869c85d74080\n",
              "...                                ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364\n",
              "2997  ffaa288c8abca300974f043b57d81521\n",
              "2998  ffc441e0c8b7153844047483a577e7c3\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1\n",
              "\n",
              "[3000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "DvkmEybnhuxB",
        "outputId": "a9aa89a9-9785-4caf-d25f-9f91c82c5ed8"
      },
      "source": [
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub\n",
        "#df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.002502</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.195280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.197328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "      <td>0.174792</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.007077</td>\n",
              "      <td>0.122213</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>0.006038</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.016485</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.023178</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>0.033101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.199561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.140198</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.008863</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.019245</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.062666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.034280</td>\n",
              "      <td>0.107503</td>\n",
              "      <td>0.099559</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.036410</td>\n",
              "      <td>0.178246</td>\n",
              "      <td>0.184320</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.069370</td>\n",
              "      <td>0.002304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "      <td>0.195568</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>0.118982</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.006666</td>\n",
              "      <td>0.011426</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.045798</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.026318</td>\n",
              "      <td>0.010865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>0.004295</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.011130</td>\n",
              "      <td>0.022830</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.125751</td>\n",
              "      <td>0.071830</td>\n",
              "      <td>0.002736</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.162730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "      <td>0.018895</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.021862</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.003354</td>\n",
              "      <td>0.163176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "      <td>0.145861</td>\n",
              "      <td>0.095181</td>\n",
              "      <td>0.034802</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.008672</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.050831</td>\n",
              "      <td>0.070977</td>\n",
              "      <td>0.008625</td>\n",
              "      <td>0.026598</td>\n",
              "      <td>0.189738</td>\n",
              "      <td>0.199768</td>\n",
              "      <td>0.004524</td>\n",
              "      <td>0.194726</td>\n",
              "      <td>0.000403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name    class0  ...   class13   class14\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9  0.000875  ...  0.001309  0.195280\n",
              "1     004f33259ee4aef671c2b95d54e4be68  0.001957  ...  0.000784  0.197328\n",
              "2     008bdde2af2462e86fd373a445d0f4cd  0.174792  ...  0.018443  0.033101\n",
              "3     009bc039326338823ca3aa84381f17f1  0.000378  ...  0.000440  0.199561\n",
              "4     00a2145de1886cb9eb88869c85d74080  0.086371  ...  0.005706  0.062666\n",
              "...                                ...       ...  ...       ...       ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02  0.169418  ...  0.069370  0.002304\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364  0.195568  ...  0.026318  0.010865\n",
              "2997  ffaa288c8abca300974f043b57d81521  0.001954  ...  0.005590  0.162730\n",
              "2998  ffc441e0c8b7153844047483a577e7c3  0.018895  ...  0.003354  0.163176\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1  0.145861  ...  0.194726  0.000403\n",
              "\n",
              "[3000 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPmlTjd8exx8",
        "outputId": "b53ed405-d72e-4f0b-ec25-4c105d87f558"
      },
      "source": [
        "#model prediction\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(3000, 15))\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    #pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / 10\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "#pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)\n",
        "print(df_sub)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1490]\n",
            "6/6 [==============================] - 17s 185ms/step\n",
            "12/12 [==============================] - 18s 189ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 17s 189ms/step\n",
            "12/12 [==============================] - 18s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 17s 188ms/step\n",
            "12/12 [==============================] - 18s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 17s 189ms/step\n",
            "12/12 [==============================] - 18s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 17s 189ms/step\n",
            "12/12 [==============================] - 18s 190ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1494]\n",
            "6/6 [==============================] - 17s 188ms/step\n",
            "12/12 [==============================] - 18s 188ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 17s 188ms/step\n",
            "12/12 [==============================] - 18s 187ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1516]\n",
            "6/6 [==============================] - 17s 188ms/step\n",
            "12/12 [==============================] - 18s 187ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1508]\n",
            "6/6 [==============================] - 17s 189ms/step\n",
            "12/12 [==============================] - 18s 191ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.104.152.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.152.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 18s 189ms/step\n",
            "12/12 [==============================] - 18s 189ms/step\n",
            "                            image_name    class0  ...   class13   class14\n",
            "0     002a34c58c5b758217ed1f584ccbcfe9  0.005034  ...  0.009353  0.984979\n",
            "1     004f33259ee4aef671c2b95d54e4be68  0.001685  ...  0.001336  0.998553\n",
            "2     008bdde2af2462e86fd373a445d0f4cd  0.990660  ...  0.087530  0.003722\n",
            "3     009bc039326338823ca3aa84381f17f1  0.000372  ...  0.001005  0.999513\n",
            "4     00a2145de1886cb9eb88869c85d74080  0.796978  ...  0.031763  0.047401\n",
            "...                                ...       ...  ...       ...       ...\n",
            "2995  ff91fb82429a27521bbec8569b041f02  0.896037  ...  0.236092  0.007882\n",
            "2996  ff9fcc4087ed5e941209aa3fa948e364  0.973011  ...  0.071007  0.039980\n",
            "2997  ffaa288c8abca300974f043b57d81521  0.025826  ...  0.059805  0.715381\n",
            "2998  ffc441e0c8b7153844047483a577e7c3  0.211900  ...  0.011565  0.723789\n",
            "2999  ffccf1709d0081d122a1d1f9edbefdf1  0.507813  ...  0.990488  0.001554\n",
            "\n",
            "[3000 rows x 16 columns]\n",
            "total auc: 0.9619714175254584\n",
            "class 14 auc: 0.9929399466520913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>0.997763</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.000404</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.999689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.444816</td>\n",
              "      <td>0.017011</td>\n",
              "      <td>0.013741</td>\n",
              "      <td>0.466103</td>\n",
              "      <td>0.072492</td>\n",
              "      <td>0.630402</td>\n",
              "      <td>0.756271</td>\n",
              "      <td>0.422619</td>\n",
              "      <td>0.047154</td>\n",
              "      <td>0.227084</td>\n",
              "      <td>0.057479</td>\n",
              "      <td>0.191088</td>\n",
              "      <td>0.007570</td>\n",
              "      <td>0.489955</td>\n",
              "      <td>0.044485</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.001012</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.998512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.553679</td>\n",
              "      <td>0.063889</td>\n",
              "      <td>0.021123</td>\n",
              "      <td>0.394695</td>\n",
              "      <td>0.950448</td>\n",
              "      <td>0.010452</td>\n",
              "      <td>0.349102</td>\n",
              "      <td>0.954452</td>\n",
              "      <td>0.840761</td>\n",
              "      <td>0.255457</td>\n",
              "      <td>0.167033</td>\n",
              "      <td>0.317005</td>\n",
              "      <td>0.057606</td>\n",
              "      <td>0.181171</td>\n",
              "      <td>0.017205</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.003528  0.997763     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.000490  0.999689     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.489955  0.044485     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.001067  0.998512     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.181171  0.017205     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "rek_1tb81wnM",
        "outputId": "13748b81-6c54-43d1-bfb9-692b8ea69350"
      },
      "source": [
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "#pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total auc: 0.9619714175254584\n",
            "class 14 auc: 0.9929399466520913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>0.997763</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.000404</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.999689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.444816</td>\n",
              "      <td>0.017011</td>\n",
              "      <td>0.013741</td>\n",
              "      <td>0.466103</td>\n",
              "      <td>0.072492</td>\n",
              "      <td>0.630402</td>\n",
              "      <td>0.756271</td>\n",
              "      <td>0.422619</td>\n",
              "      <td>0.047154</td>\n",
              "      <td>0.227084</td>\n",
              "      <td>0.057479</td>\n",
              "      <td>0.191088</td>\n",
              "      <td>0.007570</td>\n",
              "      <td>0.489955</td>\n",
              "      <td>0.044485</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.001012</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.998512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.553679</td>\n",
              "      <td>0.063889</td>\n",
              "      <td>0.021123</td>\n",
              "      <td>0.394695</td>\n",
              "      <td>0.950448</td>\n",
              "      <td>0.010452</td>\n",
              "      <td>0.349102</td>\n",
              "      <td>0.954452</td>\n",
              "      <td>0.840761</td>\n",
              "      <td>0.255457</td>\n",
              "      <td>0.167033</td>\n",
              "      <td>0.317005</td>\n",
              "      <td>0.057606</td>\n",
              "      <td>0.181171</td>\n",
              "      <td>0.017205</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.003528  0.997763     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.000490  0.999689     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.489955  0.044485     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.001067  0.998512     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.181171  0.017205     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akBcfLDedqCu"
      },
      "source": [
        "# Inference DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m1hZdOmudtC5",
        "outputId": "c87498f7-09cf-4d3e-d532-9eabb1f81ee5"
      },
      "source": [
        "#model prediction\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(3000,15))\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "\n",
        "    \n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = DenseNet201(weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD_DENSENET_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"DenseNet Model{CFG.NET} has been loaded\")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / 10\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1490]\n",
            "6/6 [==============================] - 44s 287ms/step\n",
            "12/12 [==============================] - 41s 286ms/step\n",
            "[1490, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1501]\n",
            "6/6 [==============================] - 43s 289ms/step\n",
            "12/12 [==============================] - 40s 281ms/step\n",
            "[1490, 1501, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1500]\n",
            "6/6 [==============================] - 46s 293ms/step\n",
            "12/12 [==============================] - 41s 287ms/step\n",
            "[1490, 1501, 1500, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1495]\n",
            "6/6 [==============================] - 44s 288ms/step\n",
            "12/12 [==============================] - 41s 284ms/step\n",
            "[1490, 1501, 1500, 1495, 1494, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1501]\n",
            "6/6 [==============================] - 47s 284ms/step\n",
            "12/12 [==============================] - 41s 283ms/step\n",
            "[1490, 1501, 1500, 1495, 1501, 1495, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1494]\n",
            "6/6 [==============================] - 43s 288ms/step\n",
            "12/12 [==============================] - 41s 281ms/step\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1516, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1495]\n",
            "6/6 [==============================] - 47s 286ms/step\n",
            "12/12 [==============================] - 41s 283ms/step\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1508, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1516]\n",
            "6/6 [==============================] - 41s 291ms/step\n",
            "12/12 [==============================] - 42s 285ms/step\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1500]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1508]\n",
            "6/6 [==============================] - 46s 289ms/step\n",
            "12/12 [==============================] - 44s 285ms/step\n",
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508]\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet Model4 has been loaded\n",
            "[1500]\n",
            "6/6 [==============================] - 41s 282ms/step\n",
            "12/12 [==============================] - 44s 283ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-377d6aaf95d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mdf_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mdf_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fold'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mdf_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_probs_oof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"class{x}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0mdf_oof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_pred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_fold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mdf_oof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'VINBIG_DENSENET_OOF.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_probs_oof' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Yo99Oet57i7l",
        "outputId": "fdc941b8-59ca-483a-baa3-058e2330f0e7"
      },
      "source": [
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total auc: 0.9529051791118306\n",
            "class 14 auc: 0.9890739849679303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001225</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.002121</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.002139</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.002575</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>0.998202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.002371</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.005221</td>\n",
              "      <td>0.003202</td>\n",
              "      <td>0.004513</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.004478</td>\n",
              "      <td>0.003829</td>\n",
              "      <td>0.004607</td>\n",
              "      <td>0.002472</td>\n",
              "      <td>0.997272</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.664114</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>0.028032</td>\n",
              "      <td>0.830702</td>\n",
              "      <td>0.046796</td>\n",
              "      <td>0.240386</td>\n",
              "      <td>0.457719</td>\n",
              "      <td>0.571947</td>\n",
              "      <td>0.089162</td>\n",
              "      <td>0.178943</td>\n",
              "      <td>0.045744</td>\n",
              "      <td>0.099033</td>\n",
              "      <td>0.011544</td>\n",
              "      <td>0.512904</td>\n",
              "      <td>0.024070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>0.004798</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>0.005435</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.022135</td>\n",
              "      <td>0.009931</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.003066</td>\n",
              "      <td>0.994180</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.966398</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.016248</td>\n",
              "      <td>0.167216</td>\n",
              "      <td>0.462104</td>\n",
              "      <td>0.008271</td>\n",
              "      <td>0.078319</td>\n",
              "      <td>0.514315</td>\n",
              "      <td>0.429669</td>\n",
              "      <td>0.068471</td>\n",
              "      <td>0.023668</td>\n",
              "      <td>0.021563</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.133308</td>\n",
              "      <td>0.022219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.001723  0.998202     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.002472  0.997272     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.512904  0.024070     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.003066  0.994180     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.133308  0.022219     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-eNsRRjKzXz"
      },
      "source": [
        "# Inference 768-B4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRoDyuHtK_Gg"
      },
      "source": [
        "class CFG:\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 768\n",
        "    OBJ_HEIGHT = 768\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 32 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 7e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 15\n",
        "    #CLASS_WEIGHT = {0:1.42629, 1:1.29648, 2:1.28211, 3:1.05131, 4:1.26954}\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        " \n",
        "    NET = 4\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    #GCS_PATH_2019 = 'gs://kds-2ae4f2c9141c2ce643fa1d59c544fc258a02543d9cd46d9149ba8c5a'\n",
        "    #GCS_PATH = 'gs://kds-3694fe90d2d447e28a64936f859f7b9803a570ca85e2048c0c9d47df'\n",
        "    #If Ten fold\n",
        "    GCS_PATH = 'gs://kds-986e511f45899ea1ab4c4e6a2fb999e26214b9d1c732a2b1f4a59953'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/vin_2classifier'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0EPw3woK1fS",
        "outputId": "d1d694b9-2907-4720-a5a6-83e42342eb4a"
      },
      "source": [
        "#model prediction\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(3000,15))\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'noisy-student', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x = tf.keras.layers.Dense(15, activation='sigmoid', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'binary_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 10, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"VINBIGTENFOLD{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "    #for i in range(CFG.TTA_NUM+1):\n",
        "    #    if i == 0:\n",
        "    #        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "    #    else:\n",
        "    #        ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    #        pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 2)\n",
        "\n",
        "########## NO TTA\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / 10\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_SUB.csv'),index=False)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(15)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_OOF.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1490]\n",
            "6/6 [==============================] - 22s 405ms/step\n",
            "12/12 [==============================] - 24s 407ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1500, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 22s 407ms/step\n",
            "12/12 [==============================] - 24s 414ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1495, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 22s 404ms/step\n",
            "12/12 [==============================] - 24s 404ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1501, 1494, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 23s 404ms/step\n",
            "12/12 [==============================] - 24s 408ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1494, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1501]\n",
            "6/6 [==============================] - 22s 406ms/step\n",
            "12/12 [==============================] - 25s 413ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1501, 1495, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1494]\n",
            "6/6 [==============================] - 22s 402ms/step\n",
            "12/12 [==============================] - 24s 408ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1501, 1494, 1516, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1495]\n",
            "6/6 [==============================] - 23s 405ms/step\n",
            "12/12 [==============================] - 25s 410ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1508, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1516]\n",
            "6/6 [==============================] - 23s 406ms/step\n",
            "12/12 [==============================] - 25s 408ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1500]\n",
            "Efficient Model4 has been loaded \n",
            "[1508]\n",
            "6/6 [==============================] - 22s 407ms/step\n",
            "12/12 [==============================] - 24s 410ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.48.65.154:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.65.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1490, 1501, 1500, 1495, 1501, 1494, 1495, 1516, 1508]\n",
            "Efficient Model4 has been loaded \n",
            "[1500]\n",
            "6/6 [==============================] - 22s 404ms/step\n",
            "12/12 [==============================] - 24s 412ms/step\n",
            "total auc: 0.9619749598358625\n",
            "class 14 auc: 0.992939764259476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.000980</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>0.997763</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.000404</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.999689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.444816</td>\n",
              "      <td>0.017011</td>\n",
              "      <td>0.013741</td>\n",
              "      <td>0.466103</td>\n",
              "      <td>0.072492</td>\n",
              "      <td>0.630402</td>\n",
              "      <td>0.756271</td>\n",
              "      <td>0.422619</td>\n",
              "      <td>0.047154</td>\n",
              "      <td>0.227084</td>\n",
              "      <td>0.057479</td>\n",
              "      <td>0.191088</td>\n",
              "      <td>0.007570</td>\n",
              "      <td>0.489955</td>\n",
              "      <td>0.044485</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.001012</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.998512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.553679</td>\n",
              "      <td>0.063889</td>\n",
              "      <td>0.021123</td>\n",
              "      <td>0.394695</td>\n",
              "      <td>0.950448</td>\n",
              "      <td>0.010452</td>\n",
              "      <td>0.349102</td>\n",
              "      <td>0.954452</td>\n",
              "      <td>0.840761</td>\n",
              "      <td>0.255457</td>\n",
              "      <td>0.167033</td>\n",
              "      <td>0.317005</td>\n",
              "      <td>0.057606</td>\n",
              "      <td>0.181171</td>\n",
              "      <td>0.017205</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         image_name  target0  target1  ...   class13   class14  fold\n",
              "0  5ce53167cb33fa63c59af857d7236416      0.0      0.0  ...  0.003528  0.997763     0\n",
              "1  63d5b6f568f005932b9246bcb40eee68      0.0      0.0  ...  0.000490  0.999689     0\n",
              "2  be1bb194dfb986bf7554b491852b8901      0.0      0.0  ...  0.489955  0.044485     0\n",
              "3  73a4407a2df891526e94ba4541023f49      0.0      0.0  ...  0.001067  0.998512     0\n",
              "4  9b9f47628be6a48ddb41aec8ba39b454      1.0      0.0  ...  0.181171  0.017205     0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTg6kmymFETD"
      },
      "source": [
        "# MODEL ENSEMBLE\n",
        "dense512 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_OOF.csv'))\n",
        "eff4 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_OOF.csv'))\n",
        "eff4768 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_OOF.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQIeBkioFprr",
        "outputId": "1a49137a-9f78-43bf-d31d-e5927030b829"
      },
      "source": [
        "ind_class_roc = []\n",
        "max_ind_class = 0\n",
        "max_a = 0\n",
        "max_b = 0\n",
        "max_c = 0\n",
        "for a in zip(np.linspace(0,1,30)):\n",
        "    for b in zip(np.linspace(0,1,30)):\n",
        "        for c in zip(np.linspace(0,1,30)):\n",
        "            ensemble = dense512.copy()\n",
        "            ensemble[[f'class{x}' for x in range(15)]] =\\\n",
        "            a*dense512[[f'class{x}' for x in range(15)]].values +\\\n",
        "            b*eff4[[f'class{x}' for x in range(15)]].values +\\\n",
        "            c*eff4768[[f'class{x}' for x in range(15)]].values\n",
        "            ensemble_values = ensemble[[f'class{x}' for x in range(15)]].values\n",
        "            for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "                ind_class_roc.append(roc_auc_score(true[:,i], ensemble_values[:,i]))\n",
        "    #print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "    #print(\"class 14 auc:\", ind_class_roc[-1])\n",
        "            if max_ind_class < ind_class_roc[-1]:\n",
        "                max_ind_class = ind_class_roc[-1]\n",
        "                max_a = a\n",
        "                max_b = b\n",
        "                max_c = c\n",
        "print(f\"max auc at a:{max_a}\\nmax auc at b:{max_b}\\nmax auc at a:{max_c}\\n\", max_ind_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max auc at a:(0.06896551724137931,)\n",
            "max auc at b:(0.3793103448275862,)\n",
            "max auc at a:(0.0,)\n",
            " 0.9936777569673765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fOiSg9nXh8m",
        "outputId": "32efb17a-ca5a-4ac6-9121-34d8a7202b2b"
      },
      "source": [
        "print(max_a, max_b, max_c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.06896551724137931,) (0.3793103448275862,) (0.0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmo_TUSHXjTz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/vin_2classifier'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWCvIabsXq-2"
      },
      "source": [
        "dense512 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_DENSENET_SUB.csv'))\n",
        "eff4 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'))\n",
        "eff4768 = pd.read_csv(os.path.join(ROOT_PATH,f'VINBIG_B4768_SUB.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ir2QJkXzIcnE",
        "outputId": "56dc2507-0361-423b-9ca3-c218ee7f36bc"
      },
      "source": [
        "dense512"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>target4</th>\n",
              "      <th>target5</th>\n",
              "      <th>target6</th>\n",
              "      <th>target7</th>\n",
              "      <th>target8</th>\n",
              "      <th>target9</th>\n",
              "      <th>target10</th>\n",
              "      <th>target11</th>\n",
              "      <th>target12</th>\n",
              "      <th>target13</th>\n",
              "      <th>target14</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5ce53167cb33fa63c59af857d7236416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001225</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.002121</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.002139</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.002575</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>0.998202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63d5b6f568f005932b9246bcb40eee68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.002371</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.005221</td>\n",
              "      <td>0.003202</td>\n",
              "      <td>0.004513</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.004478</td>\n",
              "      <td>0.003829</td>\n",
              "      <td>0.004607</td>\n",
              "      <td>0.002472</td>\n",
              "      <td>0.997273</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>be1bb194dfb986bf7554b491852b8901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.664114</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>0.028032</td>\n",
              "      <td>0.830702</td>\n",
              "      <td>0.046796</td>\n",
              "      <td>0.240386</td>\n",
              "      <td>0.457719</td>\n",
              "      <td>0.571947</td>\n",
              "      <td>0.089162</td>\n",
              "      <td>0.178943</td>\n",
              "      <td>0.045744</td>\n",
              "      <td>0.099033</td>\n",
              "      <td>0.011544</td>\n",
              "      <td>0.512904</td>\n",
              "      <td>0.024070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73a4407a2df891526e94ba4541023f49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>0.004798</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>0.005435</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.022135</td>\n",
              "      <td>0.009931</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.003066</td>\n",
              "      <td>0.994180</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9b9f47628be6a48ddb41aec8ba39b454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.966398</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.016248</td>\n",
              "      <td>0.167216</td>\n",
              "      <td>0.462104</td>\n",
              "      <td>0.008271</td>\n",
              "      <td>0.078319</td>\n",
              "      <td>0.514315</td>\n",
              "      <td>0.429669</td>\n",
              "      <td>0.068471</td>\n",
              "      <td>0.023668</td>\n",
              "      <td>0.021563</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.133308</td>\n",
              "      <td>0.022219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>19e52ebffd475ed05b3da85179bf33e8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.899717</td>\n",
              "      <td>0.003909</td>\n",
              "      <td>0.024409</td>\n",
              "      <td>0.627824</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.010308</td>\n",
              "      <td>0.026417</td>\n",
              "      <td>0.057616</td>\n",
              "      <td>0.055947</td>\n",
              "      <td>0.053580</td>\n",
              "      <td>0.012288</td>\n",
              "      <td>0.196733</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>0.123938</td>\n",
              "      <td>0.044439</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>54794d0cf25eaa7eaa1d37422245d1c3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001059</td>\n",
              "      <td>0.000957</td>\n",
              "      <td>0.001813</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.001135</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.001674</td>\n",
              "      <td>0.001372</td>\n",
              "      <td>0.998875</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>127c8c92b4e4393323efcde8c536de93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.327543</td>\n",
              "      <td>0.008600</td>\n",
              "      <td>0.042980</td>\n",
              "      <td>0.592974</td>\n",
              "      <td>0.002676</td>\n",
              "      <td>0.159124</td>\n",
              "      <td>0.006252</td>\n",
              "      <td>0.004563</td>\n",
              "      <td>0.003591</td>\n",
              "      <td>0.008995</td>\n",
              "      <td>0.005266</td>\n",
              "      <td>0.011235</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>0.426003</td>\n",
              "      <td>0.358000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>26716d576590f1464059375e3de86a29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.001018</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000684</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.000420</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>2033bbf90fa9b91519bac29eb334673a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.781480</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>0.035558</td>\n",
              "      <td>0.057593</td>\n",
              "      <td>0.007645</td>\n",
              "      <td>0.004763</td>\n",
              "      <td>0.013924</td>\n",
              "      <td>0.026893</td>\n",
              "      <td>0.073048</td>\n",
              "      <td>0.025830</td>\n",
              "      <td>0.051151</td>\n",
              "      <td>0.211420</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>0.254748</td>\n",
              "      <td>0.140278</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             image_name  target0  ...   class14  fold\n",
              "0      5ce53167cb33fa63c59af857d7236416      0.0  ...  0.998202     0\n",
              "1      63d5b6f568f005932b9246bcb40eee68      0.0  ...  0.997273     0\n",
              "2      be1bb194dfb986bf7554b491852b8901      0.0  ...  0.024070     0\n",
              "3      73a4407a2df891526e94ba4541023f49      0.0  ...  0.994180     0\n",
              "4      9b9f47628be6a48ddb41aec8ba39b454      1.0  ...  0.022219     0\n",
              "...                                 ...      ...  ...       ...   ...\n",
              "14995  19e52ebffd475ed05b3da85179bf33e8      0.0  ...  0.044439     9\n",
              "14996  54794d0cf25eaa7eaa1d37422245d1c3      0.0  ...  0.998875     9\n",
              "14997  127c8c92b4e4393323efcde8c536de93      0.0  ...  0.358000     9\n",
              "14998  26716d576590f1464059375e3de86a29      0.0  ...  0.999839     9\n",
              "14999  2033bbf90fa9b91519bac29eb334673a      0.0  ...  0.140278     9\n",
              "\n",
              "[15000 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU50ILn4Ild3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}